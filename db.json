{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"source/robots.txt","path":"robots.txt","modified":0,"renderable":0},{"_id":"themes/quiet/source/css/about.css","path":"css/about.css","modified":0,"renderable":1},{"_id":"themes/quiet/source/css/archive.css","path":"css/archive.css","modified":0,"renderable":1},{"_id":"themes/quiet/source/css/categories.css","path":"css/categories.css","modified":0,"renderable":1},{"_id":"themes/quiet/source/css/atom-one-dark.css","path":"css/atom-one-dark.css","modified":0,"renderable":1},{"_id":"themes/quiet/source/css/food.css","path":"css/food.css","modified":0,"renderable":1},{"_id":"themes/quiet/source/css/header.css","path":"css/header.css","modified":0,"renderable":1},{"_id":"themes/quiet/source/css/links.css","path":"css/links.css","modified":0,"renderable":1},{"_id":"themes/quiet/source/css/home.css","path":"css/home.css","modified":0,"renderable":1},{"_id":"themes/quiet/source/css/page.css","path":"css/page.css","modified":0,"renderable":1},{"_id":"themes/quiet/source/css/page_cente.css","path":"css/page_cente.css","modified":0,"renderable":1},{"_id":"themes/quiet/source/css/tags.css","path":"css/tags.css","modified":0,"renderable":1},{"_id":"themes/quiet/source/css/tag.css","path":"css/tag.css","modified":0,"renderable":1},{"_id":"themes/quiet/source/image/favicon.ico.bak","path":"image/favicon.ico.bak","modified":0,"renderable":1},{"_id":"themes/quiet/source/image/favicon.ico","path":"image/favicon.ico","modified":0,"renderable":1},{"_id":"themes/quiet/source/image/logo.png","path":"image/logo.png","modified":0,"renderable":1},{"_id":"themes/quiet/source/image/pattern.png","path":"image/pattern.png","modified":0,"renderable":1},{"_id":"themes/quiet/source/js/gotop.js","path":"js/gotop.js","modified":0,"renderable":1},{"_id":"themes/quiet/source/js/jquery.min.js","path":"js/jquery.min.js","modified":0,"renderable":1}],"Cache":[{"_id":"source/google87c07700b203804b.html","hash":"8daa1f8c4001efbd5d3efe8be8d36eaedb4f4279","modified":1648984056411},{"_id":"source/robots.txt","hash":"db1d1a8690484d24907e8d96fbab1ce46546c076","modified":1648982610661},{"_id":"source/about/index.md","hash":"58c499a6c6606ff5b5298f6be77044d449cbaea2","modified":1649156305326},{"_id":"source/_posts/Windows右键打开注册表配置.md","hash":"719be387ca5ab03d406e49ffb13b66846704f2b7","modified":1649159239633},{"_id":"source/_posts/Windows局域网共享文件.md","hash":"57057c203aff3c865e0416134eae5c82e4bb41c8","modified":1649159471405},{"_id":"source/_posts/编译Linux与Uboot.md","hash":"fd15109bda87c70ec140d749d2e690de77ce3672","modified":1649160376028},{"_id":"source/links/index.md","hash":"abe78e5176468d7306d56b9375b1f9512c81137d","modified":1649156107978},{"_id":"source/categories/index.md","hash":"098db27ce4767e092916813137a0fcdbffd45069","modified":1649158837545},{"_id":"source/tags/index.md","hash":"ae58101a97844b4aacd1babc652b94f632f129ab","modified":1649156030436},{"_id":"themes/quiet/LICENSE","hash":"a0da6b64f5ac3c2be67e22af05669c299eaa8c84","modified":1649139832719},{"_id":"themes/quiet/_config.yml","hash":"a529b63941cdc8f1c38252fd51feb0dfe33ffed5","modified":1649164947293},{"_id":"themes/quiet/languages/en.yml","hash":"81ae86203870165bcad70cd3f3dfb1b27dbd7b92","modified":1648908659161},{"_id":"themes/quiet/languages/zh-CN.yml","hash":"6ea5c442674098d947bcba89f78fcefc4d763bb0","modified":1648908659162},{"_id":"themes/quiet/layout/.DS_Store","hash":"46cf1797a08a1ea0f0cdb2af9ebf7d59bd6d976a","modified":1649139832750},{"_id":"themes/quiet/layout/404.ejs","hash":"d24c2375e0e927085e6dbeb788fde5e119bcc9b8","modified":1649139832751},{"_id":"themes/quiet/layout/about.ejs","hash":"4e1ec51bfd4823d8f0a2ab4c06c06f79bae8541a","modified":1649140834571},{"_id":"themes/quiet/layout/archive.ejs","hash":"bb8f521bdc7f4fe9e7a03beb5ceb63032dff9e4d","modified":1649156368290},{"_id":"themes/quiet/layout/categories.ejs","hash":"bc3bb7a3276d6aa25b805e73addbea778c198605","modified":1649139832765},{"_id":"themes/quiet/layout/index.ejs","hash":"b36963002a0fafb093db68c77eb0f2d0b5e7ded6","modified":1649141218597},{"_id":"themes/quiet/layout/layout.ejs","hash":"1de4d59c593645e3dd2f7953e3c4dda73606b8c3","modified":1649139832766},{"_id":"themes/quiet/layout/links.ejs","hash":"c1db6ee6b94ac0693926ba64c46d6ddd0cf18c69","modified":1649139832767},{"_id":"themes/quiet/layout/post.ejs","hash":"10c5eab4b9964b3565ab3ee3e793364032ec04da","modified":1649139832767},{"_id":"themes/quiet/layout/tag.ejs","hash":"1fa7d8d5a5db1bd817090f8998d985316f33e2b0","modified":1649139832767},{"_id":"themes/quiet/layout/tags.ejs","hash":"587bd14d96946c117b1ef6d2e612cd20e23b59ab","modified":1649139832768},{"_id":"themes/quiet/.DS_Store","hash":"d6b0bd348c278071914e2dee0dfe4123fecf375f","modified":1649139832718},{"_id":"themes/quiet/layout/_partial/.DS_Store","hash":"db62fbf1993ecd5d9e70a49a58be69ac7e7a4485","modified":1649139832751},{"_id":"themes/quiet/layout/_partial/foot.ejs","hash":"1bd9e8a5892c120d7f633e9c17a024d12d456eea","modified":1649163895403},{"_id":"themes/quiet/layout/_partial/head.ejs","hash":"d7536b46c02d8acba84d21b8ad62edefb7ce86da","modified":1649139832759},{"_id":"themes/quiet/layout/_partial/header.ejs","hash":"60f6d69505c64f628c9ace9325aa28950730852b","modified":1649139832759},{"_id":"themes/quiet/layout/_partial/home.ejs","hash":"094e3dc189406526d3934894cf0352b26ce28f13","modified":1649139832759},{"_id":"themes/quiet/layout/_partial/post_centent.ejs","hash":"b6bb8b8e04433b37854e8c8df79c72de182f4496","modified":1649139832761},{"_id":"themes/quiet/layout/_partial/post_head.ejs","hash":"be2f5a2d0d91ddb529c0508183d57ad105fedefa","modified":1649139832761},{"_id":"themes/quiet/layout/_partial/post_pn.ejs","hash":"7fab46ce1199e5e792d6f7c597690ad768f9730c","modified":1649139832761},{"_id":"themes/quiet/layout/_widget/analytics.ejs","hash":"c48c85b36c50cd18b018d0d3a08981dfb1a37bf5","modified":1649139832763},{"_id":"themes/quiet/layout/_widget/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1649139832762},{"_id":"themes/quiet/layout/_widget/gotop.ejs","hash":"fdc070e8dbd81198bbd36cdf46e8b7c33ecdeaf0","modified":1649139832763},{"_id":"themes/quiet/layout/_widget/sidebar.ejs","hash":"1e60a534616fdcf97a4d61ef25648af263ffa6e1","modified":1649139832763},{"_id":"themes/quiet/README-EN.md","hash":"8a14c4a1b8880c1b389c18e832ba7e0437c6a480","modified":1649139832732},{"_id":"themes/quiet/README.md","hash":"029fba4d4abe72177ae38e103d49581428ec6575","modified":1649139832747},{"_id":"themes/quiet/source/css/archive.css","hash":"e87c945020b9141c8dd43e0349bd1ebaa1d13f30","modified":1649139832781},{"_id":"themes/quiet/source/css/categories.css","hash":"06b727d6e2e21b1e5ab12de073406517c32dfe93","modified":1649139832783},{"_id":"themes/quiet/source/css/atom-one-dark.css","hash":"c3e2c329a09062a1702f0f51639e2068a0799fe4","modified":1649139832782},{"_id":"themes/quiet/source/css/food.css","hash":"10a0e21ef9b2e4a6af9328be51e1c0368ca91f4e","modified":1649139832783},{"_id":"themes/quiet/source/css/header.css","hash":"e3ce1dbac2e258f0943c5aebdd89b29702246baa","modified":1649139832784},{"_id":"themes/quiet/source/css/links.css","hash":"c7afe457cea5d996ee86cfc47174aa114e458fb0","modified":1649139832785},{"_id":"themes/quiet/source/css/home.css","hash":"e474078a73fa75f23f37092f01505dd8063ffc38","modified":1649139832784},{"_id":"themes/quiet/source/css/page.css","hash":"0514b75a35c93c10826cd861f0dd380d90ba8e41","modified":1649139832785},{"_id":"themes/quiet/source/css/.DS_Store","hash":"75b22b6a020bdf7a452db2f4d29044b8a88a6661","modified":1649139832780},{"_id":"themes/quiet/source/css/page_cente.css","hash":"b85a224b56e93c6b56058ed49cde58e0bfc1d2e4","modified":1649139832785},{"_id":"themes/quiet/source/css/tags.css","hash":"b2de1e197efba0a058f1a5d37aa014fcfc0016ff","modified":1649139832786},{"_id":"themes/quiet/source/.DS_Store","hash":"2fe0ee40294946d656b103cef8719c97924075f1","modified":1649139832779},{"_id":"themes/quiet/source/css/about.css","hash":"d3d7ae17f0571f1cec4514135d644c6590118bd0","modified":1649139832781},{"_id":"themes/quiet/source/image/pattern.png","hash":"e9a79b9b5716c781e8f5acf3462e42fae7f39741","modified":1649139832788},{"_id":"themes/quiet/source/js/gotop.js","hash":"2bd969b8dd7b81626dcd2a3d8a1b1bbb4e0fc33c","modified":1649139832789},{"_id":"themes/quiet/source/image/.DS_Store","hash":"3128ff56de5645c269da786b475fd357f1db7a5f","modified":1649139832787},{"_id":"themes/quiet/source/js/jquery.min.js","hash":"a9d8678047219b378ddf3addf4b44650b677eec7","modified":1649139832790},{"_id":"themes/quiet/source/image/favicon.ico","hash":"d385f27e16736b3ac501e2de2e8e5204e4e085e6","modified":1649151784325},{"_id":"themes/quiet/source/image/logo.png","hash":"d385f27e16736b3ac501e2de2e8e5204e4e085e6","modified":1649151784325},{"_id":"themes/quiet/source/css/tag.css","hash":"e87c945020b9141c8dd43e0349bd1ebaa1d13f30","modified":1649139832786},{"_id":"themes/quiet/source/js/.DS_Store","hash":"0f43f1407d3b3df9e865a28f4c9ef13640ad739b","modified":1649139832788},{"_id":"themes/quiet/source/image/favicon.ico.bak","hash":"15c3a5125bd5c742c1b49e6435e1f611719cdbc2","modified":1649151610368},{"_id":"public/baidusitemap.xml","hash":"3813865c53ea2943dfef29d80f41cad259b261a4","modified":1649161225043},{"_id":"public/sitemap.xml","hash":"4b1db1ac2de117214fa4bcfc0830457da21955fd","modified":1649161225043},{"_id":"public/google87c07700b203804b.html","hash":"bcfdf0c2a43e9b46f5e39a184a8a3c0de263c9eb","modified":1649163901126},{"_id":"public/about/index.html","hash":"88dce4d31bb9ce359cbf6065fcf1918b440cab46","modified":1649163901126},{"_id":"public/links/index.html","hash":"91dcce417fa6a8d70e6d443d2800c6ea209ebf01","modified":1649164889163},{"_id":"public/categories/index.html","hash":"7e0750424cc29baab490d2980ea72f9138ba4a32","modified":1649163901126},{"_id":"public/tags/index.html","hash":"60aaa9ea233b4734223505061c0264412eac8fb8","modified":1649164889163},{"_id":"public/2022/04/05/Windows局域网共享文件/index.html","hash":"4ed647014550770752c847461d72286a2c1a8333","modified":1649163901126},{"_id":"public/2022/04/05/Windows右键打开注册表配置/index.html","hash":"958817068295f171408eb0fbb528d9832c1ab50e","modified":1649163901126},{"_id":"public/archives/index.html","hash":"95a550933cc35c60d425b7914a48756f87f7c055","modified":1649163901126},{"_id":"public/archives/2022/index.html","hash":"95a550933cc35c60d425b7914a48756f87f7c055","modified":1649163901126},{"_id":"public/archives/2022/04/index.html","hash":"95a550933cc35c60d425b7914a48756f87f7c055","modified":1649163901126},{"_id":"public/index.html","hash":"e4199244045f7523ae71c8a2b72ec7631746b8b7","modified":1649163901126},{"_id":"public/tags/计算机妙招/index.html","hash":"f179d55fc4851520535a3aebff96c1191ce3db22","modified":1649163901126},{"_id":"public/categories/计算机事半功倍/index.html","hash":"00d58f2bc5a695c54657674eb40355400752c00e","modified":1649163901126},{"_id":"public/tags/注册表/index.html","hash":"82c9f5909c70b9f0e8bfb5fcb55f0583b39346cd","modified":1649163901126},{"_id":"public/tags/Windows/index.html","hash":"550804dfbf752d7b82012b57496331a2857ac399","modified":1649163901126},{"_id":"public/tags/局域网共享/index.html","hash":"3c34aa472e0c6a9a36297bc280120cf0a139adeb","modified":1649163901126},{"_id":"public/robots.txt","hash":"db1d1a8690484d24907e8d96fbab1ce46546c076","modified":1649160081108},{"_id":"public/image/pattern.png","hash":"e9a79b9b5716c781e8f5acf3462e42fae7f39741","modified":1649160081108},{"_id":"public/image/favicon.ico","hash":"d385f27e16736b3ac501e2de2e8e5204e4e085e6","modified":1649160081108},{"_id":"public/image/logo.png","hash":"d385f27e16736b3ac501e2de2e8e5204e4e085e6","modified":1649160081108},{"_id":"public/css/categories.css","hash":"06b727d6e2e21b1e5ab12de073406517c32dfe93","modified":1649160081108},{"_id":"public/css/about.css","hash":"d3d7ae17f0571f1cec4514135d644c6590118bd0","modified":1649160081108},{"_id":"public/css/archive.css","hash":"e87c945020b9141c8dd43e0349bd1ebaa1d13f30","modified":1649160081108},{"_id":"public/css/atom-one-dark.css","hash":"da8603ef348b38d6ef090fa9172a6521e53b6c89","modified":1649160081108},{"_id":"public/css/header.css","hash":"e3ce1dbac2e258f0943c5aebdd89b29702246baa","modified":1649160081108},{"_id":"public/css/food.css","hash":"10a0e21ef9b2e4a6af9328be51e1c0368ca91f4e","modified":1649160081108},{"_id":"public/css/home.css","hash":"e474078a73fa75f23f37092f01505dd8063ffc38","modified":1649160081108},{"_id":"public/css/page.css","hash":"0514b75a35c93c10826cd861f0dd380d90ba8e41","modified":1649160081108},{"_id":"public/css/links.css","hash":"c7afe457cea5d996ee86cfc47174aa114e458fb0","modified":1649160081108},{"_id":"public/css/page_cente.css","hash":"b85a224b56e93c6b56058ed49cde58e0bfc1d2e4","modified":1649160081108},{"_id":"public/css/tags.css","hash":"b2de1e197efba0a058f1a5d37aa014fcfc0016ff","modified":1649160081108},{"_id":"public/css/tag.css","hash":"e87c945020b9141c8dd43e0349bd1ebaa1d13f30","modified":1649160081108},{"_id":"public/js/gotop.js","hash":"2bd969b8dd7b81626dcd2a3d8a1b1bbb4e0fc33c","modified":1649160081108},{"_id":"public/image/favicon.ico.bak","hash":"15c3a5125bd5c742c1b49e6435e1f611719cdbc2","modified":1649160081108},{"_id":"public/js/jquery.min.js","hash":"948b382d052e9af0de5353f29f986d3080e7221c","modified":1649160081108},{"_id":"public/2022/04/05/编译Linux与Uboot/index.html","hash":"f090901438d489fcb757cefc300be7d059f6fc18","modified":1649163901126},{"_id":"public/categories/Linux/index.html","hash":"00d58f2bc5a695c54657674eb40355400752c00e","modified":1649163901126},{"_id":"public/tags/Linux/index.html","hash":"c103ac0d9f53aa6f925451f0aae5e9ad772700df","modified":1649163901126},{"_id":"public/tags/Uboot/index.html","hash":"bd15f1831bdcb950c98136cd8738ac75e4a05653","modified":1649163901126},{"_id":"public/tags/编译/index.html","hash":"4fd9739e10778ef0d38bf9e178c7628b44373f89","modified":1649163901126},{"_id":"source/_posts/Python爬虫学习.md","hash":"af7a40746791d8a8d6cabe2c47dff938ecfb6072","modified":1649160928627},{"_id":"public/2022/04/05/Python爬虫学习/index.html","hash":"764afc97786bd9fcf02be04a5b7ccc011c452e0e","modified":1649163901126},{"_id":"public/categories/Python/index.html","hash":"00d58f2bc5a695c54657674eb40355400752c00e","modified":1649163901126},{"_id":"public/categories/Python/爬虫/index.html","hash":"00d58f2bc5a695c54657674eb40355400752c00e","modified":1649163901126},{"_id":"public/tags/Python/index.html","hash":"2c2b2f65eccf4b777ca0af4874a0c49acc38d25a","modified":1649163901126},{"_id":"public/tags/爬虫/index.html","hash":"ef70c524050f58114c283a280e07cae76610ce2e","modified":1649163901126},{"_id":"source/_posts/Python爬虫学习——面向初学者.md","hash":"7201a7a0bb983a03b2c89d8c830b5b01056e2ef1","modified":1649164331261},{"_id":"public/2022/04/05/Python爬虫学习——面向初学者/index.html","hash":"2f33943385e47f111b88da7c7d85033b1364c87f","modified":1649164348313},{"_id":"source/_posts/GitHub-部署个人博客.md","hash":"98b8b072147908b261461179cf559a2de70bcd7b","modified":1649164400092}],"Category":[{"name":"计算机事半功倍","_id":"cl1m3bz2e00047gu5a8lqgc07"},{"name":"Linux","_id":"cl1m3fohu0001k4u5eib1fo2k"},{"name":"Python","_id":"cl1m3qred00010su5cl370w8n"},{"name":"爬虫","parent":"cl1m3qred00010su5cl370w8n","_id":"cl1m3qreh00040su56ch6hsan"}],"Data":[],"Page":[{"_content":"google-site-verification: google87c07700b203804b.html","source":"google87c07700b203804b.html","raw":"google-site-verification: google87c07700b203804b.html","date":"2022-04-03T11:07:39.683Z","updated":"2022-04-03T11:07:36.411Z","path":"google87c07700b203804b.html","title":"","comments":1,"layout":"page","_id":"cl1m3bz2500007gu5axpr0f2g","content":"google-site-verification: google87c07700b203804b.html","site":{"data":{}},"excerpt":"","more":"google-site-verification: google87c07700b203804b.html"},{"title":"个人简介","date":"2022-04-03T08:32:46.000Z","aubot":"Yoyo","portrait":"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051857441.png","describe":"我想读研究生","type":"about","layout":"about","author":"yoyo","_content":"","source":"about/index.md","raw":"---\ntitle: 个人简介\ndate: 2022-04-03 16:32:46\naubot: Yoyo\nportrait: \"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051857441.png\"\ndescribe: '我想读研究生'\ntype: \"about\"\nlayout: \"about\"\nauthor: yoyo\n---\n","updated":"2022-04-05T10:58:25.326Z","path":"about/index.html","comments":1,"_id":"cl1m3bz2a00027gu532cl55tb","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"友情链接","date":"2022-04-05T07:36:05.000Z","layout":"links","author":"yoyo","_content":"","source":"links/index.md","raw":"---\ntitle: 友情链接\ndate: 2022-04-05 15:36:05\nlayout: \"links\"\nauthor: yoyo\n---\n","updated":"2022-04-05T10:55:07.978Z","path":"links/index.html","comments":1,"_id":"cl1m3bz2g00067gu544a07yvi","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"分类","date":"2022-04-03T08:31:27.000Z","layout":"categories","author":"yoyo","_content":"","source":"categories/index.md","raw":"---\ntitle: 分类\ndate: 2022-04-03 16:31:27\nlayout: \"categories\"\nauthor: yoyo\n---\n","updated":"2022-04-05T11:40:37.545Z","path":"categories/index.html","comments":1,"_id":"cl1m3bz2i00087gu5ay459f7h","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"标签","date":"2022-04-03T08:10:46.000Z","layout":"tags","author":"yoyo","_content":"\n# 选择下列你喜欢的标签吧\n\n\n","source":"tags/index.md","raw":"---\ntitle: 标签\ndate: 2022-04-03 16:10:46\nlayout: \"tags\"\nauthor: yoyo\n---\n\n# 选择下列你喜欢的标签吧\n\n\n","updated":"2022-04-05T10:53:50.436Z","path":"tags/index.html","comments":1,"_id":"cl1m3bz2n00097gu56urw7tdl","content":"<h1 id=\"选择下列你喜欢的标签吧\"><a href=\"#选择下列你喜欢的标签吧\" class=\"headerlink\" title=\"选择下列你喜欢的标签吧\"></a>选择下列你喜欢的标签吧</h1>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"选择下列你喜欢的标签吧\"><a href=\"#选择下列你喜欢的标签吧\" class=\"headerlink\" title=\"选择下列你喜欢的标签吧\"></a>选择下列你喜欢的标签吧</h1>"}],"Post":[{"title":"Windows右键打开注册表配置","date":"2022-04-05T11:27:00.000Z","excerpt":"使得能右键以某个软件打开","cover":"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051934962.png","_content":"win+R regedit调出注册表\n\n```shell\n计算机\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Classes\\*\\shell\\\n```\n\n> 上面这个路径下新建项：Open with ……\n\n> 然后Open with ……新建项Command\n\n> Command 默认为 路径\\…….。exe  \"%1\"\n\n> 然后Open with ……新建Icon字符串值\n\n> 为路径\\…….。exe\n\n![image-20210102212700378](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051936063.png)\n\n![image-20210102212729670](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051936887.png)\n","source":"_posts/Windows右键打开注册表配置.md","raw":"---\ntitle: Windows右键打开注册表配置\ndate: 2022-04-05 19:27:00\ntags: \n\t- 计算机妙招\n\t- 注册表\n\t- Windows\nexcerpt: 使得能右键以某个软件打开\ncover: 'https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051934962.png'\ncategories: 计算机事半功倍\n---\nwin+R regedit调出注册表\n\n```shell\n计算机\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Classes\\*\\shell\\\n```\n\n> 上面这个路径下新建项：Open with ……\n\n> 然后Open with ……新建项Command\n\n> Command 默认为 路径\\…….。exe  \"%1\"\n\n> 然后Open with ……新建Icon字符串值\n\n> 为路径\\…….。exe\n\n![image-20210102212700378](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051936063.png)\n\n![image-20210102212729670](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051936887.png)\n","slug":"Windows右键打开注册表配置","published":1,"updated":"2022-04-05T11:47:19.633Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1m3bz2800017gu52i2z1vdl","content":"<p>win+R regedit调出注册表</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">计算机\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Classes\\*\\shell\\</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>上面这个路径下新建项：Open with ……</p>\n</blockquote>\n<blockquote>\n<p>然后Open with ……新建项Command</p>\n</blockquote>\n<blockquote>\n<p>Command 默认为 路径\\…….。exe  “%1”</p>\n</blockquote>\n<blockquote>\n<p>然后Open with ……新建Icon字符串值</p>\n</blockquote>\n<blockquote>\n<p>为路径\\…….。exe</p>\n</blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051936063.png\" alt=\"image-20210102212700378\"></p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051936887.png\" alt=\"image-20210102212729670\"></p>\n","site":{"data":{}},"more":"<p>win+R regedit调出注册表</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">计算机\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Classes\\*\\shell\\</span><br></pre></td></tr></table></figure>\n\n<blockquote>\n<p>上面这个路径下新建项：Open with ……</p>\n</blockquote>\n<blockquote>\n<p>然后Open with ……新建项Command</p>\n</blockquote>\n<blockquote>\n<p>Command 默认为 路径\\…….。exe  “%1”</p>\n</blockquote>\n<blockquote>\n<p>然后Open with ……新建Icon字符串值</p>\n</blockquote>\n<blockquote>\n<p>为路径\\…….。exe</p>\n</blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051936063.png\" alt=\"image-20210102212700378\"></p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051936887.png\" alt=\"image-20210102212729670\"></p>\n"},{"title":"Windows局域网共享文件","date":"2022-04-05T11:27:37.000Z","excerpt":"采取原始的网络连接方式，让数据传输变得快速","cover":"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051949856.png","_content":"\n## 开启地方1、设置\n\n![image-20220309223046115](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051946490.png)\n\n控制面板 --> 网络和Internet --> 网络和共享中心 --> 高级共享设置\n\n记得关闭 密码保护共享\n\n## 开启地方2、文件夹\n\n右键，属性，共享，高级共享（共享此文件夹勾选），应用，共享（下来框添加Everyone）、点击共享\n\n![image-20220405195030682](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051950781.png)\n\n\n\n关闭共享如下图所示\n\n![image-20220405195106733](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051951817.png)\n\n","source":"_posts/Windows局域网共享文件.md","raw":"---\ntitle: Windows局域网共享文件\ndate: 2022-04-05 19:27:37\ntags: \n\t- 计算机妙招\n\t- 局域网共享\n\t- Windows\nexcerpt: 采取原始的网络连接方式，让数据传输变得快速\ncover: 'https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051949856.png'\ncategories: 计算机事半功倍\n---\n\n## 开启地方1、设置\n\n![image-20220309223046115](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051946490.png)\n\n控制面板 --> 网络和Internet --> 网络和共享中心 --> 高级共享设置\n\n记得关闭 密码保护共享\n\n## 开启地方2、文件夹\n\n右键，属性，共享，高级共享（共享此文件夹勾选），应用，共享（下来框添加Everyone）、点击共享\n\n![image-20220405195030682](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051950781.png)\n\n\n\n关闭共享如下图所示\n\n![image-20220405195106733](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051951817.png)\n\n","slug":"Windows局域网共享文件","published":1,"updated":"2022-04-05T11:51:11.405Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cl1m3bz2b00037gu5c4j22ql3","content":"<h2 id=\"开启地方1、设置\"><a href=\"#开启地方1、设置\" class=\"headerlink\" title=\"开启地方1、设置\"></a>开启地方1、设置</h2><p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051946490.png\" alt=\"image-20220309223046115\"></p>\n<p>控制面板 –&gt; 网络和Internet –&gt; 网络和共享中心 –&gt; 高级共享设置</p>\n<p>记得关闭 密码保护共享</p>\n<h2 id=\"开启地方2、文件夹\"><a href=\"#开启地方2、文件夹\" class=\"headerlink\" title=\"开启地方2、文件夹\"></a>开启地方2、文件夹</h2><p>右键，属性，共享，高级共享（共享此文件夹勾选），应用，共享（下来框添加Everyone）、点击共享</p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051950781.png\" alt=\"image-20220405195030682\"></p>\n<p>关闭共享如下图所示</p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051951817.png\" alt=\"image-20220405195106733\"></p>\n","site":{"data":{}},"more":"<h2 id=\"开启地方1、设置\"><a href=\"#开启地方1、设置\" class=\"headerlink\" title=\"开启地方1、设置\"></a>开启地方1、设置</h2><p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051946490.png\" alt=\"image-20220309223046115\"></p>\n<p>控制面板 –&gt; 网络和Internet –&gt; 网络和共享中心 –&gt; 高级共享设置</p>\n<p>记得关闭 密码保护共享</p>\n<h2 id=\"开启地方2、文件夹\"><a href=\"#开启地方2、文件夹\" class=\"headerlink\" title=\"开启地方2、文件夹\"></a>开启地方2、文件夹</h2><p>右键，属性，共享，高级共享（共享此文件夹勾选），应用，共享（下来框添加Everyone）、点击共享</p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051950781.png\" alt=\"image-20220405195030682\"></p>\n<p>关闭共享如下图所示</p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051951817.png\" alt=\"image-20220405195106733\"></p>\n"},{"title":"编译Linux与Uboot","cover":"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052005616.png","date":"2022-04-05T11:53:21.000Z","excerpt":"编译你自己的Linux和uboot","_content":"\n# 一、前言\n\n目前没有前言\n\n# 二、准备工作\n\n准备太久了\n\n# 三、PCB绘制\n\n不是我绘制的\n\n# 四、下载编译工具链\n\n我下的是`arm-linux-gnueabi-`\n\n# 五、u-boot移植\n\n## 1、下载`u-boot`\n\n```shell\ngit clone https://github.com/Lichee-Pi/u-boot.git\ngit branch -a  # 查看分支，我们使用的是nano-v2018.01u-boot\ngit checkout nano-v2018.01u-boot  # 切换到nano-v2018.01u-boot这个分支\n```\n\n## 2、选取`config`配置\n\n考虑到水平有限，我们采用从现有的配置上进行更改。或者，我完全不进行更改，就直接使用了。\n\n### *对几个config简单介绍：*\n\n>`f1c100s_nano_uboot_defconfig`：`SPI Flash`支持版\n>\n>`licheepi_nano_defconfig`：不带`SPI Flash`，从`TF`卡启动\n>\n>`licheepi_nano_spiflash_defconfig`：从`SPI`设备启动\n\n其实上面三种我也分不清楚，我第一次采用的是 `licheepi_nano_defconfig`。我也找不到 `f1c100s_nano_uboot_defconfig`，但是在[这](https://gitee.com/LicheePiNano/u-boot)可以找到，这个是荔枝派的 `u-boot`，可能毕竟这款 `f1c100s`是国产芯片，在`GitHub`上面找不到。\n\n### 选取`config`操作\n\n```shell\ncd ~/u-boot  # 切换到 下载的 u-boot 的根目录\nmake ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- licheepi_nano_defconfig  \n# 参数介绍：\n# ARCH=arm 是arm架构的\n# CROSS_COMPILE=arm-linux-gnueabi-  是之前的下载的编译工具链\n# licheepi_nano_defconfig 选取的默认config\n```\n\n## 3、可视化配置\n\n### 打开菜单命令\n\n```shell\nmake ARCH=arm menuconfig\n# 之后上下键进行移动\n# 空格或者回车进行选择\n# 左右可以选择下方菜单\n# ctrl+退格才能删除已经填入的默认参数\n```\n\n### 参数讲解\n\n注意下面这两个参数就行\n\n![image-20220305195147976](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958695.png)\n\n#### `boot arguments`\n\n> - `console=ttyS0,115200 panic=5 rootwait root=/dev/mmcblk0p2 earlyprintk rw`\n>\n> > **`console=ttyS0,115200`** 表示终端为ttyS0即串口0,波特率为115200；\n> >\n> > **`panic=5` **字面意思是恐慌，即linux内核恐慌，其实就是linux不知道怎么执行了，此时内核就需要做一些相关的处理，这里的5表示超时时间，当Linux卡住5秒后仍未成功就会执行Linux恐慌异常的一些操作。\n> >\n> > `rootwait` 该参数是告诉内核挂在文件系统之前需要先加载相关驱动，这样做的目的是防止因mmc驱动还未加载就开始挂载驱动而导致文件系统挂载失败，所以一般bootargs中都要加上这个参数。\n> >\n> > **root=/dev/mmcblk0p2** 表示根文件系统的位置在mmc的0:2分区处，**/dev**是设备文件夹，内核在加载mmc中的时候就会在根文件系统中生成**mmcblk0p2**设备文件，这个设备文件其实就是mmc的0:2分区(这里对应TF卡的第二个分区：rootfs)，这样内核对文件系统的读写操作方式本质上就是读写/dev/mmcblk0p2该设备文件。\n> >\n> > **`earlyprintk`** 参数是指在内核加载的过程中打印输出信息，这样内核在加载的时候终端就会输出相应的启动信息。rw表示文件系统的操作属性，此处rw表示可读可写。\n\n#### `bootcmd`\n\n> - `load mmc 0:1 0x80008000 zImage;load mmc 0:1 0x80c08000 suniv-f1c100s-licheepi-nano.dtb;bootz 0x80008000 - 0x80c08000;`\n>\n> > ![image-20220305195531843](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051959333.png)\n\n\n\n## 、遇到问题不要慌\n\n### （1）` execute 'swig'`\n\n> 没有`swig`这个东西，安装即可：`sudo apt install swig`\n>\n> `swig`：我从[网上](https://zh.wikipedia.org/wiki/SWIG)了解到是一个将`C/C++`的类封装成库，给`Python、Lua、PHP`等脚本语言调用。（题外话）\n\n## 、参考链接\n\n> [参考博客](https://cnblogs.com/twzy/p/14865952.html)\n>\n> [参考荔枝派](https://wiki.sipeed.com/soft/Lichee/zh/Nano-Doc-Backup/get_started/first_eat.html)![image-20220305205126696](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051959649.png)\n\n# 六、`Linux`的移植\n\n## 1、分区操作\n\n​\t一个硬盘对于`Linux`来说，需要进行**挂载**命令是：`mount`，一般插上自动挂载），然后再能使用，然后需要**卸载**（命令：`umount`）才能操作，如格式化，分区之类的。我们借助了`Ubuntu`下图形化工具——**`Gparted`**，命令行进行下载就行了。\n\n​\t然后，买到手的`sd`卡，可能已经分区了，有一个主分区。如果没法删除，或者进场出现例如*`/dev/sdb contains a mounted filesystem`*，我的建议，使用一个全0的映像文件写入`sd`卡，将前面的数据覆盖。\n\n​\t之后便是分区了，将只有一个未分区的，且没有任何分区的`sd`卡连接`Ubuntu`。\n\n### 分区1、`boot`\n\n> 新建一个分区\n>\n> 之前剩余空间为**1M**，新大小为**32M**，文件系统为**`fat16`**，卷标就设置为**`boot`**\n>\n> 对于之前的`1M`，是留给**`uboot`**的，而且在`gparted`是看不到的\n>\n> **图片来源于网络**\n>\n> ![image-20220314221728714](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958740.png)\n\n### 分区2、`rootfs`\n\n> 新建一个分区\n>\n> 之前剩余空间为**0M**，新大小为**100M**，文件系统为**`ext4`**，卷标就设置为**`rootfs`**\n>\n> ***图片来源于网络***\n>\n> ![image-20220314221807562](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958803.png)\n\n### 最后的效果\n\n![image-20220314221850652](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958789.png)\n\n## 2、编译**`Linux`**\n\n### 更改设备树\n\n# 七、编译`rootfs`\n\n","source":"_posts/编译Linux与Uboot.md","raw":"---\ntitle: 编译Linux与Uboot\ncover: 'https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052005616.png'\ndate: 2022-04-05 19:53:21\ntags: \n\t- Linux\n\t- Uboot\n\t- 编译\nexcerpt: 编译你自己的Linux和uboot\ncategories: Linux\n---\n\n# 一、前言\n\n目前没有前言\n\n# 二、准备工作\n\n准备太久了\n\n# 三、PCB绘制\n\n不是我绘制的\n\n# 四、下载编译工具链\n\n我下的是`arm-linux-gnueabi-`\n\n# 五、u-boot移植\n\n## 1、下载`u-boot`\n\n```shell\ngit clone https://github.com/Lichee-Pi/u-boot.git\ngit branch -a  # 查看分支，我们使用的是nano-v2018.01u-boot\ngit checkout nano-v2018.01u-boot  # 切换到nano-v2018.01u-boot这个分支\n```\n\n## 2、选取`config`配置\n\n考虑到水平有限，我们采用从现有的配置上进行更改。或者，我完全不进行更改，就直接使用了。\n\n### *对几个config简单介绍：*\n\n>`f1c100s_nano_uboot_defconfig`：`SPI Flash`支持版\n>\n>`licheepi_nano_defconfig`：不带`SPI Flash`，从`TF`卡启动\n>\n>`licheepi_nano_spiflash_defconfig`：从`SPI`设备启动\n\n其实上面三种我也分不清楚，我第一次采用的是 `licheepi_nano_defconfig`。我也找不到 `f1c100s_nano_uboot_defconfig`，但是在[这](https://gitee.com/LicheePiNano/u-boot)可以找到，这个是荔枝派的 `u-boot`，可能毕竟这款 `f1c100s`是国产芯片，在`GitHub`上面找不到。\n\n### 选取`config`操作\n\n```shell\ncd ~/u-boot  # 切换到 下载的 u-boot 的根目录\nmake ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- licheepi_nano_defconfig  \n# 参数介绍：\n# ARCH=arm 是arm架构的\n# CROSS_COMPILE=arm-linux-gnueabi-  是之前的下载的编译工具链\n# licheepi_nano_defconfig 选取的默认config\n```\n\n## 3、可视化配置\n\n### 打开菜单命令\n\n```shell\nmake ARCH=arm menuconfig\n# 之后上下键进行移动\n# 空格或者回车进行选择\n# 左右可以选择下方菜单\n# ctrl+退格才能删除已经填入的默认参数\n```\n\n### 参数讲解\n\n注意下面这两个参数就行\n\n![image-20220305195147976](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958695.png)\n\n#### `boot arguments`\n\n> - `console=ttyS0,115200 panic=5 rootwait root=/dev/mmcblk0p2 earlyprintk rw`\n>\n> > **`console=ttyS0,115200`** 表示终端为ttyS0即串口0,波特率为115200；\n> >\n> > **`panic=5` **字面意思是恐慌，即linux内核恐慌，其实就是linux不知道怎么执行了，此时内核就需要做一些相关的处理，这里的5表示超时时间，当Linux卡住5秒后仍未成功就会执行Linux恐慌异常的一些操作。\n> >\n> > `rootwait` 该参数是告诉内核挂在文件系统之前需要先加载相关驱动，这样做的目的是防止因mmc驱动还未加载就开始挂载驱动而导致文件系统挂载失败，所以一般bootargs中都要加上这个参数。\n> >\n> > **root=/dev/mmcblk0p2** 表示根文件系统的位置在mmc的0:2分区处，**/dev**是设备文件夹，内核在加载mmc中的时候就会在根文件系统中生成**mmcblk0p2**设备文件，这个设备文件其实就是mmc的0:2分区(这里对应TF卡的第二个分区：rootfs)，这样内核对文件系统的读写操作方式本质上就是读写/dev/mmcblk0p2该设备文件。\n> >\n> > **`earlyprintk`** 参数是指在内核加载的过程中打印输出信息，这样内核在加载的时候终端就会输出相应的启动信息。rw表示文件系统的操作属性，此处rw表示可读可写。\n\n#### `bootcmd`\n\n> - `load mmc 0:1 0x80008000 zImage;load mmc 0:1 0x80c08000 suniv-f1c100s-licheepi-nano.dtb;bootz 0x80008000 - 0x80c08000;`\n>\n> > ![image-20220305195531843](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051959333.png)\n\n\n\n## 、遇到问题不要慌\n\n### （1）` execute 'swig'`\n\n> 没有`swig`这个东西，安装即可：`sudo apt install swig`\n>\n> `swig`：我从[网上](https://zh.wikipedia.org/wiki/SWIG)了解到是一个将`C/C++`的类封装成库，给`Python、Lua、PHP`等脚本语言调用。（题外话）\n\n## 、参考链接\n\n> [参考博客](https://cnblogs.com/twzy/p/14865952.html)\n>\n> [参考荔枝派](https://wiki.sipeed.com/soft/Lichee/zh/Nano-Doc-Backup/get_started/first_eat.html)![image-20220305205126696](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051959649.png)\n\n# 六、`Linux`的移植\n\n## 1、分区操作\n\n​\t一个硬盘对于`Linux`来说，需要进行**挂载**命令是：`mount`，一般插上自动挂载），然后再能使用，然后需要**卸载**（命令：`umount`）才能操作，如格式化，分区之类的。我们借助了`Ubuntu`下图形化工具——**`Gparted`**，命令行进行下载就行了。\n\n​\t然后，买到手的`sd`卡，可能已经分区了，有一个主分区。如果没法删除，或者进场出现例如*`/dev/sdb contains a mounted filesystem`*，我的建议，使用一个全0的映像文件写入`sd`卡，将前面的数据覆盖。\n\n​\t之后便是分区了，将只有一个未分区的，且没有任何分区的`sd`卡连接`Ubuntu`。\n\n### 分区1、`boot`\n\n> 新建一个分区\n>\n> 之前剩余空间为**1M**，新大小为**32M**，文件系统为**`fat16`**，卷标就设置为**`boot`**\n>\n> 对于之前的`1M`，是留给**`uboot`**的，而且在`gparted`是看不到的\n>\n> **图片来源于网络**\n>\n> ![image-20220314221728714](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958740.png)\n\n### 分区2、`rootfs`\n\n> 新建一个分区\n>\n> 之前剩余空间为**0M**，新大小为**100M**，文件系统为**`ext4`**，卷标就设置为**`rootfs`**\n>\n> ***图片来源于网络***\n>\n> ![image-20220314221807562](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958803.png)\n\n### 最后的效果\n\n![image-20220314221850652](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958789.png)\n\n## 2、编译**`Linux`**\n\n### 更改设备树\n\n# 七、编译`rootfs`\n\n","slug":"编译Linux与Uboot","published":1,"updated":"2022-04-05T12:06:16.028Z","_id":"cl1m3fohp0000k4u50nm422aa","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"一、前言\"><a href=\"#一、前言\" class=\"headerlink\" title=\"一、前言\"></a>一、前言</h1><p>目前没有前言</p>\n<h1 id=\"二、准备工作\"><a href=\"#二、准备工作\" class=\"headerlink\" title=\"二、准备工作\"></a>二、准备工作</h1><p>准备太久了</p>\n<h1 id=\"三、PCB绘制\"><a href=\"#三、PCB绘制\" class=\"headerlink\" title=\"三、PCB绘制\"></a>三、PCB绘制</h1><p>不是我绘制的</p>\n<h1 id=\"四、下载编译工具链\"><a href=\"#四、下载编译工具链\" class=\"headerlink\" title=\"四、下载编译工具链\"></a>四、下载编译工具链</h1><p>我下的是<code>arm-linux-gnueabi-</code></p>\n<h1 id=\"五、u-boot移植\"><a href=\"#五、u-boot移植\" class=\"headerlink\" title=\"五、u-boot移植\"></a>五、u-boot移植</h1><h2 id=\"1、下载u-boot\"><a href=\"#1、下载u-boot\" class=\"headerlink\" title=\"1、下载u-boot\"></a>1、下载<code>u-boot</code></h2><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/Lichee-Pi/u-boot.git</span><br><span class=\"line\">git branch -a  # 查看分支，我们使用的是nano-v2018.01u-boot</span><br><span class=\"line\">git checkout nano-v2018.01u-boot  # 切换到nano-v2018.01u-boot这个分支</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2、选取config配置\"><a href=\"#2、选取config配置\" class=\"headerlink\" title=\"2、选取config配置\"></a>2、选取<code>config</code>配置</h2><p>考虑到水平有限，我们采用从现有的配置上进行更改。或者，我完全不进行更改，就直接使用了。</p>\n<h3 id=\"对几个config简单介绍：\"><a href=\"#对几个config简单介绍：\" class=\"headerlink\" title=\"对几个config简单介绍：\"></a><em>对几个config简单介绍：</em></h3><blockquote>\n<p><code>f1c100s_nano_uboot_defconfig</code>：<code>SPI Flash</code>支持版</p>\n<p><code>licheepi_nano_defconfig</code>：不带<code>SPI Flash</code>，从<code>TF</code>卡启动</p>\n<p><code>licheepi_nano_spiflash_defconfig</code>：从<code>SPI</code>设备启动</p>\n</blockquote>\n<p>其实上面三种我也分不清楚，我第一次采用的是 <code>licheepi_nano_defconfig</code>。我也找不到 <code>f1c100s_nano_uboot_defconfig</code>，但是在<a href=\"https://gitee.com/LicheePiNano/u-boot\">这</a>可以找到，这个是荔枝派的 <code>u-boot</code>，可能毕竟这款 <code>f1c100s</code>是国产芯片，在<code>GitHub</code>上面找不到。</p>\n<h3 id=\"选取config操作\"><a href=\"#选取config操作\" class=\"headerlink\" title=\"选取config操作\"></a>选取<code>config</code>操作</h3><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">cd ~/u-boot  # 切换到 下载的 u-boot 的根目录</span><br><span class=\"line\">make ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- licheepi_nano_defconfig  </span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">参数介绍：</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">ARCH=arm 是arm架构的</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">CROSS_COMPILE=arm-linux-gnueabi-  是之前的下载的编译工具链</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">licheepi_nano_defconfig 选取的默认config</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3、可视化配置\"><a href=\"#3、可视化配置\" class=\"headerlink\" title=\"3、可视化配置\"></a>3、可视化配置</h2><h3 id=\"打开菜单命令\"><a href=\"#打开菜单命令\" class=\"headerlink\" title=\"打开菜单命令\"></a>打开菜单命令</h3><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">make ARCH=arm menuconfig</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">之后上下键进行移动</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">空格或者回车进行选择</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">左右可以选择下方菜单</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">ctrl+退格才能删除已经填入的默认参数</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"参数讲解\"><a href=\"#参数讲解\" class=\"headerlink\" title=\"参数讲解\"></a>参数讲解</h3><p>注意下面这两个参数就行</p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958695.png\" alt=\"image-20220305195147976\"></p>\n<h4 id=\"boot-arguments\"><a href=\"#boot-arguments\" class=\"headerlink\" title=\"boot arguments\"></a><code>boot arguments</code></h4><blockquote>\n<ul>\n<li><code>console=ttyS0,115200 panic=5 rootwait root=/dev/mmcblk0p2 earlyprintk rw</code></li>\n</ul>\n<blockquote>\n<p><strong><code>console=ttyS0,115200</code></strong> 表示终端为ttyS0即串口0,波特率为115200；</p>\n<p>**<code>panic=5</code> **字面意思是恐慌，即linux内核恐慌，其实就是linux不知道怎么执行了，此时内核就需要做一些相关的处理，这里的5表示超时时间，当Linux卡住5秒后仍未成功就会执行Linux恐慌异常的一些操作。</p>\n<p><code>rootwait</code> 该参数是告诉内核挂在文件系统之前需要先加载相关驱动，这样做的目的是防止因mmc驱动还未加载就开始挂载驱动而导致文件系统挂载失败，所以一般bootargs中都要加上这个参数。</p>\n<p><strong>root&#x3D;&#x2F;dev&#x2F;mmcblk0p2</strong> 表示根文件系统的位置在mmc的0:2分区处，**&#x2F;dev<strong>是设备文件夹，内核在加载mmc中的时候就会在根文件系统中生成</strong>mmcblk0p2**设备文件，这个设备文件其实就是mmc的0:2分区(这里对应TF卡的第二个分区：rootfs)，这样内核对文件系统的读写操作方式本质上就是读写&#x2F;dev&#x2F;mmcblk0p2该设备文件。</p>\n<p><strong><code>earlyprintk</code></strong> 参数是指在内核加载的过程中打印输出信息，这样内核在加载的时候终端就会输出相应的启动信息。rw表示文件系统的操作属性，此处rw表示可读可写。</p>\n</blockquote>\n</blockquote>\n<h4 id=\"bootcmd\"><a href=\"#bootcmd\" class=\"headerlink\" title=\"bootcmd\"></a><code>bootcmd</code></h4><blockquote>\n<ul>\n<li><code>load mmc 0:1 0x80008000 zImage;load mmc 0:1 0x80c08000 suniv-f1c100s-licheepi-nano.dtb;bootz 0x80008000 - 0x80c08000;</code></li>\n</ul>\n<blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051959333.png\" alt=\"image-20220305195531843\"></p>\n</blockquote>\n</blockquote>\n<h2 id=\"、遇到问题不要慌\"><a href=\"#、遇到问题不要慌\" class=\"headerlink\" title=\"、遇到问题不要慌\"></a>、遇到问题不要慌</h2><h3 id=\"（1）-execute-39-swig-39\"><a href=\"#（1）-execute-39-swig-39\" class=\"headerlink\" title=\"（1） execute &#39;swig&#39;\"></a>（1）<code> execute &#39;swig&#39;</code></h3><blockquote>\n<p>没有<code>swig</code>这个东西，安装即可：<code>sudo apt install swig</code></p>\n<p><code>swig</code>：我从<a href=\"https://zh.wikipedia.org/wiki/SWIG\">网上</a>了解到是一个将<code>C/C++</code>的类封装成库，给<code>Python、Lua、PHP</code>等脚本语言调用。（题外话）</p>\n</blockquote>\n<h2 id=\"、参考链接\"><a href=\"#、参考链接\" class=\"headerlink\" title=\"、参考链接\"></a>、参考链接</h2><blockquote>\n<p><a href=\"https://cnblogs.com/twzy/p/14865952.html\">参考博客</a></p>\n<p><a href=\"https://wiki.sipeed.com/soft/Lichee/zh/Nano-Doc-Backup/get_started/first_eat.html\">参考荔枝派</a><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051959649.png\" alt=\"image-20220305205126696\"></p>\n</blockquote>\n<h1 id=\"六、Linux的移植\"><a href=\"#六、Linux的移植\" class=\"headerlink\" title=\"六、Linux的移植\"></a>六、<code>Linux</code>的移植</h1><h2 id=\"1、分区操作\"><a href=\"#1、分区操作\" class=\"headerlink\" title=\"1、分区操作\"></a>1、分区操作</h2><p>​    一个硬盘对于<code>Linux</code>来说，需要进行<strong>挂载</strong>命令是：<code>mount</code>，一般插上自动挂载），然后再能使用，然后需要<strong>卸载</strong>（命令：<code>umount</code>）才能操作，如格式化，分区之类的。我们借助了<code>Ubuntu</code>下图形化工具——**<code>Gparted</code>**，命令行进行下载就行了。</p>\n<p>​    然后，买到手的<code>sd</code>卡，可能已经分区了，有一个主分区。如果没法删除，或者进场出现例如*<code>/dev/sdb contains a mounted filesystem</code>*，我的建议，使用一个全0的映像文件写入<code>sd</code>卡，将前面的数据覆盖。</p>\n<p>​    之后便是分区了，将只有一个未分区的，且没有任何分区的<code>sd</code>卡连接<code>Ubuntu</code>。</p>\n<h3 id=\"分区1、boot\"><a href=\"#分区1、boot\" class=\"headerlink\" title=\"分区1、boot\"></a>分区1、<code>boot</code></h3><blockquote>\n<p>新建一个分区</p>\n<p>之前剩余空间为<strong>1M</strong>，新大小为<strong>32M</strong>，文件系统为**<code>fat16</code><strong>，卷标就设置为</strong><code>boot</code>**</p>\n<p>对于之前的<code>1M</code>，是留给**<code>uboot</code>**的，而且在<code>gparted</code>是看不到的</p>\n<p><strong>图片来源于网络</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958740.png\" alt=\"image-20220314221728714\"></p>\n</blockquote>\n<h3 id=\"分区2、rootfs\"><a href=\"#分区2、rootfs\" class=\"headerlink\" title=\"分区2、rootfs\"></a>分区2、<code>rootfs</code></h3><blockquote>\n<p>新建一个分区</p>\n<p>之前剩余空间为<strong>0M</strong>，新大小为<strong>100M</strong>，文件系统为**<code>ext4</code><strong>，卷标就设置为</strong><code>rootfs</code>**</p>\n<p><em><strong>图片来源于网络</strong></em></p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958803.png\" alt=\"image-20220314221807562\"></p>\n</blockquote>\n<h3 id=\"最后的效果\"><a href=\"#最后的效果\" class=\"headerlink\" title=\"最后的效果\"></a>最后的效果</h3><p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958789.png\" alt=\"image-20220314221850652\"></p>\n<h2 id=\"2、编译-Linux\"><a href=\"#2、编译-Linux\" class=\"headerlink\" title=\"2、编译**Linux**\"></a>2、编译**<code>Linux</code>**</h2><h3 id=\"更改设备树\"><a href=\"#更改设备树\" class=\"headerlink\" title=\"更改设备树\"></a>更改设备树</h3><h1 id=\"七、编译rootfs\"><a href=\"#七、编译rootfs\" class=\"headerlink\" title=\"七、编译rootfs\"></a>七、编译<code>rootfs</code></h1>","site":{"data":{}},"more":"<h1 id=\"一、前言\"><a href=\"#一、前言\" class=\"headerlink\" title=\"一、前言\"></a>一、前言</h1><p>目前没有前言</p>\n<h1 id=\"二、准备工作\"><a href=\"#二、准备工作\" class=\"headerlink\" title=\"二、准备工作\"></a>二、准备工作</h1><p>准备太久了</p>\n<h1 id=\"三、PCB绘制\"><a href=\"#三、PCB绘制\" class=\"headerlink\" title=\"三、PCB绘制\"></a>三、PCB绘制</h1><p>不是我绘制的</p>\n<h1 id=\"四、下载编译工具链\"><a href=\"#四、下载编译工具链\" class=\"headerlink\" title=\"四、下载编译工具链\"></a>四、下载编译工具链</h1><p>我下的是<code>arm-linux-gnueabi-</code></p>\n<h1 id=\"五、u-boot移植\"><a href=\"#五、u-boot移植\" class=\"headerlink\" title=\"五、u-boot移植\"></a>五、u-boot移植</h1><h2 id=\"1、下载u-boot\"><a href=\"#1、下载u-boot\" class=\"headerlink\" title=\"1、下载u-boot\"></a>1、下载<code>u-boot</code></h2><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/Lichee-Pi/u-boot.git</span><br><span class=\"line\">git branch -a  # 查看分支，我们使用的是nano-v2018.01u-boot</span><br><span class=\"line\">git checkout nano-v2018.01u-boot  # 切换到nano-v2018.01u-boot这个分支</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2、选取config配置\"><a href=\"#2、选取config配置\" class=\"headerlink\" title=\"2、选取config配置\"></a>2、选取<code>config</code>配置</h2><p>考虑到水平有限，我们采用从现有的配置上进行更改。或者，我完全不进行更改，就直接使用了。</p>\n<h3 id=\"对几个config简单介绍：\"><a href=\"#对几个config简单介绍：\" class=\"headerlink\" title=\"对几个config简单介绍：\"></a><em>对几个config简单介绍：</em></h3><blockquote>\n<p><code>f1c100s_nano_uboot_defconfig</code>：<code>SPI Flash</code>支持版</p>\n<p><code>licheepi_nano_defconfig</code>：不带<code>SPI Flash</code>，从<code>TF</code>卡启动</p>\n<p><code>licheepi_nano_spiflash_defconfig</code>：从<code>SPI</code>设备启动</p>\n</blockquote>\n<p>其实上面三种我也分不清楚，我第一次采用的是 <code>licheepi_nano_defconfig</code>。我也找不到 <code>f1c100s_nano_uboot_defconfig</code>，但是在<a href=\"https://gitee.com/LicheePiNano/u-boot\">这</a>可以找到，这个是荔枝派的 <code>u-boot</code>，可能毕竟这款 <code>f1c100s</code>是国产芯片，在<code>GitHub</code>上面找不到。</p>\n<h3 id=\"选取config操作\"><a href=\"#选取config操作\" class=\"headerlink\" title=\"选取config操作\"></a>选取<code>config</code>操作</h3><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">cd ~/u-boot  # 切换到 下载的 u-boot 的根目录</span><br><span class=\"line\">make ARCH=arm CROSS_COMPILE=arm-linux-gnueabi- licheepi_nano_defconfig  </span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">参数介绍：</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">ARCH=arm 是arm架构的</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">CROSS_COMPILE=arm-linux-gnueabi-  是之前的下载的编译工具链</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">licheepi_nano_defconfig 选取的默认config</span></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3、可视化配置\"><a href=\"#3、可视化配置\" class=\"headerlink\" title=\"3、可视化配置\"></a>3、可视化配置</h2><h3 id=\"打开菜单命令\"><a href=\"#打开菜单命令\" class=\"headerlink\" title=\"打开菜单命令\"></a>打开菜单命令</h3><figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">make ARCH=arm menuconfig</span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">之后上下键进行移动</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">空格或者回车进行选择</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">左右可以选择下方菜单</span></span><br><span class=\"line\"><span class=\"meta prompt_\"># </span><span class=\"language-bash\">ctrl+退格才能删除已经填入的默认参数</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"参数讲解\"><a href=\"#参数讲解\" class=\"headerlink\" title=\"参数讲解\"></a>参数讲解</h3><p>注意下面这两个参数就行</p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958695.png\" alt=\"image-20220305195147976\"></p>\n<h4 id=\"boot-arguments\"><a href=\"#boot-arguments\" class=\"headerlink\" title=\"boot arguments\"></a><code>boot arguments</code></h4><blockquote>\n<ul>\n<li><code>console=ttyS0,115200 panic=5 rootwait root=/dev/mmcblk0p2 earlyprintk rw</code></li>\n</ul>\n<blockquote>\n<p><strong><code>console=ttyS0,115200</code></strong> 表示终端为ttyS0即串口0,波特率为115200；</p>\n<p>**<code>panic=5</code> **字面意思是恐慌，即linux内核恐慌，其实就是linux不知道怎么执行了，此时内核就需要做一些相关的处理，这里的5表示超时时间，当Linux卡住5秒后仍未成功就会执行Linux恐慌异常的一些操作。</p>\n<p><code>rootwait</code> 该参数是告诉内核挂在文件系统之前需要先加载相关驱动，这样做的目的是防止因mmc驱动还未加载就开始挂载驱动而导致文件系统挂载失败，所以一般bootargs中都要加上这个参数。</p>\n<p><strong>root&#x3D;&#x2F;dev&#x2F;mmcblk0p2</strong> 表示根文件系统的位置在mmc的0:2分区处，**&#x2F;dev<strong>是设备文件夹，内核在加载mmc中的时候就会在根文件系统中生成</strong>mmcblk0p2**设备文件，这个设备文件其实就是mmc的0:2分区(这里对应TF卡的第二个分区：rootfs)，这样内核对文件系统的读写操作方式本质上就是读写&#x2F;dev&#x2F;mmcblk0p2该设备文件。</p>\n<p><strong><code>earlyprintk</code></strong> 参数是指在内核加载的过程中打印输出信息，这样内核在加载的时候终端就会输出相应的启动信息。rw表示文件系统的操作属性，此处rw表示可读可写。</p>\n</blockquote>\n</blockquote>\n<h4 id=\"bootcmd\"><a href=\"#bootcmd\" class=\"headerlink\" title=\"bootcmd\"></a><code>bootcmd</code></h4><blockquote>\n<ul>\n<li><code>load mmc 0:1 0x80008000 zImage;load mmc 0:1 0x80c08000 suniv-f1c100s-licheepi-nano.dtb;bootz 0x80008000 - 0x80c08000;</code></li>\n</ul>\n<blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051959333.png\" alt=\"image-20220305195531843\"></p>\n</blockquote>\n</blockquote>\n<h2 id=\"、遇到问题不要慌\"><a href=\"#、遇到问题不要慌\" class=\"headerlink\" title=\"、遇到问题不要慌\"></a>、遇到问题不要慌</h2><h3 id=\"（1）-execute-39-swig-39\"><a href=\"#（1）-execute-39-swig-39\" class=\"headerlink\" title=\"（1） execute &#39;swig&#39;\"></a>（1）<code> execute &#39;swig&#39;</code></h3><blockquote>\n<p>没有<code>swig</code>这个东西，安装即可：<code>sudo apt install swig</code></p>\n<p><code>swig</code>：我从<a href=\"https://zh.wikipedia.org/wiki/SWIG\">网上</a>了解到是一个将<code>C/C++</code>的类封装成库，给<code>Python、Lua、PHP</code>等脚本语言调用。（题外话）</p>\n</blockquote>\n<h2 id=\"、参考链接\"><a href=\"#、参考链接\" class=\"headerlink\" title=\"、参考链接\"></a>、参考链接</h2><blockquote>\n<p><a href=\"https://cnblogs.com/twzy/p/14865952.html\">参考博客</a></p>\n<p><a href=\"https://wiki.sipeed.com/soft/Lichee/zh/Nano-Doc-Backup/get_started/first_eat.html\">参考荔枝派</a><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051959649.png\" alt=\"image-20220305205126696\"></p>\n</blockquote>\n<h1 id=\"六、Linux的移植\"><a href=\"#六、Linux的移植\" class=\"headerlink\" title=\"六、Linux的移植\"></a>六、<code>Linux</code>的移植</h1><h2 id=\"1、分区操作\"><a href=\"#1、分区操作\" class=\"headerlink\" title=\"1、分区操作\"></a>1、分区操作</h2><p>​    一个硬盘对于<code>Linux</code>来说，需要进行<strong>挂载</strong>命令是：<code>mount</code>，一般插上自动挂载），然后再能使用，然后需要<strong>卸载</strong>（命令：<code>umount</code>）才能操作，如格式化，分区之类的。我们借助了<code>Ubuntu</code>下图形化工具——**<code>Gparted</code>**，命令行进行下载就行了。</p>\n<p>​    然后，买到手的<code>sd</code>卡，可能已经分区了，有一个主分区。如果没法删除，或者进场出现例如*<code>/dev/sdb contains a mounted filesystem</code>*，我的建议，使用一个全0的映像文件写入<code>sd</code>卡，将前面的数据覆盖。</p>\n<p>​    之后便是分区了，将只有一个未分区的，且没有任何分区的<code>sd</code>卡连接<code>Ubuntu</code>。</p>\n<h3 id=\"分区1、boot\"><a href=\"#分区1、boot\" class=\"headerlink\" title=\"分区1、boot\"></a>分区1、<code>boot</code></h3><blockquote>\n<p>新建一个分区</p>\n<p>之前剩余空间为<strong>1M</strong>，新大小为<strong>32M</strong>，文件系统为**<code>fat16</code><strong>，卷标就设置为</strong><code>boot</code>**</p>\n<p>对于之前的<code>1M</code>，是留给**<code>uboot</code>**的，而且在<code>gparted</code>是看不到的</p>\n<p><strong>图片来源于网络</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958740.png\" alt=\"image-20220314221728714\"></p>\n</blockquote>\n<h3 id=\"分区2、rootfs\"><a href=\"#分区2、rootfs\" class=\"headerlink\" title=\"分区2、rootfs\"></a>分区2、<code>rootfs</code></h3><blockquote>\n<p>新建一个分区</p>\n<p>之前剩余空间为<strong>0M</strong>，新大小为<strong>100M</strong>，文件系统为**<code>ext4</code><strong>，卷标就设置为</strong><code>rootfs</code>**</p>\n<p><em><strong>图片来源于网络</strong></em></p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958803.png\" alt=\"image-20220314221807562\"></p>\n</blockquote>\n<h3 id=\"最后的效果\"><a href=\"#最后的效果\" class=\"headerlink\" title=\"最后的效果\"></a>最后的效果</h3><p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204051958789.png\" alt=\"image-20220314221850652\"></p>\n<h2 id=\"2、编译-Linux\"><a href=\"#2、编译-Linux\" class=\"headerlink\" title=\"2、编译**Linux**\"></a>2、编译**<code>Linux</code>**</h2><h3 id=\"更改设备树\"><a href=\"#更改设备树\" class=\"headerlink\" title=\"更改设备树\"></a>更改设备树</h3><h1 id=\"七、编译rootfs\"><a href=\"#七、编译rootfs\" class=\"headerlink\" title=\"七、编译rootfs\"></a>七、编译<code>rootfs</code></h1>"},{"title":"Python爬虫学习","cover":"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052015303.png","date":"2022-04-05T12:07:16.000Z","excerpt":"爬虫是个好东西，轻易的下到别人下不到的东西","_content":"\n## 1、`requests`模块的使用\n\n> **response的用法**\n>\n> ```python\n> # ====== 1、基础知识  ======== #\n> import requests\n> url = \"http://www.baidu.com\"\n> response = requests.get(url)\n> print(respones.text)\t\t\t# 注意，text这个变量是默认解码过的，根据内容自动猜测的解码，str类数据\n> print(response.content.decode())   \t\n> # content是没有解码的，bytes数据，默认用utf-8解码，也可以指定gbk解码，如decode('gbk')\n> # 常见的解码方式：utf-8，gbk，gb2312，ascii，iso-8859-1\n> # 有些平台可能上述都不行，那就用bytes存储就好\n> print(responst.encoding)\t\t\t# 推测的遍码格式\n> \n> # 当然可以先设置encoding\n> response.encoding = \"utf8\"   # 注意不是写成 utf-8\n> print(response.text)   # 即可按照utf-8解码\n> \n> \n> \n> # ====== 2、常见的对象参数和方法  ======== #\n> # 响应的url\n> print(response.url)  \n> \n> # 状态码（一般来说，不要相信）\n> print(response.status_code)\n> \n> # 响应对应的请求头\n> print(response.request.headers)\n> \n> # 响应头\n> print(response.headers)\n> \n> # 响应对应请求的cookie 返回cookieJar类型\n> print(response.request._cookies)\n> \n> # 响应的cookie\n> print(response.cookies)\n> \n> # 自动将json字符串类型的响应内容转换成python对象\n> print(response.json())\n> \n> ```\n\n> **关闭代理**\n>\n> > ```python\n> > proxies = {\"http\": None, \"https\": None}\n> > response = rq.get(url, headers=headers, verify=False, proxies=proxies) # 关闭代理，关闭ssl认证\n> > ```\n> >\n> > \n\n---\n\n## 2、浏览器中的操作合集（可切换成无痕有痕分别都操作，带入多种数值操作）\n\n> **获取所有数据，勾选`All`**\n>\n> > ![image-20211201095759608](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052011268.png)\n>\n> **登录或者其他导致页面自动跳转，那么抓的包会刷新，勾选下面这个就不会刷新**\n>\n> > ![image-20211201205357600](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008211.png)\n>\n> **查看请求数据和响应数据**\n>\n> > ![image-20211201195017543](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008042.png)\n>\n> **关于请求头的一些参数意义**\n>\n> > `Referer`：这个是解释从哪个网站跳转的\n> >\n> > `User-Agent`：包含了请求主机的信息，包括系统信息和浏览器信息，如果要伪装成浏览器，这个参数很重要\n> >\n> > `Cookie`：这个分为`请求cookie`和`响应cookie`，分开使用\n> >\n> > `host`：请求域名\n> >\n> > `Connection`：是否保持连接，例如`keep-alive`，`close`\n> >\n> > `Upgrade-Insecure-Requests`：升级为`https`\n>\n> **关于响应头的一些参数意义** - 响应头一般是返回参数，主要看请求头\n>\n> > `Set-Cookie`：设置的`cookie`\n> >\n> > 状态码：200表示成功，但是，一般不要关注状态码，因为其不可信\n>\n> **常见的单词意义**\n>\n> > `token`：这个是一般为了保持的浏览器的连接性\n>\n> **注意事项**\n>\n> > 上面的`host`是域名，不一定是请求`url`，请求url看下面图\n> >\n> > > ![image-20211201194750582](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008032.png)\n>\n> **其他帮助网站合集**\n>\n> > - [在线字符串转`json`](https://www.json.cn/)\n> >\n> > - **免费代理站点**\n> >\n> >   > [国内免费代理站点1](https://www.kuaidaili.com/free/)\n> >   >\n> >   > [国内免费代理站点2](https://proxy.mimvp.com/freeopen)\n> >   >\n> >   > [国内免费代理站点3](https://www.89ip.cn/index.html)\n> >\n> > - \n\n## 3、爬虫入门一\n\n> **注意请求头中的一些参数**\n>\n> - `User-Agent`：包含了很多参数，如浏览器数据，系统数据等\n>\n> > ```python\n> > headers = {\n> >   'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36'  # 最好不要加到这一行的值，因为会报错，不明白为什么\n> > }\n> > headers = {\n> >   'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)'\n> > }\n> > response1 = requests.get(url, headers=headers)\n> > ```\n>\n> **发送带参数的请求**\n>\n> - `url`直接带参数\n>\n> > ```python\n> > # http://www.baidu.com/s?ie=utf-8&f=8&rsv_bp=1&rsv_idx=1&tn=baidu&wd=python&fenlei=256&rsv_pq=8cb91fd5000035bd&rsv_t=368aR6DDwiiYX59pfDu4vQz2%2FajgsJuSG4IS8mBB5GeZwSo6Sn%2BjQuytYZM&rqlang=cn&rsv_enter=1&rsv_dl=tb&rsv_sug3=9&rsv_sug1=7&rsv_sug7=101&rsv_sug2=0&rsv_btype=i&prefixsug=python&rsp=5&inputT=2667&rsv_sug4=6046\n> > \n> > # 如上面这个连接，可以尝试删掉一下不要的参数，最终得到下面这个\n> > # http://www.baidu.com/s?wd=python\n> > # 这个才是关键，然后进行get请求\n> > url = 'http://www.baidu.com/s?wd=python'\n> > headers = {\n> >     'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)'\n> > }\n> > ##  注意，get请求不要使用https\n> > response = requests.get(url, headers=headers)\n> > ```\n>\n> - 使用`params`携带参数字典\n>\n> > ```python\n> > url = 'http://www.baidu.com/s?'  # 注意这里需要加上s?，这个是百度的特性\n> > data = {\n> >  'wd': 'python'\n> > }\n> > heads = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)'}\n> > response = requests.get(url, params=data, headers=heads)\n> > ```\n>\n> **携带`cookie`信息，`cookie`一般有时效性，过段时间需要重新获取**\n>\n> - 以`github`为列\n>\n> > 见下列图片，浏览器抓包\n> >\n> > ![image-20211201111147337](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008253.png)\n>\n> - 在`headers`携带\n>\n> > ```python\n> > headers={\n> >  'cookie': 'xxxx',\n> >  'User-Agent': 'xxxx'\n> > }\n> > \n> > ```\n>\n> - 使用`cookie`参数来保持\n>\n> > ```python\n> > # 构建cookie字典\n> > # 需要先切割键值对\n> > # 如下列cookie\n> > cookies = '_octo=GH1.1.612724434.1638322138; tz=Asia/Shanghai; _device_id=5fa9f396b9f0691f8db3054f0b87dbb9; has_recent_activity=1; user_session=03yOITMxPd4lG6qXwYYs9QEaFPgu2hxw04gHIymweU4J1EEe; __Host-user_session_same_site=03yOITMxPd4lG6qXwYYs9QEaFPgu2hxw04gHIymweU4J1EEe; tz=Asia/Shanghai; color_mode={\"color_mode\":\"auto\",\"light_theme\":{\"name\":\"light\",\"color_mode\":\"light\"},\"dark_theme\":{\"name\":\"dark\",\"color_mode\":\"dark\"}}; logged_in=yes; dotcom_user=HF-Mfeng; _gh_sess=Bvk3bQRV+XfUQlh+l8Mu2MKWcl7O+LH3nLtnVSWOFvzAo50NycqAlQFAYbNMdXfpVAxSU08+65qeCVG2+wX97z/sjsdsI2grX7uXpIWvFpAi/pOBPyt4dXjNRT5n2o2VTvCgIP2mWQEXTg7HVjs3v16QCj/eUFbd460btIb6J1NG/DY1wW7jx8/VAS2vkFVZ7uTkoljKQdcs8K7oAndejxw7f3fdBKCybeghEIqu71SonF5C774enN5nq2zNtSILtA7lEA+s72ekWtLrFkzRpAoi+rzQLR2naFzIXCuFbbCdsLj7tNRAF8Uj0vyRn29LdqxbjMsssMmiiBVi81x3Vf7awZRHhjp2jzMINq+J3grHfOyjgwer1XRXkUW4RaIayrC60XOl/NG5tOPUmPCHqDkHhAyFx3TRVxhz84a+oxBSW9PJK4ebYu2sZrA3nCOdRkPDvEoMehgxhZuOz07e8usCuKc//p/tozi/WI+CuPWjYamF3Hyv1uYt4C1sKjZbhNzH3sjd+9hD5DP33IROZWlvCM4W2PWmq6RWyC5B1Dyk8pAq89W87dsdm5W2eyMo/xNLdwZi+o8cXkJROi8W/XQa6NwRWlh9yON+xl3L9Txtesvi3mlB7b1L+ic/XR4f7Wh8C59yeyY67lijumG/qfX0F8w3H76BPnlmbH9oxL4qRkWwVSflal4LjRhgOaoiCZzs1r6oellyNV6pPilm7QRbP7KEnq+R+PusPQsDBWn4Gej/vbQ2P9cwqW9EQr+VhsV6MHUvhuGAY8MRB5eBKtxrhqXZMiLYak0Pk82cl9oesvU5tqp3xNo2VNHWXt5uM6YLQTggbG+spmuxqnbHt481AoMUNnRcN6WomLZ4vS4pYXO5NLa58uk9slgT/3iwPEWsy7HuK5FLYqcMvPTGNeO+nYs=--c91BUqTy9ZXXOfRr--YhanrwguBRPMP5S/I3ig0A=='\n> > cookies = cookies.splie(\"; \")\n> > cookies_ = {}\n> > for cookie in cookies:\n> >  cookies_[cookie.split('=')[0]] = cookie.splie('=')[-1]\n> > \n> > # 其中有许多的等号，如_octo=GH1.1.612724434.1638322138，就是一个键值对\n> > respose = requests.get(url,headers=headers,cookies=cookies_)\n> > ```\n>\n> - `cookieJar`对象转换成`cookie`字典，一般用不到\n>\n> > ```python\n> > # 什么是cookieJar对象呢，如下\n> > requests.get(url).cookie\t\t# 这个就是cookieJar对象\n> > dict_cookies = requests.utils.dict_from_cookiejar(response.cookies)   # cookiejar转换成字典\n> > \n> > jar_cookies = requests.utils.cookiesjar_from_dict(dict_cookies)  # 重新转化成cookiejar\n> > \n> > ```\n>\n> **`timeout`的用法**\n>\n> - 设置一下\n>\n> > ```python\n> > wresponse = requests.get(url, timeout=3)  # 设为3s，一般设个十秒左右就好\n> > ```\n> >\n> > \n>\n> **代理`Proxy`**\n>\n> > 代理分为正向代理和反向代理\n> >\n> > 代理还分为透明代理、匿名代理、高匿代理\n> >\n> > - 透明代理\n> >\n> > > ```python\n> > > REMOTE_ADDR = Proxy IP\n> > > HTTP_VIA = Proxy IP\n> > > HTTP_X_FORWARDED_FOR = Your IP\n> > > ```\n> >\n> > - 匿名代理\n> >\n> > > ```python\n> > > REMOTE_ADDR = Proxy IP\n> > > HTTP_VIA = Proxy IP\n> > > HTTP_X_FORWARDED_FOR = Proxy IP\n> > > ```\n> >\n> > - 高匿代理\n> >\n> > > ```shell\n> > > REMOTE_ADDR = Proxy IP\n> > > HTTP_VIA = not determined\n> > > HTTP_X_FORWARDED_FOR = not determined\n> > > ```\n> >\n> > 代理还可分为，`http、https、socks`\n> >\n> > - `http`：目标`url`为`http`协议\n> > - `https`：目标`url`为`https`协议\n> > - `socks`：只传递数据包，不在乎什么应用协议，耗时少\n> >\n> > **用法**\n> >\n> > > ```python\n> > > proxies = {\n> > >  'http': 'http://127.0.0.1:7890',\n> > >  'https': 'http://127.0.0.1:7890'\n> > > }\n> > > response = requests.get(url, proxies=proxies)\n> > > ```\n> > >\n> > > [国内免费代理站点1](https://www.kuaidaili.com/free/)\n> > >\n> > > [国内免费代理站点2](https://proxy.mimvp.com/freeopen)\n> > >\n> > > [国内免费代理站点3](https://www.89ip.cn/index.html)\n> >\n> > - 并且代理站点可能会给你添加一下信息，使得你更像一个浏览器\n> > - 代理也有可能截获你的数据，所以这个也要注意\n>\n> **`verify`忽略`CA`证书**\n>\n> > 很多情况如下图所示\n> >\n> > > ![image-20211201192347257](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008307.png)\n> >\n> > 爬虫过程遇到下列情况\n> >\n> > > ```python\n> > > requests.exceptions.SSLError: HTTPSConnection.....\n> > > ```\n> >\n> > 设置为`False`即可\n> >\n> > > ```python\n> > > # 默认是True，设置为False\n> > > # 运行过程会报警告的，但是 don't worry it 爬虫还是可以爬取内容的\n> > > response = requests.get(url, verify=False)\n> > > ```\n>\n> **`post`请求**\n>\n> > `post`用途\n> >\n> > - 一般有账号密码，都会使用`post`请求，因为`get`请求是在`url`中的明文\n> > - 大文件以及多数据，都是使用`post`\n> > - `web`工程师会认为`post`比`get`请求更加安全\n> >\n> > 简单实现\n> >\n> > > ```python\n> > > respose = requests.post(url, data) # data是一个字典\n> > > ```\n> >\n> > 找`data`的步骤寻找固定值：一般来说浏览器抓抓包就知道了\n> >\n> > - 寻找输入值：也一般来说浏览器抓抓包就知道了\n> > - 寻找预设值 - 静态文件：一般来说，需要从`html`文件中搜索，可以尝试，这个是反爬的\n> > - 寻找预设值 - 发请求：需要对指定地址发送请求\n> > - 寻找动态生成值：一般是客户端生成的，反爬的重点，一般采用`Javascript`生成\n> >\n> > `data`反爬套路\n> >\n> > - 模仿其他浏览器发送，如手机什么的，因为很多浏览器都是不一样的反爬，找个弱的\n> > - 注意时间戳什么的\n> > - 注意里面的`JS`文件\n> > - 有些可能是随机值\n> > - 从`html`提取，可以试试无痕浏览器\n>\n> **`requess.session`状态保持**\n>\n> - 自动保持`cookie`，一般多次请求（如登录之后再操作的），使用方法\n>\n> > ```python\n> > session = requests.session()\n> > session.headers = {\n> > \n> > }\n> > session.data = {\n> > \n> > }\n> > response = session.get(url)\n> > response = session.post(url)\n> > \n> > # 如下用法\n> > s = rq.session()\n> > s.trust_env\n> > s.verify\n> > s.headers\n> > s.proxies\n> > s.cookies\n> > s.get(url, data=data)\n> > s.post(url, data=data)\n> > ```\n\n## 正则表达式，这个也是重点\n\n> **首先如何使用正则表达式**\n>\n> > ```python\n> > response = requests.get(url)\n> > restr = response.content.decode()   # 转成utf-8或者gbk\n> > # 正则提取\n> > import re  # 导入正则模块\n> > str_tmp = \"<link href=\\\"https://stacdn.proginn.com/plugin/swiper/swiper.min.css?version=4.30.2\\\" rel=\\\"stylesheet\\\" type=\\\"text/css\\\">\"   # 临时字符串，不用写到代码里\n> > # 假如想要获取上面中的href，那么这样写正则表达式\n> > # 正则\n> > restr = '<link href=\\\"(.*?)\\\" rel=\\\"stylesheet\\\" type=\\\"text/css\\\">'   # 这个是以非贪婪模式匹配多个字符\n> > # 然后匹配一下全文，看看是否获取了对应的\n> > dst_list = re.findall(restr, str_tmp)   # 打印一下看看就知道了\n> > ```\n> >\n> > \n\n## 额外补充知识\n\n> **`form`表单**\n>\n> - 以`github`为例\n> - 一般来说，`form`表单上面会有很多消息可挖掘，如下图所示\n>\n> > ![image-20211201205057556](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052010824.png)\n> >\n> > - 其中，`action`指的是提交给的路径\n> > - `method`是提交方法\n> > - `token`这个一般用来表示保持的意思，同行的`value`表示`token`的值\n> > - 而下面这个`name`，就是输入标签将里面的值提交给什么了，这里是提交给`login`\n>\n> **往往需要多次抓包，多次比较才行，找出差异**\n>\n> - 如在无痕串口进行多次退出和登录\n> - 主要是为了找出`post`的变值（不包括输入值，除非输入值不是明文传输）\n>\n> **注意多次爬虫，需要注意页面的跳转**\n>\n> - 比如登录的时候，一般会跳转的\n\n\n## 结束语\n\n​\t\t**技术永远是好东西，只是拿来做什么**\n\n","source":"_posts/Python爬虫学习.md","raw":"---\ntitle: Python爬虫学习\ncover: 'https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052015303.png'\ndate: 2022-04-05 20:07:16\ntags:\n  - Python\n  - 爬虫\nexcerpt: '爬虫是个好东西，轻易的下到别人下不到的东西'\ncategories: \n  - Python\n  - 爬虫\n---\n\n## 1、`requests`模块的使用\n\n> **response的用法**\n>\n> ```python\n> # ====== 1、基础知识  ======== #\n> import requests\n> url = \"http://www.baidu.com\"\n> response = requests.get(url)\n> print(respones.text)\t\t\t# 注意，text这个变量是默认解码过的，根据内容自动猜测的解码，str类数据\n> print(response.content.decode())   \t\n> # content是没有解码的，bytes数据，默认用utf-8解码，也可以指定gbk解码，如decode('gbk')\n> # 常见的解码方式：utf-8，gbk，gb2312，ascii，iso-8859-1\n> # 有些平台可能上述都不行，那就用bytes存储就好\n> print(responst.encoding)\t\t\t# 推测的遍码格式\n> \n> # 当然可以先设置encoding\n> response.encoding = \"utf8\"   # 注意不是写成 utf-8\n> print(response.text)   # 即可按照utf-8解码\n> \n> \n> \n> # ====== 2、常见的对象参数和方法  ======== #\n> # 响应的url\n> print(response.url)  \n> \n> # 状态码（一般来说，不要相信）\n> print(response.status_code)\n> \n> # 响应对应的请求头\n> print(response.request.headers)\n> \n> # 响应头\n> print(response.headers)\n> \n> # 响应对应请求的cookie 返回cookieJar类型\n> print(response.request._cookies)\n> \n> # 响应的cookie\n> print(response.cookies)\n> \n> # 自动将json字符串类型的响应内容转换成python对象\n> print(response.json())\n> \n> ```\n\n> **关闭代理**\n>\n> > ```python\n> > proxies = {\"http\": None, \"https\": None}\n> > response = rq.get(url, headers=headers, verify=False, proxies=proxies) # 关闭代理，关闭ssl认证\n> > ```\n> >\n> > \n\n---\n\n## 2、浏览器中的操作合集（可切换成无痕有痕分别都操作，带入多种数值操作）\n\n> **获取所有数据，勾选`All`**\n>\n> > ![image-20211201095759608](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052011268.png)\n>\n> **登录或者其他导致页面自动跳转，那么抓的包会刷新，勾选下面这个就不会刷新**\n>\n> > ![image-20211201205357600](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008211.png)\n>\n> **查看请求数据和响应数据**\n>\n> > ![image-20211201195017543](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008042.png)\n>\n> **关于请求头的一些参数意义**\n>\n> > `Referer`：这个是解释从哪个网站跳转的\n> >\n> > `User-Agent`：包含了请求主机的信息，包括系统信息和浏览器信息，如果要伪装成浏览器，这个参数很重要\n> >\n> > `Cookie`：这个分为`请求cookie`和`响应cookie`，分开使用\n> >\n> > `host`：请求域名\n> >\n> > `Connection`：是否保持连接，例如`keep-alive`，`close`\n> >\n> > `Upgrade-Insecure-Requests`：升级为`https`\n>\n> **关于响应头的一些参数意义** - 响应头一般是返回参数，主要看请求头\n>\n> > `Set-Cookie`：设置的`cookie`\n> >\n> > 状态码：200表示成功，但是，一般不要关注状态码，因为其不可信\n>\n> **常见的单词意义**\n>\n> > `token`：这个是一般为了保持的浏览器的连接性\n>\n> **注意事项**\n>\n> > 上面的`host`是域名，不一定是请求`url`，请求url看下面图\n> >\n> > > ![image-20211201194750582](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008032.png)\n>\n> **其他帮助网站合集**\n>\n> > - [在线字符串转`json`](https://www.json.cn/)\n> >\n> > - **免费代理站点**\n> >\n> >   > [国内免费代理站点1](https://www.kuaidaili.com/free/)\n> >   >\n> >   > [国内免费代理站点2](https://proxy.mimvp.com/freeopen)\n> >   >\n> >   > [国内免费代理站点3](https://www.89ip.cn/index.html)\n> >\n> > - \n\n## 3、爬虫入门一\n\n> **注意请求头中的一些参数**\n>\n> - `User-Agent`：包含了很多参数，如浏览器数据，系统数据等\n>\n> > ```python\n> > headers = {\n> >   'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36'  # 最好不要加到这一行的值，因为会报错，不明白为什么\n> > }\n> > headers = {\n> >   'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)'\n> > }\n> > response1 = requests.get(url, headers=headers)\n> > ```\n>\n> **发送带参数的请求**\n>\n> - `url`直接带参数\n>\n> > ```python\n> > # http://www.baidu.com/s?ie=utf-8&f=8&rsv_bp=1&rsv_idx=1&tn=baidu&wd=python&fenlei=256&rsv_pq=8cb91fd5000035bd&rsv_t=368aR6DDwiiYX59pfDu4vQz2%2FajgsJuSG4IS8mBB5GeZwSo6Sn%2BjQuytYZM&rqlang=cn&rsv_enter=1&rsv_dl=tb&rsv_sug3=9&rsv_sug1=7&rsv_sug7=101&rsv_sug2=0&rsv_btype=i&prefixsug=python&rsp=5&inputT=2667&rsv_sug4=6046\n> > \n> > # 如上面这个连接，可以尝试删掉一下不要的参数，最终得到下面这个\n> > # http://www.baidu.com/s?wd=python\n> > # 这个才是关键，然后进行get请求\n> > url = 'http://www.baidu.com/s?wd=python'\n> > headers = {\n> >     'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)'\n> > }\n> > ##  注意，get请求不要使用https\n> > response = requests.get(url, headers=headers)\n> > ```\n>\n> - 使用`params`携带参数字典\n>\n> > ```python\n> > url = 'http://www.baidu.com/s?'  # 注意这里需要加上s?，这个是百度的特性\n> > data = {\n> >  'wd': 'python'\n> > }\n> > heads = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)'}\n> > response = requests.get(url, params=data, headers=heads)\n> > ```\n>\n> **携带`cookie`信息，`cookie`一般有时效性，过段时间需要重新获取**\n>\n> - 以`github`为列\n>\n> > 见下列图片，浏览器抓包\n> >\n> > ![image-20211201111147337](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008253.png)\n>\n> - 在`headers`携带\n>\n> > ```python\n> > headers={\n> >  'cookie': 'xxxx',\n> >  'User-Agent': 'xxxx'\n> > }\n> > \n> > ```\n>\n> - 使用`cookie`参数来保持\n>\n> > ```python\n> > # 构建cookie字典\n> > # 需要先切割键值对\n> > # 如下列cookie\n> > cookies = '_octo=GH1.1.612724434.1638322138; tz=Asia/Shanghai; _device_id=5fa9f396b9f0691f8db3054f0b87dbb9; has_recent_activity=1; user_session=03yOITMxPd4lG6qXwYYs9QEaFPgu2hxw04gHIymweU4J1EEe; __Host-user_session_same_site=03yOITMxPd4lG6qXwYYs9QEaFPgu2hxw04gHIymweU4J1EEe; tz=Asia/Shanghai; color_mode={\"color_mode\":\"auto\",\"light_theme\":{\"name\":\"light\",\"color_mode\":\"light\"},\"dark_theme\":{\"name\":\"dark\",\"color_mode\":\"dark\"}}; logged_in=yes; dotcom_user=HF-Mfeng; _gh_sess=Bvk3bQRV+XfUQlh+l8Mu2MKWcl7O+LH3nLtnVSWOFvzAo50NycqAlQFAYbNMdXfpVAxSU08+65qeCVG2+wX97z/sjsdsI2grX7uXpIWvFpAi/pOBPyt4dXjNRT5n2o2VTvCgIP2mWQEXTg7HVjs3v16QCj/eUFbd460btIb6J1NG/DY1wW7jx8/VAS2vkFVZ7uTkoljKQdcs8K7oAndejxw7f3fdBKCybeghEIqu71SonF5C774enN5nq2zNtSILtA7lEA+s72ekWtLrFkzRpAoi+rzQLR2naFzIXCuFbbCdsLj7tNRAF8Uj0vyRn29LdqxbjMsssMmiiBVi81x3Vf7awZRHhjp2jzMINq+J3grHfOyjgwer1XRXkUW4RaIayrC60XOl/NG5tOPUmPCHqDkHhAyFx3TRVxhz84a+oxBSW9PJK4ebYu2sZrA3nCOdRkPDvEoMehgxhZuOz07e8usCuKc//p/tozi/WI+CuPWjYamF3Hyv1uYt4C1sKjZbhNzH3sjd+9hD5DP33IROZWlvCM4W2PWmq6RWyC5B1Dyk8pAq89W87dsdm5W2eyMo/xNLdwZi+o8cXkJROi8W/XQa6NwRWlh9yON+xl3L9Txtesvi3mlB7b1L+ic/XR4f7Wh8C59yeyY67lijumG/qfX0F8w3H76BPnlmbH9oxL4qRkWwVSflal4LjRhgOaoiCZzs1r6oellyNV6pPilm7QRbP7KEnq+R+PusPQsDBWn4Gej/vbQ2P9cwqW9EQr+VhsV6MHUvhuGAY8MRB5eBKtxrhqXZMiLYak0Pk82cl9oesvU5tqp3xNo2VNHWXt5uM6YLQTggbG+spmuxqnbHt481AoMUNnRcN6WomLZ4vS4pYXO5NLa58uk9slgT/3iwPEWsy7HuK5FLYqcMvPTGNeO+nYs=--c91BUqTy9ZXXOfRr--YhanrwguBRPMP5S/I3ig0A=='\n> > cookies = cookies.splie(\"; \")\n> > cookies_ = {}\n> > for cookie in cookies:\n> >  cookies_[cookie.split('=')[0]] = cookie.splie('=')[-1]\n> > \n> > # 其中有许多的等号，如_octo=GH1.1.612724434.1638322138，就是一个键值对\n> > respose = requests.get(url,headers=headers,cookies=cookies_)\n> > ```\n>\n> - `cookieJar`对象转换成`cookie`字典，一般用不到\n>\n> > ```python\n> > # 什么是cookieJar对象呢，如下\n> > requests.get(url).cookie\t\t# 这个就是cookieJar对象\n> > dict_cookies = requests.utils.dict_from_cookiejar(response.cookies)   # cookiejar转换成字典\n> > \n> > jar_cookies = requests.utils.cookiesjar_from_dict(dict_cookies)  # 重新转化成cookiejar\n> > \n> > ```\n>\n> **`timeout`的用法**\n>\n> - 设置一下\n>\n> > ```python\n> > wresponse = requests.get(url, timeout=3)  # 设为3s，一般设个十秒左右就好\n> > ```\n> >\n> > \n>\n> **代理`Proxy`**\n>\n> > 代理分为正向代理和反向代理\n> >\n> > 代理还分为透明代理、匿名代理、高匿代理\n> >\n> > - 透明代理\n> >\n> > > ```python\n> > > REMOTE_ADDR = Proxy IP\n> > > HTTP_VIA = Proxy IP\n> > > HTTP_X_FORWARDED_FOR = Your IP\n> > > ```\n> >\n> > - 匿名代理\n> >\n> > > ```python\n> > > REMOTE_ADDR = Proxy IP\n> > > HTTP_VIA = Proxy IP\n> > > HTTP_X_FORWARDED_FOR = Proxy IP\n> > > ```\n> >\n> > - 高匿代理\n> >\n> > > ```shell\n> > > REMOTE_ADDR = Proxy IP\n> > > HTTP_VIA = not determined\n> > > HTTP_X_FORWARDED_FOR = not determined\n> > > ```\n> >\n> > 代理还可分为，`http、https、socks`\n> >\n> > - `http`：目标`url`为`http`协议\n> > - `https`：目标`url`为`https`协议\n> > - `socks`：只传递数据包，不在乎什么应用协议，耗时少\n> >\n> > **用法**\n> >\n> > > ```python\n> > > proxies = {\n> > >  'http': 'http://127.0.0.1:7890',\n> > >  'https': 'http://127.0.0.1:7890'\n> > > }\n> > > response = requests.get(url, proxies=proxies)\n> > > ```\n> > >\n> > > [国内免费代理站点1](https://www.kuaidaili.com/free/)\n> > >\n> > > [国内免费代理站点2](https://proxy.mimvp.com/freeopen)\n> > >\n> > > [国内免费代理站点3](https://www.89ip.cn/index.html)\n> >\n> > - 并且代理站点可能会给你添加一下信息，使得你更像一个浏览器\n> > - 代理也有可能截获你的数据，所以这个也要注意\n>\n> **`verify`忽略`CA`证书**\n>\n> > 很多情况如下图所示\n> >\n> > > ![image-20211201192347257](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008307.png)\n> >\n> > 爬虫过程遇到下列情况\n> >\n> > > ```python\n> > > requests.exceptions.SSLError: HTTPSConnection.....\n> > > ```\n> >\n> > 设置为`False`即可\n> >\n> > > ```python\n> > > # 默认是True，设置为False\n> > > # 运行过程会报警告的，但是 don't worry it 爬虫还是可以爬取内容的\n> > > response = requests.get(url, verify=False)\n> > > ```\n>\n> **`post`请求**\n>\n> > `post`用途\n> >\n> > - 一般有账号密码，都会使用`post`请求，因为`get`请求是在`url`中的明文\n> > - 大文件以及多数据，都是使用`post`\n> > - `web`工程师会认为`post`比`get`请求更加安全\n> >\n> > 简单实现\n> >\n> > > ```python\n> > > respose = requests.post(url, data) # data是一个字典\n> > > ```\n> >\n> > 找`data`的步骤寻找固定值：一般来说浏览器抓抓包就知道了\n> >\n> > - 寻找输入值：也一般来说浏览器抓抓包就知道了\n> > - 寻找预设值 - 静态文件：一般来说，需要从`html`文件中搜索，可以尝试，这个是反爬的\n> > - 寻找预设值 - 发请求：需要对指定地址发送请求\n> > - 寻找动态生成值：一般是客户端生成的，反爬的重点，一般采用`Javascript`生成\n> >\n> > `data`反爬套路\n> >\n> > - 模仿其他浏览器发送，如手机什么的，因为很多浏览器都是不一样的反爬，找个弱的\n> > - 注意时间戳什么的\n> > - 注意里面的`JS`文件\n> > - 有些可能是随机值\n> > - 从`html`提取，可以试试无痕浏览器\n>\n> **`requess.session`状态保持**\n>\n> - 自动保持`cookie`，一般多次请求（如登录之后再操作的），使用方法\n>\n> > ```python\n> > session = requests.session()\n> > session.headers = {\n> > \n> > }\n> > session.data = {\n> > \n> > }\n> > response = session.get(url)\n> > response = session.post(url)\n> > \n> > # 如下用法\n> > s = rq.session()\n> > s.trust_env\n> > s.verify\n> > s.headers\n> > s.proxies\n> > s.cookies\n> > s.get(url, data=data)\n> > s.post(url, data=data)\n> > ```\n\n## 正则表达式，这个也是重点\n\n> **首先如何使用正则表达式**\n>\n> > ```python\n> > response = requests.get(url)\n> > restr = response.content.decode()   # 转成utf-8或者gbk\n> > # 正则提取\n> > import re  # 导入正则模块\n> > str_tmp = \"<link href=\\\"https://stacdn.proginn.com/plugin/swiper/swiper.min.css?version=4.30.2\\\" rel=\\\"stylesheet\\\" type=\\\"text/css\\\">\"   # 临时字符串，不用写到代码里\n> > # 假如想要获取上面中的href，那么这样写正则表达式\n> > # 正则\n> > restr = '<link href=\\\"(.*?)\\\" rel=\\\"stylesheet\\\" type=\\\"text/css\\\">'   # 这个是以非贪婪模式匹配多个字符\n> > # 然后匹配一下全文，看看是否获取了对应的\n> > dst_list = re.findall(restr, str_tmp)   # 打印一下看看就知道了\n> > ```\n> >\n> > \n\n## 额外补充知识\n\n> **`form`表单**\n>\n> - 以`github`为例\n> - 一般来说，`form`表单上面会有很多消息可挖掘，如下图所示\n>\n> > ![image-20211201205057556](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052010824.png)\n> >\n> > - 其中，`action`指的是提交给的路径\n> > - `method`是提交方法\n> > - `token`这个一般用来表示保持的意思，同行的`value`表示`token`的值\n> > - 而下面这个`name`，就是输入标签将里面的值提交给什么了，这里是提交给`login`\n>\n> **往往需要多次抓包，多次比较才行，找出差异**\n>\n> - 如在无痕串口进行多次退出和登录\n> - 主要是为了找出`post`的变值（不包括输入值，除非输入值不是明文传输）\n>\n> **注意多次爬虫，需要注意页面的跳转**\n>\n> - 比如登录的时候，一般会跳转的\n\n\n## 结束语\n\n​\t\t**技术永远是好东西，只是拿来做什么**\n\n","slug":"Python爬虫学习","published":1,"updated":"2022-04-05T12:15:28.627Z","_id":"cl1m3qre700000su5ap2e331l","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"1、requests模块的使用\"><a href=\"#1、requests模块的使用\" class=\"headerlink\" title=\"1、requests模块的使用\"></a>1、<code>requests</code>模块的使用</h2><blockquote>\n<p><strong>response的用法</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ====== 1、基础知识  ======== #</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> requests</span><br><span class=\"line\">url = <span class=\"string\">&quot;http://www.baidu.com&quot;</span></span><br><span class=\"line\">response = requests.get(url)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(respones.text)\t\t\t<span class=\"comment\"># 注意，text这个变量是默认解码过的，根据内容自动猜测的解码，str类数据</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.content.decode())   \t</span><br><span class=\"line\"><span class=\"comment\"># content是没有解码的，bytes数据，默认用utf-8解码，也可以指定gbk解码，如decode(&#x27;gbk&#x27;)</span></span><br><span class=\"line\"><span class=\"comment\"># 常见的解码方式：utf-8，gbk，gb2312，ascii，iso-8859-1</span></span><br><span class=\"line\"><span class=\"comment\"># 有些平台可能上述都不行，那就用bytes存储就好</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(responst.encoding)\t\t\t<span class=\"comment\"># 推测的遍码格式</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 当然可以先设置encoding</span></span><br><span class=\"line\">response.encoding = <span class=\"string\">&quot;utf8&quot;</span>   <span class=\"comment\"># 注意不是写成 utf-8</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.text)   <span class=\"comment\"># 即可按照utf-8解码</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ====== 2、常见的对象参数和方法  ======== #</span></span><br><span class=\"line\"><span class=\"comment\"># 响应的url</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.url)  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 状态码（一般来说，不要相信）</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.status_code)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 响应对应的请求头</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.request.headers)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 响应头</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.headers)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 响应对应请求的cookie 返回cookieJar类型</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.request._cookies)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 响应的cookie</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.cookies)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 自动将json字符串类型的响应内容转换成python对象</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.json())</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</blockquote>\n<blockquote>\n<p><strong>关闭代理</strong></p>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">proxies = &#123;<span class=\"string\">&quot;http&quot;</span>: <span class=\"literal\">None</span>, <span class=\"string\">&quot;https&quot;</span>: <span class=\"literal\">None</span>&#125;</span><br><span class=\"line\">response = rq.get(url, headers=headers, verify=<span class=\"literal\">False</span>, proxies=proxies) <span class=\"comment\"># 关闭代理，关闭ssl认证</span></span><br></pre></td></tr></table></figure>\n\n\n</blockquote>\n</blockquote>\n<hr>\n<h2 id=\"2、浏览器中的操作合集（可切换成无痕有痕分别都操作，带入多种数值操作）\"><a href=\"#2、浏览器中的操作合集（可切换成无痕有痕分别都操作，带入多种数值操作）\" class=\"headerlink\" title=\"2、浏览器中的操作合集（可切换成无痕有痕分别都操作，带入多种数值操作）\"></a>2、浏览器中的操作合集（可切换成无痕有痕分别都操作，带入多种数值操作）</h2><blockquote>\n<p><strong>获取所有数据，勾选<code>All</code></strong></p>\n<blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052011268.png\" alt=\"image-20211201095759608\"></p>\n</blockquote>\n<p><strong>登录或者其他导致页面自动跳转，那么抓的包会刷新，勾选下面这个就不会刷新</strong></p>\n<blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008211.png\" alt=\"image-20211201205357600\"></p>\n</blockquote>\n<p><strong>查看请求数据和响应数据</strong></p>\n<blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008042.png\" alt=\"image-20211201195017543\"></p>\n</blockquote>\n<p><strong>关于请求头的一些参数意义</strong></p>\n<blockquote>\n<p><code>Referer</code>：这个是解释从哪个网站跳转的</p>\n<p><code>User-Agent</code>：包含了请求主机的信息，包括系统信息和浏览器信息，如果要伪装成浏览器，这个参数很重要</p>\n<p><code>Cookie</code>：这个分为<code>请求cookie</code>和<code>响应cookie</code>，分开使用</p>\n<p><code>host</code>：请求域名</p>\n<p><code>Connection</code>：是否保持连接，例如<code>keep-alive</code>，<code>close</code></p>\n<p><code>Upgrade-Insecure-Requests</code>：升级为<code>https</code></p>\n</blockquote>\n<p><strong>关于响应头的一些参数意义</strong> - 响应头一般是返回参数，主要看请求头</p>\n<blockquote>\n<p><code>Set-Cookie</code>：设置的<code>cookie</code></p>\n<p>状态码：200表示成功，但是，一般不要关注状态码，因为其不可信</p>\n</blockquote>\n<p><strong>常见的单词意义</strong></p>\n<blockquote>\n<p><code>token</code>：这个是一般为了保持的浏览器的连接性</p>\n</blockquote>\n<p><strong>注意事项</strong></p>\n<blockquote>\n<p>上面的<code>host</code>是域名，不一定是请求<code>url</code>，请求url看下面图</p>\n<blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008032.png\" alt=\"image-20211201194750582\"></p>\n</blockquote>\n</blockquote>\n<p><strong>其他帮助网站合集</strong></p>\n<blockquote>\n<ul>\n<li><p><a href=\"https://www.json.cn/\">在线字符串转<code>json</code></a></p>\n</li>\n<li><p><strong>免费代理站点</strong></p>\n<blockquote>\n<p><a href=\"https://www.kuaidaili.com/free/\">国内免费代理站点1</a></p>\n<p><a href=\"https://proxy.mimvp.com/freeopen\">国内免费代理站点2</a></p>\n<p><a href=\"https://www.89ip.cn/index.html\">国内免费代理站点3</a></p>\n</blockquote>\n</li>\n<li></li>\n</ul>\n</blockquote>\n</blockquote>\n<h2 id=\"3、爬虫入门一\"><a href=\"#3、爬虫入门一\" class=\"headerlink\" title=\"3、爬虫入门一\"></a>3、爬虫入门一</h2><blockquote>\n<p><strong>注意请求头中的一些参数</strong></p>\n<ul>\n<li><code>User-Agent</code>：包含了很多参数，如浏览器数据，系统数据等</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">headers = &#123;</span><br><span class=\"line\">  <span class=\"string\">&#x27;User-Agent&#x27;</span>: <span class=\"string\">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36&#x27;</span>  <span class=\"comment\"># 最好不要加到这一行的值，因为会报错，不明白为什么</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">headers = &#123;</span><br><span class=\"line\">  <span class=\"string\">&#x27;User-Agent&#x27;</span>: <span class=\"string\">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)&#x27;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">response1 = requests.get(url, headers=headers)</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p><strong>发送带参数的请求</strong></p>\n<ul>\n<li><code>url</code>直接带参数</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># http://www.baidu.com/s?ie=utf-8&amp;f=8&amp;rsv_bp=1&amp;rsv_idx=1&amp;tn=baidu&amp;wd=python&amp;fenlei=256&amp;rsv_pq=8cb91fd5000035bd&amp;rsv_t=368aR6DDwiiYX59pfDu4vQz2%2FajgsJuSG4IS8mBB5GeZwSo6Sn%2BjQuytYZM&amp;rqlang=cn&amp;rsv_enter=1&amp;rsv_dl=tb&amp;rsv_sug3=9&amp;rsv_sug1=7&amp;rsv_sug7=101&amp;rsv_sug2=0&amp;rsv_btype=i&amp;prefixsug=python&amp;rsp=5&amp;inputT=2667&amp;rsv_sug4=6046</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 如上面这个连接，可以尝试删掉一下不要的参数，最终得到下面这个</span></span><br><span class=\"line\"><span class=\"comment\"># http://www.baidu.com/s?wd=python</span></span><br><span class=\"line\"><span class=\"comment\"># 这个才是关键，然后进行get请求</span></span><br><span class=\"line\">url = <span class=\"string\">&#x27;http://www.baidu.com/s?wd=python&#x27;</span></span><br><span class=\"line\">headers = &#123;</span><br><span class=\"line\">    <span class=\"string\">&#x27;User-Agent&#x27;</span>: <span class=\"string\">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)&#x27;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">##  注意，get请求不要使用https</span></span><br><span class=\"line\">response = requests.get(url, headers=headers)</span><br></pre></td></tr></table></figure>\n</blockquote>\n<ul>\n<li>使用<code>params</code>携带参数字典</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">url = <span class=\"string\">&#x27;http://www.baidu.com/s?&#x27;</span>  <span class=\"comment\"># 注意这里需要加上s?，这个是百度的特性</span></span><br><span class=\"line\">data = &#123;</span><br><span class=\"line\"> <span class=\"string\">&#x27;wd&#x27;</span>: <span class=\"string\">&#x27;python&#x27;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">heads = &#123;<span class=\"string\">&#x27;User-Agent&#x27;</span>: <span class=\"string\">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)&#x27;</span>&#125;</span><br><span class=\"line\">response = requests.get(url, params=data, headers=heads)</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p><strong>携带<code>cookie</code>信息，<code>cookie</code>一般有时效性，过段时间需要重新获取</strong></p>\n<ul>\n<li>以<code>github</code>为列</li>\n</ul>\n<blockquote>\n<p>见下列图片，浏览器抓包</p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008253.png\" alt=\"image-20211201111147337\"></p>\n</blockquote>\n<ul>\n<li>在<code>headers</code>携带</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">headers=&#123;</span><br><span class=\"line\"> <span class=\"string\">&#x27;cookie&#x27;</span>: <span class=\"string\">&#x27;xxxx&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;User-Agent&#x27;</span>: <span class=\"string\">&#x27;xxxx&#x27;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</blockquote>\n<ul>\n<li>使用<code>cookie</code>参数来保持</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 构建cookie字典</span></span><br><span class=\"line\"><span class=\"comment\"># 需要先切割键值对</span></span><br><span class=\"line\"><span class=\"comment\"># 如下列cookie</span></span><br><span class=\"line\">cookies = <span class=\"string\">&#x27;_octo=GH1.1.612724434.1638322138; tz=Asia/Shanghai; _device_id=5fa9f396b9f0691f8db3054f0b87dbb9; has_recent_activity=1; user_session=03yOITMxPd4lG6qXwYYs9QEaFPgu2hxw04gHIymweU4J1EEe; __Host-user_session_same_site=03yOITMxPd4lG6qXwYYs9QEaFPgu2hxw04gHIymweU4J1EEe; tz=Asia/Shanghai; color_mode=&#123;&quot;color_mode&quot;:&quot;auto&quot;,&quot;light_theme&quot;:&#123;&quot;name&quot;:&quot;light&quot;,&quot;color_mode&quot;:&quot;light&quot;&#125;,&quot;dark_theme&quot;:&#123;&quot;name&quot;:&quot;dark&quot;,&quot;color_mode&quot;:&quot;dark&quot;&#125;&#125;; logged_in=yes; dotcom_user=HF-Mfeng; _gh_sess=Bvk3bQRV+XfUQlh+l8Mu2MKWcl7O+LH3nLtnVSWOFvzAo50NycqAlQFAYbNMdXfpVAxSU08+65qeCVG2+wX97z/sjsdsI2grX7uXpIWvFpAi/pOBPyt4dXjNRT5n2o2VTvCgIP2mWQEXTg7HVjs3v16QCj/eUFbd460btIb6J1NG/DY1wW7jx8/VAS2vkFVZ7uTkoljKQdcs8K7oAndejxw7f3fdBKCybeghEIqu71SonF5C774enN5nq2zNtSILtA7lEA+s72ekWtLrFkzRpAoi+rzQLR2naFzIXCuFbbCdsLj7tNRAF8Uj0vyRn29LdqxbjMsssMmiiBVi81x3Vf7awZRHhjp2jzMINq+J3grHfOyjgwer1XRXkUW4RaIayrC60XOl/NG5tOPUmPCHqDkHhAyFx3TRVxhz84a+oxBSW9PJK4ebYu2sZrA3nCOdRkPDvEoMehgxhZuOz07e8usCuKc//p/tozi/WI+CuPWjYamF3Hyv1uYt4C1sKjZbhNzH3sjd+9hD5DP33IROZWlvCM4W2PWmq6RWyC5B1Dyk8pAq89W87dsdm5W2eyMo/xNLdwZi+o8cXkJROi8W/XQa6NwRWlh9yON+xl3L9Txtesvi3mlB7b1L+ic/XR4f7Wh8C59yeyY67lijumG/qfX0F8w3H76BPnlmbH9oxL4qRkWwVSflal4LjRhgOaoiCZzs1r6oellyNV6pPilm7QRbP7KEnq+R+PusPQsDBWn4Gej/vbQ2P9cwqW9EQr+VhsV6MHUvhuGAY8MRB5eBKtxrhqXZMiLYak0Pk82cl9oesvU5tqp3xNo2VNHWXt5uM6YLQTggbG+spmuxqnbHt481AoMUNnRcN6WomLZ4vS4pYXO5NLa58uk9slgT/3iwPEWsy7HuK5FLYqcMvPTGNeO+nYs=--c91BUqTy9ZXXOfRr--YhanrwguBRPMP5S/I3ig0A==&#x27;</span></span><br><span class=\"line\">cookies = cookies.splie(<span class=\"string\">&quot;; &quot;</span>)</span><br><span class=\"line\">cookies_ = &#123;&#125;</span><br><span class=\"line\"><span class=\"keyword\">for</span> cookie <span class=\"keyword\">in</span> cookies:</span><br><span class=\"line\"> cookies_[cookie.split(<span class=\"string\">&#x27;=&#x27;</span>)[<span class=\"number\">0</span>]] = cookie.splie(<span class=\"string\">&#x27;=&#x27;</span>)[-<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 其中有许多的等号，如_octo=GH1.1.612724434.1638322138，就是一个键值对</span></span><br><span class=\"line\">respose = requests.get(url,headers=headers,cookies=cookies_)</span><br></pre></td></tr></table></figure>\n</blockquote>\n<ul>\n<li><code>cookieJar</code>对象转换成<code>cookie</code>字典，一般用不到</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 什么是cookieJar对象呢，如下</span></span><br><span class=\"line\">requests.get(url).cookie\t\t<span class=\"comment\"># 这个就是cookieJar对象</span></span><br><span class=\"line\">dict_cookies = requests.utils.dict_from_cookiejar(response.cookies)   <span class=\"comment\"># cookiejar转换成字典</span></span><br><span class=\"line\"></span><br><span class=\"line\">jar_cookies = requests.utils.cookiesjar_from_dict(dict_cookies)  <span class=\"comment\"># 重新转化成cookiejar</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</blockquote>\n<p><strong><code>timeout</code>的用法</strong></p>\n<ul>\n<li>设置一下</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">wresponse = requests.get(url, timeout=<span class=\"number\">3</span>)  <span class=\"comment\"># 设为3s，一般设个十秒左右就好</span></span><br></pre></td></tr></table></figure>\n\n\n</blockquote>\n<p><strong>代理<code>Proxy</code></strong></p>\n<blockquote>\n<p>代理分为正向代理和反向代理</p>\n<p>代理还分为透明代理、匿名代理、高匿代理</p>\n<ul>\n<li>透明代理</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">REMOTE_ADDR = Proxy IP</span><br><span class=\"line\">HTTP_VIA = Proxy IP</span><br><span class=\"line\">HTTP_X_FORWARDED_FOR = Your IP</span><br></pre></td></tr></table></figure>\n</blockquote>\n<ul>\n<li>匿名代理</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">REMOTE_ADDR = Proxy IP</span><br><span class=\"line\">HTTP_VIA = Proxy IP</span><br><span class=\"line\">HTTP_X_FORWARDED_FOR = Proxy IP</span><br></pre></td></tr></table></figure>\n</blockquote>\n<ul>\n<li>高匿代理</li>\n</ul>\n<blockquote>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">REMOTE_ADDR = Proxy IP</span><br><span class=\"line\">HTTP_VIA = not determined</span><br><span class=\"line\">HTTP_X_FORWARDED_FOR = not determined</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p>代理还可分为，<code>http、https、socks</code></p>\n<ul>\n<li><code>http</code>：目标<code>url</code>为<code>http</code>协议</li>\n<li><code>https</code>：目标<code>url</code>为<code>https</code>协议</li>\n<li><code>socks</code>：只传递数据包，不在乎什么应用协议，耗时少</li>\n</ul>\n<p><strong>用法</strong></p>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">proxies = &#123;</span><br><span class=\"line\"> <span class=\"string\">&#x27;http&#x27;</span>: <span class=\"string\">&#x27;http://127.0.0.1:7890&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;https&#x27;</span>: <span class=\"string\">&#x27;http://127.0.0.1:7890&#x27;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">response = requests.get(url, proxies=proxies)</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://www.kuaidaili.com/free/\">国内免费代理站点1</a></p>\n<p><a href=\"https://proxy.mimvp.com/freeopen\">国内免费代理站点2</a></p>\n<p><a href=\"https://www.89ip.cn/index.html\">国内免费代理站点3</a></p>\n</blockquote>\n<ul>\n<li>并且代理站点可能会给你添加一下信息，使得你更像一个浏览器</li>\n<li>代理也有可能截获你的数据，所以这个也要注意</li>\n</ul>\n</blockquote>\n<p><strong><code>verify</code>忽略<code>CA</code>证书</strong></p>\n<blockquote>\n<p>很多情况如下图所示</p>\n<blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008307.png\" alt=\"image-20211201192347257\"></p>\n</blockquote>\n<p>爬虫过程遇到下列情况</p>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">requests.exceptions.SSLError: HTTPSConnection.....</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p>设置为<code>False</code>即可</p>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 默认是True，设置为False</span></span><br><span class=\"line\"><span class=\"comment\"># 运行过程会报警告的，但是 don&#x27;t worry it 爬虫还是可以爬取内容的</span></span><br><span class=\"line\">response = requests.get(url, verify=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n</blockquote>\n</blockquote>\n<p><strong><code>post</code>请求</strong></p>\n<blockquote>\n<p><code>post</code>用途</p>\n<ul>\n<li>一般有账号密码，都会使用<code>post</code>请求，因为<code>get</code>请求是在<code>url</code>中的明文</li>\n<li>大文件以及多数据，都是使用<code>post</code></li>\n<li><code>web</code>工程师会认为<code>post</code>比<code>get</code>请求更加安全</li>\n</ul>\n<p>简单实现</p>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">respose = requests.post(url, data) <span class=\"comment\"># data是一个字典</span></span><br></pre></td></tr></table></figure>\n</blockquote>\n<p>找<code>data</code>的步骤寻找固定值：一般来说浏览器抓抓包就知道了</p>\n<ul>\n<li>寻找输入值：也一般来说浏览器抓抓包就知道了</li>\n<li>寻找预设值 - 静态文件：一般来说，需要从<code>html</code>文件中搜索，可以尝试，这个是反爬的</li>\n<li>寻找预设值 - 发请求：需要对指定地址发送请求</li>\n<li>寻找动态生成值：一般是客户端生成的，反爬的重点，一般采用<code>Javascript</code>生成</li>\n</ul>\n<p><code>data</code>反爬套路</p>\n<ul>\n<li>模仿其他浏览器发送，如手机什么的，因为很多浏览器都是不一样的反爬，找个弱的</li>\n<li>注意时间戳什么的</li>\n<li>注意里面的<code>JS</code>文件</li>\n<li>有些可能是随机值</li>\n<li>从<code>html</code>提取，可以试试无痕浏览器</li>\n</ul>\n</blockquote>\n<p><strong><code>requess.session</code>状态保持</strong></p>\n<ul>\n<li>自动保持<code>cookie</code>，一般多次请求（如登录之后再操作的），使用方法</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">session = requests.session()</span><br><span class=\"line\">session.headers = &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">session.data = &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">response = session.get(url)</span><br><span class=\"line\">response = session.post(url)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 如下用法</span></span><br><span class=\"line\">s = rq.session()</span><br><span class=\"line\">s.trust_env</span><br><span class=\"line\">s.verify</span><br><span class=\"line\">s.headers</span><br><span class=\"line\">s.proxies</span><br><span class=\"line\">s.cookies</span><br><span class=\"line\">s.get(url, data=data)</span><br><span class=\"line\">s.post(url, data=data)</span><br></pre></td></tr></table></figure>\n</blockquote>\n</blockquote>\n<h2 id=\"正则表达式，这个也是重点\"><a href=\"#正则表达式，这个也是重点\" class=\"headerlink\" title=\"正则表达式，这个也是重点\"></a>正则表达式，这个也是重点</h2><blockquote>\n<p><strong>首先如何使用正则表达式</strong></p>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">response = requests.get(url)</span><br><span class=\"line\">restr = response.content.decode()   <span class=\"comment\"># 转成utf-8或者gbk</span></span><br><span class=\"line\"><span class=\"comment\"># 正则提取</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> re  <span class=\"comment\"># 导入正则模块</span></span><br><span class=\"line\">str_tmp = <span class=\"string\">&quot;&lt;link href=\\&quot;https://stacdn.proginn.com/plugin/swiper/swiper.min.css?version=4.30.2\\&quot; rel=\\&quot;stylesheet\\&quot; type=\\&quot;text/css\\&quot;&gt;&quot;</span>   <span class=\"comment\"># 临时字符串，不用写到代码里</span></span><br><span class=\"line\"><span class=\"comment\"># 假如想要获取上面中的href，那么这样写正则表达式</span></span><br><span class=\"line\"><span class=\"comment\"># 正则</span></span><br><span class=\"line\">restr = <span class=\"string\">&#x27;&lt;link href=\\&quot;(.*?)\\&quot; rel=\\&quot;stylesheet\\&quot; type=\\&quot;text/css\\&quot;&gt;&#x27;</span>   <span class=\"comment\"># 这个是以非贪婪模式匹配多个字符</span></span><br><span class=\"line\"><span class=\"comment\"># 然后匹配一下全文，看看是否获取了对应的</span></span><br><span class=\"line\">dst_list = re.findall(restr, str_tmp)   <span class=\"comment\"># 打印一下看看就知道了</span></span><br></pre></td></tr></table></figure>\n\n\n</blockquote>\n</blockquote>\n<h2 id=\"额外补充知识\"><a href=\"#额外补充知识\" class=\"headerlink\" title=\"额外补充知识\"></a>额外补充知识</h2><blockquote>\n<p><strong><code>form</code>表单</strong></p>\n<ul>\n<li>以<code>github</code>为例</li>\n<li>一般来说，<code>form</code>表单上面会有很多消息可挖掘，如下图所示</li>\n</ul>\n<blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052010824.png\" alt=\"image-20211201205057556\"></p>\n<ul>\n<li>其中，<code>action</code>指的是提交给的路径</li>\n<li><code>method</code>是提交方法</li>\n<li><code>token</code>这个一般用来表示保持的意思，同行的<code>value</code>表示<code>token</code>的值</li>\n<li>而下面这个<code>name</code>，就是输入标签将里面的值提交给什么了，这里是提交给<code>login</code></li>\n</ul>\n</blockquote>\n<p><strong>往往需要多次抓包，多次比较才行，找出差异</strong></p>\n<ul>\n<li>如在无痕串口进行多次退出和登录</li>\n<li>主要是为了找出<code>post</code>的变值（不包括输入值，除非输入值不是明文传输）</li>\n</ul>\n<p><strong>注意多次爬虫，需要注意页面的跳转</strong></p>\n<ul>\n<li>比如登录的时候，一般会跳转的</li>\n</ul>\n</blockquote>\n<h2 id=\"结束语\"><a href=\"#结束语\" class=\"headerlink\" title=\"结束语\"></a>结束语</h2><p>​        <strong>技术永远是好东西，只是拿来做什么</strong></p>\n","site":{"data":{}},"more":"<h2 id=\"1、requests模块的使用\"><a href=\"#1、requests模块的使用\" class=\"headerlink\" title=\"1、requests模块的使用\"></a>1、<code>requests</code>模块的使用</h2><blockquote>\n<p><strong>response的用法</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ====== 1、基础知识  ======== #</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> requests</span><br><span class=\"line\">url = <span class=\"string\">&quot;http://www.baidu.com&quot;</span></span><br><span class=\"line\">response = requests.get(url)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(respones.text)\t\t\t<span class=\"comment\"># 注意，text这个变量是默认解码过的，根据内容自动猜测的解码，str类数据</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.content.decode())   \t</span><br><span class=\"line\"><span class=\"comment\"># content是没有解码的，bytes数据，默认用utf-8解码，也可以指定gbk解码，如decode(&#x27;gbk&#x27;)</span></span><br><span class=\"line\"><span class=\"comment\"># 常见的解码方式：utf-8，gbk，gb2312，ascii，iso-8859-1</span></span><br><span class=\"line\"><span class=\"comment\"># 有些平台可能上述都不行，那就用bytes存储就好</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(responst.encoding)\t\t\t<span class=\"comment\"># 推测的遍码格式</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 当然可以先设置encoding</span></span><br><span class=\"line\">response.encoding = <span class=\"string\">&quot;utf8&quot;</span>   <span class=\"comment\"># 注意不是写成 utf-8</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.text)   <span class=\"comment\"># 即可按照utf-8解码</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ====== 2、常见的对象参数和方法  ======== #</span></span><br><span class=\"line\"><span class=\"comment\"># 响应的url</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.url)  </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 状态码（一般来说，不要相信）</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.status_code)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 响应对应的请求头</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.request.headers)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 响应头</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.headers)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 响应对应请求的cookie 返回cookieJar类型</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.request._cookies)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 响应的cookie</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.cookies)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 自动将json字符串类型的响应内容转换成python对象</span></span><br><span class=\"line\"><span class=\"built_in\">print</span>(response.json())</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</blockquote>\n<blockquote>\n<p><strong>关闭代理</strong></p>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">proxies = &#123;<span class=\"string\">&quot;http&quot;</span>: <span class=\"literal\">None</span>, <span class=\"string\">&quot;https&quot;</span>: <span class=\"literal\">None</span>&#125;</span><br><span class=\"line\">response = rq.get(url, headers=headers, verify=<span class=\"literal\">False</span>, proxies=proxies) <span class=\"comment\"># 关闭代理，关闭ssl认证</span></span><br></pre></td></tr></table></figure>\n\n\n</blockquote>\n</blockquote>\n<hr>\n<h2 id=\"2、浏览器中的操作合集（可切换成无痕有痕分别都操作，带入多种数值操作）\"><a href=\"#2、浏览器中的操作合集（可切换成无痕有痕分别都操作，带入多种数值操作）\" class=\"headerlink\" title=\"2、浏览器中的操作合集（可切换成无痕有痕分别都操作，带入多种数值操作）\"></a>2、浏览器中的操作合集（可切换成无痕有痕分别都操作，带入多种数值操作）</h2><blockquote>\n<p><strong>获取所有数据，勾选<code>All</code></strong></p>\n<blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052011268.png\" alt=\"image-20211201095759608\"></p>\n</blockquote>\n<p><strong>登录或者其他导致页面自动跳转，那么抓的包会刷新，勾选下面这个就不会刷新</strong></p>\n<blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008211.png\" alt=\"image-20211201205357600\"></p>\n</blockquote>\n<p><strong>查看请求数据和响应数据</strong></p>\n<blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008042.png\" alt=\"image-20211201195017543\"></p>\n</blockquote>\n<p><strong>关于请求头的一些参数意义</strong></p>\n<blockquote>\n<p><code>Referer</code>：这个是解释从哪个网站跳转的</p>\n<p><code>User-Agent</code>：包含了请求主机的信息，包括系统信息和浏览器信息，如果要伪装成浏览器，这个参数很重要</p>\n<p><code>Cookie</code>：这个分为<code>请求cookie</code>和<code>响应cookie</code>，分开使用</p>\n<p><code>host</code>：请求域名</p>\n<p><code>Connection</code>：是否保持连接，例如<code>keep-alive</code>，<code>close</code></p>\n<p><code>Upgrade-Insecure-Requests</code>：升级为<code>https</code></p>\n</blockquote>\n<p><strong>关于响应头的一些参数意义</strong> - 响应头一般是返回参数，主要看请求头</p>\n<blockquote>\n<p><code>Set-Cookie</code>：设置的<code>cookie</code></p>\n<p>状态码：200表示成功，但是，一般不要关注状态码，因为其不可信</p>\n</blockquote>\n<p><strong>常见的单词意义</strong></p>\n<blockquote>\n<p><code>token</code>：这个是一般为了保持的浏览器的连接性</p>\n</blockquote>\n<p><strong>注意事项</strong></p>\n<blockquote>\n<p>上面的<code>host</code>是域名，不一定是请求<code>url</code>，请求url看下面图</p>\n<blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008032.png\" alt=\"image-20211201194750582\"></p>\n</blockquote>\n</blockquote>\n<p><strong>其他帮助网站合集</strong></p>\n<blockquote>\n<ul>\n<li><p><a href=\"https://www.json.cn/\">在线字符串转<code>json</code></a></p>\n</li>\n<li><p><strong>免费代理站点</strong></p>\n<blockquote>\n<p><a href=\"https://www.kuaidaili.com/free/\">国内免费代理站点1</a></p>\n<p><a href=\"https://proxy.mimvp.com/freeopen\">国内免费代理站点2</a></p>\n<p><a href=\"https://www.89ip.cn/index.html\">国内免费代理站点3</a></p>\n</blockquote>\n</li>\n<li></li>\n</ul>\n</blockquote>\n</blockquote>\n<h2 id=\"3、爬虫入门一\"><a href=\"#3、爬虫入门一\" class=\"headerlink\" title=\"3、爬虫入门一\"></a>3、爬虫入门一</h2><blockquote>\n<p><strong>注意请求头中的一些参数</strong></p>\n<ul>\n<li><code>User-Agent</code>：包含了很多参数，如浏览器数据，系统数据等</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">headers = &#123;</span><br><span class=\"line\">  <span class=\"string\">&#x27;User-Agent&#x27;</span>: <span class=\"string\">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36&#x27;</span>  <span class=\"comment\"># 最好不要加到这一行的值，因为会报错，不明白为什么</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">headers = &#123;</span><br><span class=\"line\">  <span class=\"string\">&#x27;User-Agent&#x27;</span>: <span class=\"string\">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)&#x27;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">response1 = requests.get(url, headers=headers)</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p><strong>发送带参数的请求</strong></p>\n<ul>\n<li><code>url</code>直接带参数</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># http://www.baidu.com/s?ie=utf-8&amp;f=8&amp;rsv_bp=1&amp;rsv_idx=1&amp;tn=baidu&amp;wd=python&amp;fenlei=256&amp;rsv_pq=8cb91fd5000035bd&amp;rsv_t=368aR6DDwiiYX59pfDu4vQz2%2FajgsJuSG4IS8mBB5GeZwSo6Sn%2BjQuytYZM&amp;rqlang=cn&amp;rsv_enter=1&amp;rsv_dl=tb&amp;rsv_sug3=9&amp;rsv_sug1=7&amp;rsv_sug7=101&amp;rsv_sug2=0&amp;rsv_btype=i&amp;prefixsug=python&amp;rsp=5&amp;inputT=2667&amp;rsv_sug4=6046</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 如上面这个连接，可以尝试删掉一下不要的参数，最终得到下面这个</span></span><br><span class=\"line\"><span class=\"comment\"># http://www.baidu.com/s?wd=python</span></span><br><span class=\"line\"><span class=\"comment\"># 这个才是关键，然后进行get请求</span></span><br><span class=\"line\">url = <span class=\"string\">&#x27;http://www.baidu.com/s?wd=python&#x27;</span></span><br><span class=\"line\">headers = &#123;</span><br><span class=\"line\">    <span class=\"string\">&#x27;User-Agent&#x27;</span>: <span class=\"string\">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)&#x27;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"comment\">##  注意，get请求不要使用https</span></span><br><span class=\"line\">response = requests.get(url, headers=headers)</span><br></pre></td></tr></table></figure>\n</blockquote>\n<ul>\n<li>使用<code>params</code>携带参数字典</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">url = <span class=\"string\">&#x27;http://www.baidu.com/s?&#x27;</span>  <span class=\"comment\"># 注意这里需要加上s?，这个是百度的特性</span></span><br><span class=\"line\">data = &#123;</span><br><span class=\"line\"> <span class=\"string\">&#x27;wd&#x27;</span>: <span class=\"string\">&#x27;python&#x27;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">heads = &#123;<span class=\"string\">&#x27;User-Agent&#x27;</span>: <span class=\"string\">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)&#x27;</span>&#125;</span><br><span class=\"line\">response = requests.get(url, params=data, headers=heads)</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p><strong>携带<code>cookie</code>信息，<code>cookie</code>一般有时效性，过段时间需要重新获取</strong></p>\n<ul>\n<li>以<code>github</code>为列</li>\n</ul>\n<blockquote>\n<p>见下列图片，浏览器抓包</p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008253.png\" alt=\"image-20211201111147337\"></p>\n</blockquote>\n<ul>\n<li>在<code>headers</code>携带</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">headers=&#123;</span><br><span class=\"line\"> <span class=\"string\">&#x27;cookie&#x27;</span>: <span class=\"string\">&#x27;xxxx&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;User-Agent&#x27;</span>: <span class=\"string\">&#x27;xxxx&#x27;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</blockquote>\n<ul>\n<li>使用<code>cookie</code>参数来保持</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 构建cookie字典</span></span><br><span class=\"line\"><span class=\"comment\"># 需要先切割键值对</span></span><br><span class=\"line\"><span class=\"comment\"># 如下列cookie</span></span><br><span class=\"line\">cookies = <span class=\"string\">&#x27;_octo=GH1.1.612724434.1638322138; tz=Asia/Shanghai; _device_id=5fa9f396b9f0691f8db3054f0b87dbb9; has_recent_activity=1; user_session=03yOITMxPd4lG6qXwYYs9QEaFPgu2hxw04gHIymweU4J1EEe; __Host-user_session_same_site=03yOITMxPd4lG6qXwYYs9QEaFPgu2hxw04gHIymweU4J1EEe; tz=Asia/Shanghai; color_mode=&#123;&quot;color_mode&quot;:&quot;auto&quot;,&quot;light_theme&quot;:&#123;&quot;name&quot;:&quot;light&quot;,&quot;color_mode&quot;:&quot;light&quot;&#125;,&quot;dark_theme&quot;:&#123;&quot;name&quot;:&quot;dark&quot;,&quot;color_mode&quot;:&quot;dark&quot;&#125;&#125;; logged_in=yes; dotcom_user=HF-Mfeng; _gh_sess=Bvk3bQRV+XfUQlh+l8Mu2MKWcl7O+LH3nLtnVSWOFvzAo50NycqAlQFAYbNMdXfpVAxSU08+65qeCVG2+wX97z/sjsdsI2grX7uXpIWvFpAi/pOBPyt4dXjNRT5n2o2VTvCgIP2mWQEXTg7HVjs3v16QCj/eUFbd460btIb6J1NG/DY1wW7jx8/VAS2vkFVZ7uTkoljKQdcs8K7oAndejxw7f3fdBKCybeghEIqu71SonF5C774enN5nq2zNtSILtA7lEA+s72ekWtLrFkzRpAoi+rzQLR2naFzIXCuFbbCdsLj7tNRAF8Uj0vyRn29LdqxbjMsssMmiiBVi81x3Vf7awZRHhjp2jzMINq+J3grHfOyjgwer1XRXkUW4RaIayrC60XOl/NG5tOPUmPCHqDkHhAyFx3TRVxhz84a+oxBSW9PJK4ebYu2sZrA3nCOdRkPDvEoMehgxhZuOz07e8usCuKc//p/tozi/WI+CuPWjYamF3Hyv1uYt4C1sKjZbhNzH3sjd+9hD5DP33IROZWlvCM4W2PWmq6RWyC5B1Dyk8pAq89W87dsdm5W2eyMo/xNLdwZi+o8cXkJROi8W/XQa6NwRWlh9yON+xl3L9Txtesvi3mlB7b1L+ic/XR4f7Wh8C59yeyY67lijumG/qfX0F8w3H76BPnlmbH9oxL4qRkWwVSflal4LjRhgOaoiCZzs1r6oellyNV6pPilm7QRbP7KEnq+R+PusPQsDBWn4Gej/vbQ2P9cwqW9EQr+VhsV6MHUvhuGAY8MRB5eBKtxrhqXZMiLYak0Pk82cl9oesvU5tqp3xNo2VNHWXt5uM6YLQTggbG+spmuxqnbHt481AoMUNnRcN6WomLZ4vS4pYXO5NLa58uk9slgT/3iwPEWsy7HuK5FLYqcMvPTGNeO+nYs=--c91BUqTy9ZXXOfRr--YhanrwguBRPMP5S/I3ig0A==&#x27;</span></span><br><span class=\"line\">cookies = cookies.splie(<span class=\"string\">&quot;; &quot;</span>)</span><br><span class=\"line\">cookies_ = &#123;&#125;</span><br><span class=\"line\"><span class=\"keyword\">for</span> cookie <span class=\"keyword\">in</span> cookies:</span><br><span class=\"line\"> cookies_[cookie.split(<span class=\"string\">&#x27;=&#x27;</span>)[<span class=\"number\">0</span>]] = cookie.splie(<span class=\"string\">&#x27;=&#x27;</span>)[-<span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 其中有许多的等号，如_octo=GH1.1.612724434.1638322138，就是一个键值对</span></span><br><span class=\"line\">respose = requests.get(url,headers=headers,cookies=cookies_)</span><br></pre></td></tr></table></figure>\n</blockquote>\n<ul>\n<li><code>cookieJar</code>对象转换成<code>cookie</code>字典，一般用不到</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 什么是cookieJar对象呢，如下</span></span><br><span class=\"line\">requests.get(url).cookie\t\t<span class=\"comment\"># 这个就是cookieJar对象</span></span><br><span class=\"line\">dict_cookies = requests.utils.dict_from_cookiejar(response.cookies)   <span class=\"comment\"># cookiejar转换成字典</span></span><br><span class=\"line\"></span><br><span class=\"line\">jar_cookies = requests.utils.cookiesjar_from_dict(dict_cookies)  <span class=\"comment\"># 重新转化成cookiejar</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</blockquote>\n<p><strong><code>timeout</code>的用法</strong></p>\n<ul>\n<li>设置一下</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">wresponse = requests.get(url, timeout=<span class=\"number\">3</span>)  <span class=\"comment\"># 设为3s，一般设个十秒左右就好</span></span><br></pre></td></tr></table></figure>\n\n\n</blockquote>\n<p><strong>代理<code>Proxy</code></strong></p>\n<blockquote>\n<p>代理分为正向代理和反向代理</p>\n<p>代理还分为透明代理、匿名代理、高匿代理</p>\n<ul>\n<li>透明代理</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">REMOTE_ADDR = Proxy IP</span><br><span class=\"line\">HTTP_VIA = Proxy IP</span><br><span class=\"line\">HTTP_X_FORWARDED_FOR = Your IP</span><br></pre></td></tr></table></figure>\n</blockquote>\n<ul>\n<li>匿名代理</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">REMOTE_ADDR = Proxy IP</span><br><span class=\"line\">HTTP_VIA = Proxy IP</span><br><span class=\"line\">HTTP_X_FORWARDED_FOR = Proxy IP</span><br></pre></td></tr></table></figure>\n</blockquote>\n<ul>\n<li>高匿代理</li>\n</ul>\n<blockquote>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">REMOTE_ADDR = Proxy IP</span><br><span class=\"line\">HTTP_VIA = not determined</span><br><span class=\"line\">HTTP_X_FORWARDED_FOR = not determined</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p>代理还可分为，<code>http、https、socks</code></p>\n<ul>\n<li><code>http</code>：目标<code>url</code>为<code>http</code>协议</li>\n<li><code>https</code>：目标<code>url</code>为<code>https</code>协议</li>\n<li><code>socks</code>：只传递数据包，不在乎什么应用协议，耗时少</li>\n</ul>\n<p><strong>用法</strong></p>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">proxies = &#123;</span><br><span class=\"line\"> <span class=\"string\">&#x27;http&#x27;</span>: <span class=\"string\">&#x27;http://127.0.0.1:7890&#x27;</span>,</span><br><span class=\"line\"> <span class=\"string\">&#x27;https&#x27;</span>: <span class=\"string\">&#x27;http://127.0.0.1:7890&#x27;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">response = requests.get(url, proxies=proxies)</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://www.kuaidaili.com/free/\">国内免费代理站点1</a></p>\n<p><a href=\"https://proxy.mimvp.com/freeopen\">国内免费代理站点2</a></p>\n<p><a href=\"https://www.89ip.cn/index.html\">国内免费代理站点3</a></p>\n</blockquote>\n<ul>\n<li>并且代理站点可能会给你添加一下信息，使得你更像一个浏览器</li>\n<li>代理也有可能截获你的数据，所以这个也要注意</li>\n</ul>\n</blockquote>\n<p><strong><code>verify</code>忽略<code>CA</code>证书</strong></p>\n<blockquote>\n<p>很多情况如下图所示</p>\n<blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052008307.png\" alt=\"image-20211201192347257\"></p>\n</blockquote>\n<p>爬虫过程遇到下列情况</p>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">requests.exceptions.SSLError: HTTPSConnection.....</span><br></pre></td></tr></table></figure>\n</blockquote>\n<p>设置为<code>False</code>即可</p>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 默认是True，设置为False</span></span><br><span class=\"line\"><span class=\"comment\"># 运行过程会报警告的，但是 don&#x27;t worry it 爬虫还是可以爬取内容的</span></span><br><span class=\"line\">response = requests.get(url, verify=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n</blockquote>\n</blockquote>\n<p><strong><code>post</code>请求</strong></p>\n<blockquote>\n<p><code>post</code>用途</p>\n<ul>\n<li>一般有账号密码，都会使用<code>post</code>请求，因为<code>get</code>请求是在<code>url</code>中的明文</li>\n<li>大文件以及多数据，都是使用<code>post</code></li>\n<li><code>web</code>工程师会认为<code>post</code>比<code>get</code>请求更加安全</li>\n</ul>\n<p>简单实现</p>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">respose = requests.post(url, data) <span class=\"comment\"># data是一个字典</span></span><br></pre></td></tr></table></figure>\n</blockquote>\n<p>找<code>data</code>的步骤寻找固定值：一般来说浏览器抓抓包就知道了</p>\n<ul>\n<li>寻找输入值：也一般来说浏览器抓抓包就知道了</li>\n<li>寻找预设值 - 静态文件：一般来说，需要从<code>html</code>文件中搜索，可以尝试，这个是反爬的</li>\n<li>寻找预设值 - 发请求：需要对指定地址发送请求</li>\n<li>寻找动态生成值：一般是客户端生成的，反爬的重点，一般采用<code>Javascript</code>生成</li>\n</ul>\n<p><code>data</code>反爬套路</p>\n<ul>\n<li>模仿其他浏览器发送，如手机什么的，因为很多浏览器都是不一样的反爬，找个弱的</li>\n<li>注意时间戳什么的</li>\n<li>注意里面的<code>JS</code>文件</li>\n<li>有些可能是随机值</li>\n<li>从<code>html</code>提取，可以试试无痕浏览器</li>\n</ul>\n</blockquote>\n<p><strong><code>requess.session</code>状态保持</strong></p>\n<ul>\n<li>自动保持<code>cookie</code>，一般多次请求（如登录之后再操作的），使用方法</li>\n</ul>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">session = requests.session()</span><br><span class=\"line\">session.headers = &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">session.data = &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">response = session.get(url)</span><br><span class=\"line\">response = session.post(url)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 如下用法</span></span><br><span class=\"line\">s = rq.session()</span><br><span class=\"line\">s.trust_env</span><br><span class=\"line\">s.verify</span><br><span class=\"line\">s.headers</span><br><span class=\"line\">s.proxies</span><br><span class=\"line\">s.cookies</span><br><span class=\"line\">s.get(url, data=data)</span><br><span class=\"line\">s.post(url, data=data)</span><br></pre></td></tr></table></figure>\n</blockquote>\n</blockquote>\n<h2 id=\"正则表达式，这个也是重点\"><a href=\"#正则表达式，这个也是重点\" class=\"headerlink\" title=\"正则表达式，这个也是重点\"></a>正则表达式，这个也是重点</h2><blockquote>\n<p><strong>首先如何使用正则表达式</strong></p>\n<blockquote>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">response = requests.get(url)</span><br><span class=\"line\">restr = response.content.decode()   <span class=\"comment\"># 转成utf-8或者gbk</span></span><br><span class=\"line\"><span class=\"comment\"># 正则提取</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> re  <span class=\"comment\"># 导入正则模块</span></span><br><span class=\"line\">str_tmp = <span class=\"string\">&quot;&lt;link href=\\&quot;https://stacdn.proginn.com/plugin/swiper/swiper.min.css?version=4.30.2\\&quot; rel=\\&quot;stylesheet\\&quot; type=\\&quot;text/css\\&quot;&gt;&quot;</span>   <span class=\"comment\"># 临时字符串，不用写到代码里</span></span><br><span class=\"line\"><span class=\"comment\"># 假如想要获取上面中的href，那么这样写正则表达式</span></span><br><span class=\"line\"><span class=\"comment\"># 正则</span></span><br><span class=\"line\">restr = <span class=\"string\">&#x27;&lt;link href=\\&quot;(.*?)\\&quot; rel=\\&quot;stylesheet\\&quot; type=\\&quot;text/css\\&quot;&gt;&#x27;</span>   <span class=\"comment\"># 这个是以非贪婪模式匹配多个字符</span></span><br><span class=\"line\"><span class=\"comment\"># 然后匹配一下全文，看看是否获取了对应的</span></span><br><span class=\"line\">dst_list = re.findall(restr, str_tmp)   <span class=\"comment\"># 打印一下看看就知道了</span></span><br></pre></td></tr></table></figure>\n\n\n</blockquote>\n</blockquote>\n<h2 id=\"额外补充知识\"><a href=\"#额外补充知识\" class=\"headerlink\" title=\"额外补充知识\"></a>额外补充知识</h2><blockquote>\n<p><strong><code>form</code>表单</strong></p>\n<ul>\n<li>以<code>github</code>为例</li>\n<li>一般来说，<code>form</code>表单上面会有很多消息可挖掘，如下图所示</li>\n</ul>\n<blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052010824.png\" alt=\"image-20211201205057556\"></p>\n<ul>\n<li>其中，<code>action</code>指的是提交给的路径</li>\n<li><code>method</code>是提交方法</li>\n<li><code>token</code>这个一般用来表示保持的意思，同行的<code>value</code>表示<code>token</code>的值</li>\n<li>而下面这个<code>name</code>，就是输入标签将里面的值提交给什么了，这里是提交给<code>login</code></li>\n</ul>\n</blockquote>\n<p><strong>往往需要多次抓包，多次比较才行，找出差异</strong></p>\n<ul>\n<li>如在无痕串口进行多次退出和登录</li>\n<li>主要是为了找出<code>post</code>的变值（不包括输入值，除非输入值不是明文传输）</li>\n</ul>\n<p><strong>注意多次爬虫，需要注意页面的跳转</strong></p>\n<ul>\n<li>比如登录的时候，一般会跳转的</li>\n</ul>\n</blockquote>\n<h2 id=\"结束语\"><a href=\"#结束语\" class=\"headerlink\" title=\"结束语\"></a>结束语</h2><p>​        <strong>技术永远是好东西，只是拿来做什么</strong></p>\n"},{"title":"Python爬虫学习-更加友好的教程","cover":"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052018349.png","date":"2022-04-05T12:07:16.000Z","excerpt":"准备拿来社团授课的教程，比之前那一篇更加清晰一点","_content":"\n# `Python`爬虫入门教程\n\n---\n\n## 基础知识\n\n### 什么是`HTML、CSS、JavaScript`\n\n> 网页往往采用`html+css+js`开发，`html`是一门标记语言\n>\n> 如下：\n>\n> ```html\n> <!- 将下面这句话放入html文件中，-->\n> <!- 然后浏览器就会将这句话解释为下面那张图片，-->\n> <!- 这个就是浏览器渲染的功能-->\n> <!- 这里我们知道了一个词——浏览器的渲染   -->\n> <!- 并且我们发现，浏览器会在下面这个网址 自动 -->\n> <!- 把这张图片下载下来，然后渲染给我们看，这在我们之后抓包会有用 -->\n> <img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019260.png\"\n> width=\"300px\">\n> ```\n>\n> <img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019260.png\" width=\"300px\">\n\n### 什么是请求，什么是响应\n\n> 请求：就是前端向后端发送一个请求，如请求我的账户浏览记录\n>\n> 响应：就是后端向前端发送一个响应，你请求你的账户浏览器记录，那么我把记录发给你，叫做响应\n>\n> `JavaScript`中有请求，浏览器渲染到其中的请求，就会向后端发送请求\n\n### 什么是`GET`，什么是`POST`\n\n> 这个是两种请求方式而已，`get`直接把请求数据放在链接里面，`post`一般以则不是\n\n### 什么是`Cookie`\n\n> 曲奇饼干？不是\n>\n> 打个比方，大家申请出校，需要在手机上申请，然后今天一天都可以通过刷脸进出校园\n>\n> 那么，在手机上申请相当于告诉学校后端，你请求了进出校权限。也相当于，你在网页上登录账户密码\n>\n> 然后，你一天可以通过刷脸，这个刷脸就是`cookie`，今天进出校园不需要再申请了\n>\n> 这个就是`cookie`的作用，最常见的就是，不需要每次点开一个页面都进行账户密码登录\n\n### `Python`基本语法\n\n> 这个本该大家自己去学习的，但是这里说好基础入门，就简单提一点点\n>\n> ```python\n> a = 1\n> b = 2\n> # if结构\n> if a > b:\n>  print(\"a大于b\")\n> else:\n>  print(\"a不大于b\")\n> \n> # while循环\n> while True:\n>  print(\"这里面是while循环\")\n> \n> # 列表和字典\n> m = [\"hello\", 2, 4.5]  # 列表支持不同数据类型，并且可以随意扩充和删减\n> n = {\t\t\t# 字典里面每个元素都是   键值:值   组成\n>  \"key1\": 3,\n>  \"key3\": \"hello\"\n> }\n> m[0]    ## 索引到第0个元素，即 \"hello\"\n> n[\"key1\"]   ## 索引到键值为\"key1\"的值，即 3\n> ```\n\n### 什么是抓包\n\n> 打个比方：你要向某人发一条数据，我在你们之间截获了或者记录了你们的数据，这个叫做抓包\n>\n```mermaid\ngraph LR\nA(数据发送者) -->B[抓包者]\nB -->C(数据接收者)\n```\n>\n> **那么我们需要抓什么包呢？抓包的用处在哪呢？**\n>\n> 答：我们需要抓取浏览器和后端服务器通信的包；用处是分析他们的数据然后用代码进行伪造数据发送，以便获得和浏览器同样的响应\n\n### 什么是代理\n\n> 不进行代理应该是下列图：\n>\n```mermaid\ngraph LR\nA(前台客户端)-->|发送请求|C[后台服务器]\nC -->|返回响应|A\n```\n>\n> \n>\n> 代理就是如下：\n>\n```mermaid\ngraph LR\nA(前台客户端)-->|发送请求|B[代理服务器]\nB -->|转发请求|C(后台服务器)\nC -->|返回响应|B\nB -->|转发响应|A\n```\n\n### 如何伪造呢？\n\n> 1、一般网站开发者希望我们使用浏览器浏览他们的网站，不希望我们使用代码进行浏览\n>\n> 2、欸，但我就想用代码进行浏览，怎么办呢？\n>\n> 3、那么就需要将我们的代码尽量伪装成浏览器，让后端以为我们是浏览器\n>\n> 4、具体就是抓包，分析数据，用代码发送请求\n\n---\n\n## 浏览器抓包\n\n### 进入调试模式\n\n> 打开某个浏览器，按下键盘上的<kbd>F12</kbd>键，进入调试模式\n>\n> ![image-20211219160806912](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019536.png)\n>\n> 一般用得到上面四个红圈里面的内容，建议跟我一样，将这个调试界面放到右侧，不然之后找不到对应的按钮（仅代表个人习惯）。\n> 如果是英文的，也不要担心，相信这点英文应该看得懂，看不懂应该也能找到相应位置，还可以自行百度怎么换成中文哦。\n>\n> <img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019319.png\" width=\"300px\">\n\n> - 红圈1、找到页面上的元素分别对应哪句`html`标签\n> - 红圈2、主要看<kbd>元素</kbd>和<kbd>网络</kbd>两个\n> - 红圈3、左边如果是红色表示正在抓包记录，右边是清除已经抓到的包记录\n> - 红圈4、一般我喜欢直接点选<kbd>全部</kbd>这个按钮，其他的是过滤数据的类型\n\n### 如何寻找数据呢？\n\n> ![image-20211219162409621](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019519.png)\n>\n> 我们首先需要伪造成浏览器，发送请求标头，然后分析一下响应的数据，这个就是一个抓包过程啦\n>\n> 听起来是不是很简单呢？\n>\n> <kbd>简单</kbd> 打在公屏上\n\n---\n\n## 分析数据\n\n### 浏览器人性化查看数据\n\n> <center><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052033311.png\" width=\"450px\"><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052033151.png\" width=\"450px\"></center>\n>\n> 第一张图和第二张图有所区别，多了一个<kbd>载荷</kbd>选项，因为第二张图是在百度翻译上面抓的\n>\n> 第二张图发送请求时候带了参数，所以比第一张图多了<kbd>载荷</kbd>选项\n\n### 分析请求标头\n\n> **这么多的数据，我应该怎么办呢？**\n>\n> - `User-Agent`：这个相当于浏览器标识，看你是什么浏览器发送的，我们直接用这个就行`Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36`，这个代表是`chrome`浏览器的标识\n> - `Referer`：它其实是`refer`，就是代表这个网也从哪个网页来的\n> - `cookie`：就是`cookie`，前面基础知识提到过\n> - `请求网址`：就是你向哪个网址发送请求，请求的对象是哪个\n>\n> **查看载荷**\n>\n> 如上面第二张图中的请求网址是：![image-20211219170540421](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019090.png)\n>\n> 分为前后两部分组成，后面那部分就是载荷了，它是多个<kbd>字符串参数</kbd>，然后它是这么个形式：<kbd>键值=值</kbd> 组成的\n>\n> 多个<kbd>字符串参数</kbd>用`&`链接起来，把他人性化一点查看就是这样：<kbd>字符串参数</kbd>\n>\n> ![image-20211219170645219](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019096.png)\n>\n> **POST请求不仅仅只有请求头还有请求数据**\n>\n> 下面是百度翻译的`post`请求的载荷\n>\n> ![image-20211219170803923](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019112.png)\n>\n> 上面和`get`请求一样，是<kbd>字符串参数</kbd>，下面就是<kbd>表单数据</kbd>，这个是很重要的一个部分\n\n这些都是基础概念，之后会用到，现在先学学\n\n### 分析响应数据\n\n> 响应数据多种多样，常见的有：`html`文本，图片文件，表单数据，视频文件等等\n>\n> 其中，图片文件和视频文件等都是二进制格式\n>\n> `html`文本和表单数据是文本格式\n\n> - `html`文本\n>\n> 一般都需要请求这个，它会告诉浏览器需要<kbd>渲染</kbd>什么，如下载哪张图片，下载哪个音频，下载哪个文件等等\n>\n> 我们一般都需要分析一下这个文件\n>\n> - 图片文件\n>\n> 直接以二进制的形式写入本地就相当于下载下来\n>\n> - 表单数据\n>\n> 返回的数据中一般带有我们需要的数据，如翻译的请求，就会把翻译的结果再以表单的形式返回了\n\n## 代码编写\n\n有了上述的知识，可以进行代码编写，其实完全可以先进行代码编写，然后再去上述补充基本知识，这个顺序可以根据大家喜好来看。\n\n[***`requests`教程***](https://docs.python-requests.org/zh_CN/latest/user/quickstart.html)\n\n#### 导入`requests`包\n\n> 下载：`pip install requests`\n>\n> 导入：`import requests`\n>\n> `emmmmm `怎么说呢，这个好像不如跟着视频里面做一遍，虽然我还没有录视频，但是聪明的你们肯定会上百度吧\n\n#### `requests`包的使用\n\n> 这个教程顺序可能和网上很多都不一样\n>\n> ```python\n> import requests as rq\n> import json\n> import re\n> \n> tool = rq.session()   # 这个会返回一个爬虫工具箱，并且它会自动维持cookie\n> \n> verify=False   # 设置是否进行SSL验证，一般设置为否\n> url=\"https://baidu.com\"  # 这里请求百度的数据\n> headers={   # 设置请求头\n>  \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/\"\n>   \"537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\",\n> }\n> proxies={    # 设置代理\n>  \"http\": None,\n>  \"https\": None\n> }\n> params={   # 设置字符串参数\n> \n> }\n> data={  # 设置请求表单\n> \n> }\n> \n> # 发送get请求，得到get响应\n> responseGet = tool.get(url=url, params=params, headers=headers, verify=verify, proxies=proxies)\n> # 发送post请求，得到post响应\n> responsePost = tool.post(url=url, data=data, headers=headers, verify=verify, proxies=proxies)\n> \n> # 解析响应\n> # 1、假如响应是文本数据，如html文本\n> response = responseGet\n> response.content # 这个是内容，是二进制编码\n> response.content.decode(\"gbk\")  # 使用gbk解码，不加参数就是utf-8解码\n> # 2、假如响应是图片数据\n> with open(\"1.png\", \"wb\") as f:\n>  f.write(response.content)   # 直接以二进制写入文件\n> # 3、假如响应是表单数据\n> dat = json.loads(response.content.decode())   # 返回的就是一个字典数据了\n> \n> ```\n\n#### 正则表达式简单用法\n\n> 爬虫中的正则表达式一般会比较简单\n>\n> ```python\n> import re   # 导入正则表达式包\n> # 假如有下列字符串需要被匹配\n> # str1 = \"<link href=\"https://stacdn.proginn.com/plugin/swiper/swiper.min.css?version=4.30.2\"\n> # rel=\"stylesheet\" type=\"text/css\">\"\n> # 其中href中的是我们需要的那么\n> html = response.content.decode()\n> restr = \"<link\\\\shref=\\\"(.*?)\\\"\\\\srel=\\\"stylesheet\\\"\\\\stype=\\\"text/css\\\">\"\n> dst_list = re.findall(restr, html)   # 返回一个列表\n> # 上面这条语句，会将html里面所有形如str1中的href都返回到列表中\n> \n> # 假如我们是要爬取妹妹图，那么就把当前页面所有的妹妹图的网址都保存到列表了\n> # 只需要进行如下操作遍历列表就行\n> for pngurl in dst_list:\n>  print(pngurl)\n> ```\n\n---\n\n# 结束语\n\n​\t\t爬虫会涉及到有关法律问题，这里不作讨论，但是希望大家不要拿来干坏事。***概不负责***。\n\n​\t\t爬虫与反爬、反反爬一直都在相互进行着，是相互迭代的过程，爬虫重点在于数据分析而不是代码编写。\n\n​\t\t本课程涉及的只是非常非常简单的爬虫，还有很多很多爬虫知识需要后续的学习，爬虫涉及的知识太广了，不是一堂课能够讲的清楚的。涵盖网络知识、密码知识、前后端工作方式、编码格式等等。之后应该学校课程有一门叫做<kbd>《计算机网络技术》</kbd>，我个人感觉这门课程非常重要，但是其实学校老师讲的可能`emmmmmm...`。大家可以课外多花时间学习，不管之后是嵌入式，物联网，互联网，软件开发，网络安全、科学上网等等方向都需要用到计算机网络的知识。\n\n​\t\t任重而道远，我学这个是凭借着兴趣而学习，所以更多的知识还是得看自己慢慢学。之后我如果有时间，应该会录制两三个爬虫例子。如爬取二次元桌面图片、一键登录校园网、获取天气预报、打造一个翻译官等等。\n","source":"_posts/Python爬虫学习——面向初学者.md","raw":"---\ntitle: Python爬虫学习-更加友好的教程\ncover: 'https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052018349.png'\ndate: 2022-04-05 20:07:16\ntags:\n  - Python\n  - 爬虫\nexcerpt: '准备拿来社团授课的教程，比之前那一篇更加清晰一点'\ncategories: \n  - Python\n  - 爬虫\n---\n\n# `Python`爬虫入门教程\n\n---\n\n## 基础知识\n\n### 什么是`HTML、CSS、JavaScript`\n\n> 网页往往采用`html+css+js`开发，`html`是一门标记语言\n>\n> 如下：\n>\n> ```html\n> <!- 将下面这句话放入html文件中，-->\n> <!- 然后浏览器就会将这句话解释为下面那张图片，-->\n> <!- 这个就是浏览器渲染的功能-->\n> <!- 这里我们知道了一个词——浏览器的渲染   -->\n> <!- 并且我们发现，浏览器会在下面这个网址 自动 -->\n> <!- 把这张图片下载下来，然后渲染给我们看，这在我们之后抓包会有用 -->\n> <img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019260.png\"\n> width=\"300px\">\n> ```\n>\n> <img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019260.png\" width=\"300px\">\n\n### 什么是请求，什么是响应\n\n> 请求：就是前端向后端发送一个请求，如请求我的账户浏览记录\n>\n> 响应：就是后端向前端发送一个响应，你请求你的账户浏览器记录，那么我把记录发给你，叫做响应\n>\n> `JavaScript`中有请求，浏览器渲染到其中的请求，就会向后端发送请求\n\n### 什么是`GET`，什么是`POST`\n\n> 这个是两种请求方式而已，`get`直接把请求数据放在链接里面，`post`一般以则不是\n\n### 什么是`Cookie`\n\n> 曲奇饼干？不是\n>\n> 打个比方，大家申请出校，需要在手机上申请，然后今天一天都可以通过刷脸进出校园\n>\n> 那么，在手机上申请相当于告诉学校后端，你请求了进出校权限。也相当于，你在网页上登录账户密码\n>\n> 然后，你一天可以通过刷脸，这个刷脸就是`cookie`，今天进出校园不需要再申请了\n>\n> 这个就是`cookie`的作用，最常见的就是，不需要每次点开一个页面都进行账户密码登录\n\n### `Python`基本语法\n\n> 这个本该大家自己去学习的，但是这里说好基础入门，就简单提一点点\n>\n> ```python\n> a = 1\n> b = 2\n> # if结构\n> if a > b:\n>  print(\"a大于b\")\n> else:\n>  print(\"a不大于b\")\n> \n> # while循环\n> while True:\n>  print(\"这里面是while循环\")\n> \n> # 列表和字典\n> m = [\"hello\", 2, 4.5]  # 列表支持不同数据类型，并且可以随意扩充和删减\n> n = {\t\t\t# 字典里面每个元素都是   键值:值   组成\n>  \"key1\": 3,\n>  \"key3\": \"hello\"\n> }\n> m[0]    ## 索引到第0个元素，即 \"hello\"\n> n[\"key1\"]   ## 索引到键值为\"key1\"的值，即 3\n> ```\n\n### 什么是抓包\n\n> 打个比方：你要向某人发一条数据，我在你们之间截获了或者记录了你们的数据，这个叫做抓包\n>\n```mermaid\ngraph LR\nA(数据发送者) -->B[抓包者]\nB -->C(数据接收者)\n```\n>\n> **那么我们需要抓什么包呢？抓包的用处在哪呢？**\n>\n> 答：我们需要抓取浏览器和后端服务器通信的包；用处是分析他们的数据然后用代码进行伪造数据发送，以便获得和浏览器同样的响应\n\n### 什么是代理\n\n> 不进行代理应该是下列图：\n>\n```mermaid\ngraph LR\nA(前台客户端)-->|发送请求|C[后台服务器]\nC -->|返回响应|A\n```\n>\n> \n>\n> 代理就是如下：\n>\n```mermaid\ngraph LR\nA(前台客户端)-->|发送请求|B[代理服务器]\nB -->|转发请求|C(后台服务器)\nC -->|返回响应|B\nB -->|转发响应|A\n```\n\n### 如何伪造呢？\n\n> 1、一般网站开发者希望我们使用浏览器浏览他们的网站，不希望我们使用代码进行浏览\n>\n> 2、欸，但我就想用代码进行浏览，怎么办呢？\n>\n> 3、那么就需要将我们的代码尽量伪装成浏览器，让后端以为我们是浏览器\n>\n> 4、具体就是抓包，分析数据，用代码发送请求\n\n---\n\n## 浏览器抓包\n\n### 进入调试模式\n\n> 打开某个浏览器，按下键盘上的<kbd>F12</kbd>键，进入调试模式\n>\n> ![image-20211219160806912](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019536.png)\n>\n> 一般用得到上面四个红圈里面的内容，建议跟我一样，将这个调试界面放到右侧，不然之后找不到对应的按钮（仅代表个人习惯）。\n> 如果是英文的，也不要担心，相信这点英文应该看得懂，看不懂应该也能找到相应位置，还可以自行百度怎么换成中文哦。\n>\n> <img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019319.png\" width=\"300px\">\n\n> - 红圈1、找到页面上的元素分别对应哪句`html`标签\n> - 红圈2、主要看<kbd>元素</kbd>和<kbd>网络</kbd>两个\n> - 红圈3、左边如果是红色表示正在抓包记录，右边是清除已经抓到的包记录\n> - 红圈4、一般我喜欢直接点选<kbd>全部</kbd>这个按钮，其他的是过滤数据的类型\n\n### 如何寻找数据呢？\n\n> ![image-20211219162409621](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019519.png)\n>\n> 我们首先需要伪造成浏览器，发送请求标头，然后分析一下响应的数据，这个就是一个抓包过程啦\n>\n> 听起来是不是很简单呢？\n>\n> <kbd>简单</kbd> 打在公屏上\n\n---\n\n## 分析数据\n\n### 浏览器人性化查看数据\n\n> <center><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052033311.png\" width=\"450px\"><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052033151.png\" width=\"450px\"></center>\n>\n> 第一张图和第二张图有所区别，多了一个<kbd>载荷</kbd>选项，因为第二张图是在百度翻译上面抓的\n>\n> 第二张图发送请求时候带了参数，所以比第一张图多了<kbd>载荷</kbd>选项\n\n### 分析请求标头\n\n> **这么多的数据，我应该怎么办呢？**\n>\n> - `User-Agent`：这个相当于浏览器标识，看你是什么浏览器发送的，我们直接用这个就行`Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36`，这个代表是`chrome`浏览器的标识\n> - `Referer`：它其实是`refer`，就是代表这个网也从哪个网页来的\n> - `cookie`：就是`cookie`，前面基础知识提到过\n> - `请求网址`：就是你向哪个网址发送请求，请求的对象是哪个\n>\n> **查看载荷**\n>\n> 如上面第二张图中的请求网址是：![image-20211219170540421](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019090.png)\n>\n> 分为前后两部分组成，后面那部分就是载荷了，它是多个<kbd>字符串参数</kbd>，然后它是这么个形式：<kbd>键值=值</kbd> 组成的\n>\n> 多个<kbd>字符串参数</kbd>用`&`链接起来，把他人性化一点查看就是这样：<kbd>字符串参数</kbd>\n>\n> ![image-20211219170645219](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019096.png)\n>\n> **POST请求不仅仅只有请求头还有请求数据**\n>\n> 下面是百度翻译的`post`请求的载荷\n>\n> ![image-20211219170803923](https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019112.png)\n>\n> 上面和`get`请求一样，是<kbd>字符串参数</kbd>，下面就是<kbd>表单数据</kbd>，这个是很重要的一个部分\n\n这些都是基础概念，之后会用到，现在先学学\n\n### 分析响应数据\n\n> 响应数据多种多样，常见的有：`html`文本，图片文件，表单数据，视频文件等等\n>\n> 其中，图片文件和视频文件等都是二进制格式\n>\n> `html`文本和表单数据是文本格式\n\n> - `html`文本\n>\n> 一般都需要请求这个，它会告诉浏览器需要<kbd>渲染</kbd>什么，如下载哪张图片，下载哪个音频，下载哪个文件等等\n>\n> 我们一般都需要分析一下这个文件\n>\n> - 图片文件\n>\n> 直接以二进制的形式写入本地就相当于下载下来\n>\n> - 表单数据\n>\n> 返回的数据中一般带有我们需要的数据，如翻译的请求，就会把翻译的结果再以表单的形式返回了\n\n## 代码编写\n\n有了上述的知识，可以进行代码编写，其实完全可以先进行代码编写，然后再去上述补充基本知识，这个顺序可以根据大家喜好来看。\n\n[***`requests`教程***](https://docs.python-requests.org/zh_CN/latest/user/quickstart.html)\n\n#### 导入`requests`包\n\n> 下载：`pip install requests`\n>\n> 导入：`import requests`\n>\n> `emmmmm `怎么说呢，这个好像不如跟着视频里面做一遍，虽然我还没有录视频，但是聪明的你们肯定会上百度吧\n\n#### `requests`包的使用\n\n> 这个教程顺序可能和网上很多都不一样\n>\n> ```python\n> import requests as rq\n> import json\n> import re\n> \n> tool = rq.session()   # 这个会返回一个爬虫工具箱，并且它会自动维持cookie\n> \n> verify=False   # 设置是否进行SSL验证，一般设置为否\n> url=\"https://baidu.com\"  # 这里请求百度的数据\n> headers={   # 设置请求头\n>  \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/\"\n>   \"537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\",\n> }\n> proxies={    # 设置代理\n>  \"http\": None,\n>  \"https\": None\n> }\n> params={   # 设置字符串参数\n> \n> }\n> data={  # 设置请求表单\n> \n> }\n> \n> # 发送get请求，得到get响应\n> responseGet = tool.get(url=url, params=params, headers=headers, verify=verify, proxies=proxies)\n> # 发送post请求，得到post响应\n> responsePost = tool.post(url=url, data=data, headers=headers, verify=verify, proxies=proxies)\n> \n> # 解析响应\n> # 1、假如响应是文本数据，如html文本\n> response = responseGet\n> response.content # 这个是内容，是二进制编码\n> response.content.decode(\"gbk\")  # 使用gbk解码，不加参数就是utf-8解码\n> # 2、假如响应是图片数据\n> with open(\"1.png\", \"wb\") as f:\n>  f.write(response.content)   # 直接以二进制写入文件\n> # 3、假如响应是表单数据\n> dat = json.loads(response.content.decode())   # 返回的就是一个字典数据了\n> \n> ```\n\n#### 正则表达式简单用法\n\n> 爬虫中的正则表达式一般会比较简单\n>\n> ```python\n> import re   # 导入正则表达式包\n> # 假如有下列字符串需要被匹配\n> # str1 = \"<link href=\"https://stacdn.proginn.com/plugin/swiper/swiper.min.css?version=4.30.2\"\n> # rel=\"stylesheet\" type=\"text/css\">\"\n> # 其中href中的是我们需要的那么\n> html = response.content.decode()\n> restr = \"<link\\\\shref=\\\"(.*?)\\\"\\\\srel=\\\"stylesheet\\\"\\\\stype=\\\"text/css\\\">\"\n> dst_list = re.findall(restr, html)   # 返回一个列表\n> # 上面这条语句，会将html里面所有形如str1中的href都返回到列表中\n> \n> # 假如我们是要爬取妹妹图，那么就把当前页面所有的妹妹图的网址都保存到列表了\n> # 只需要进行如下操作遍历列表就行\n> for pngurl in dst_list:\n>  print(pngurl)\n> ```\n\n---\n\n# 结束语\n\n​\t\t爬虫会涉及到有关法律问题，这里不作讨论，但是希望大家不要拿来干坏事。***概不负责***。\n\n​\t\t爬虫与反爬、反反爬一直都在相互进行着，是相互迭代的过程，爬虫重点在于数据分析而不是代码编写。\n\n​\t\t本课程涉及的只是非常非常简单的爬虫，还有很多很多爬虫知识需要后续的学习，爬虫涉及的知识太广了，不是一堂课能够讲的清楚的。涵盖网络知识、密码知识、前后端工作方式、编码格式等等。之后应该学校课程有一门叫做<kbd>《计算机网络技术》</kbd>，我个人感觉这门课程非常重要，但是其实学校老师讲的可能`emmmmmm...`。大家可以课外多花时间学习，不管之后是嵌入式，物联网，互联网，软件开发，网络安全、科学上网等等方向都需要用到计算机网络的知识。\n\n​\t\t任重而道远，我学这个是凭借着兴趣而学习，所以更多的知识还是得看自己慢慢学。之后我如果有时间，应该会录制两三个爬虫例子。如爬取二次元桌面图片、一键登录校园网、获取天气预报、打造一个翻译官等等。\n","slug":"Python爬虫学习——面向初学者","published":1,"updated":"2022-04-05T13:12:11.261Z","_id":"cl1m40hwb0000rsu5e9vk13cu","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"Python爬虫入门教程\"><a href=\"#Python爬虫入门教程\" class=\"headerlink\" title=\"Python爬虫入门教程\"></a><code>Python</code>爬虫入门教程</h1><hr>\n<h2 id=\"基础知识\"><a href=\"#基础知识\" class=\"headerlink\" title=\"基础知识\"></a>基础知识</h2><h3 id=\"什么是HTML、CSS、JavaScript\"><a href=\"#什么是HTML、CSS、JavaScript\" class=\"headerlink\" title=\"什么是HTML、CSS、JavaScript\"></a>什么是<code>HTML、CSS、JavaScript</code></h3><blockquote>\n<p>网页往往采用<code>html+css+js</code>开发，<code>html</code>是一门标记语言</p>\n<p>如下：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;!- 将下面这句话放入html文件中，--&gt;</span><br><span class=\"line\">&lt;!- 然后浏览器就会将这句话解释为下面那张图片，--&gt;</span><br><span class=\"line\">&lt;!- 这个就是浏览器渲染的功能--&gt;</span><br><span class=\"line\">&lt;!- 这里我们知道了一个词——浏览器的渲染   --&gt;</span><br><span class=\"line\">&lt;!- 并且我们发现，浏览器会在下面这个网址 自动 --&gt;</span><br><span class=\"line\">&lt;!- 把这张图片下载下来，然后渲染给我们看，这在我们之后抓包会有用 --&gt;</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">img</span> <span class=\"attr\">src</span>=<span class=\"string\">&quot;https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019260.png&quot;</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"attr\">width</span>=<span class=\"string\">&quot;300px&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019260.png\" width=\"300px\">\n</blockquote>\n<h3 id=\"什么是请求，什么是响应\"><a href=\"#什么是请求，什么是响应\" class=\"headerlink\" title=\"什么是请求，什么是响应\"></a>什么是请求，什么是响应</h3><blockquote>\n<p>请求：就是前端向后端发送一个请求，如请求我的账户浏览记录</p>\n<p>响应：就是后端向前端发送一个响应，你请求你的账户浏览器记录，那么我把记录发给你，叫做响应</p>\n<p><code>JavaScript</code>中有请求，浏览器渲染到其中的请求，就会向后端发送请求</p>\n</blockquote>\n<h3 id=\"什么是GET，什么是POST\"><a href=\"#什么是GET，什么是POST\" class=\"headerlink\" title=\"什么是GET，什么是POST\"></a>什么是<code>GET</code>，什么是<code>POST</code></h3><blockquote>\n<p>这个是两种请求方式而已，<code>get</code>直接把请求数据放在链接里面，<code>post</code>一般以则不是</p>\n</blockquote>\n<h3 id=\"什么是Cookie\"><a href=\"#什么是Cookie\" class=\"headerlink\" title=\"什么是Cookie\"></a>什么是<code>Cookie</code></h3><blockquote>\n<p>曲奇饼干？不是</p>\n<p>打个比方，大家申请出校，需要在手机上申请，然后今天一天都可以通过刷脸进出校园</p>\n<p>那么，在手机上申请相当于告诉学校后端，你请求了进出校权限。也相当于，你在网页上登录账户密码</p>\n<p>然后，你一天可以通过刷脸，这个刷脸就是<code>cookie</code>，今天进出校园不需要再申请了</p>\n<p>这个就是<code>cookie</code>的作用，最常见的就是，不需要每次点开一个页面都进行账户密码登录</p>\n</blockquote>\n<h3 id=\"Python基本语法\"><a href=\"#Python基本语法\" class=\"headerlink\" title=\"Python基本语法\"></a><code>Python</code>基本语法</h3><blockquote>\n<p>这个本该大家自己去学习的，但是这里说好基础入门，就简单提一点点</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">a = <span class=\"number\">1</span></span><br><span class=\"line\">b = <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"comment\"># if结构</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> a &gt; b:</span><br><span class=\"line\"> <span class=\"built_in\">print</span>(<span class=\"string\">&quot;a大于b&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\"> <span class=\"built_in\">print</span>(<span class=\"string\">&quot;a不大于b&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># while循环</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\"> <span class=\"built_in\">print</span>(<span class=\"string\">&quot;这里面是while循环&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 列表和字典</span></span><br><span class=\"line\">m = [<span class=\"string\">&quot;hello&quot;</span>, <span class=\"number\">2</span>, <span class=\"number\">4.5</span>]  <span class=\"comment\"># 列表支持不同数据类型，并且可以随意扩充和删减</span></span><br><span class=\"line\">n = &#123;\t\t\t<span class=\"comment\"># 字典里面每个元素都是   键值:值   组成</span></span><br><span class=\"line\"> <span class=\"string\">&quot;key1&quot;</span>: <span class=\"number\">3</span>,</span><br><span class=\"line\"> <span class=\"string\">&quot;key3&quot;</span>: <span class=\"string\">&quot;hello&quot;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">m[<span class=\"number\">0</span>]    <span class=\"comment\">## 索引到第0个元素，即 &quot;hello&quot;</span></span><br><span class=\"line\">n[<span class=\"string\">&quot;key1&quot;</span>]   <span class=\"comment\">## 索引到键值为&quot;key1&quot;的值，即 3</span></span><br></pre></td></tr></table></figure>\n</blockquote>\n<h3 id=\"什么是抓包\"><a href=\"#什么是抓包\" class=\"headerlink\" title=\"什么是抓包\"></a>什么是抓包</h3><blockquote>\n<p>打个比方：你要向某人发一条数据，我在你们之间截获了或者记录了你们的数据，这个叫做抓包</p>\n</blockquote>\n<pre class=\"mermaid\">graph LR\nA(数据发送者) -->B[抓包者]\nB -->C(数据接收者)</pre>\n<blockquote>\n<p><strong>那么我们需要抓什么包呢？抓包的用处在哪呢？</strong></p>\n<p>答：我们需要抓取浏览器和后端服务器通信的包；用处是分析他们的数据然后用代码进行伪造数据发送，以便获得和浏览器同样的响应</p>\n</blockquote>\n<h3 id=\"什么是代理\"><a href=\"#什么是代理\" class=\"headerlink\" title=\"什么是代理\"></a>什么是代理</h3><blockquote>\n<p>不进行代理应该是下列图：</p>\n</blockquote>\n<pre class=\"mermaid\">graph LR\nA(前台客户端)-->|发送请求|C[后台服务器]\nC -->|返回响应|A</pre>\n<blockquote>\n<p>代理就是如下：</p>\n</blockquote>\n<pre class=\"mermaid\">graph LR\nA(前台客户端)-->|发送请求|B[代理服务器]\nB -->|转发请求|C(后台服务器)\nC -->|返回响应|B\nB -->|转发响应|A</pre>\n\n<h3 id=\"如何伪造呢？\"><a href=\"#如何伪造呢？\" class=\"headerlink\" title=\"如何伪造呢？\"></a>如何伪造呢？</h3><blockquote>\n<p>1、一般网站开发者希望我们使用浏览器浏览他们的网站，不希望我们使用代码进行浏览</p>\n<p>2、欸，但我就想用代码进行浏览，怎么办呢？</p>\n<p>3、那么就需要将我们的代码尽量伪装成浏览器，让后端以为我们是浏览器</p>\n<p>4、具体就是抓包，分析数据，用代码发送请求</p>\n</blockquote>\n<hr>\n<h2 id=\"浏览器抓包\"><a href=\"#浏览器抓包\" class=\"headerlink\" title=\"浏览器抓包\"></a>浏览器抓包</h2><h3 id=\"进入调试模式\"><a href=\"#进入调试模式\" class=\"headerlink\" title=\"进入调试模式\"></a>进入调试模式</h3><blockquote>\n<p>打开某个浏览器，按下键盘上的<kbd>F12</kbd>键，进入调试模式</p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019536.png\" alt=\"image-20211219160806912\"></p>\n<p>一般用得到上面四个红圈里面的内容，建议跟我一样，将这个调试界面放到右侧，不然之后找不到对应的按钮（仅代表个人习惯）。<br>如果是英文的，也不要担心，相信这点英文应该看得懂，看不懂应该也能找到相应位置，还可以自行百度怎么换成中文哦。</p>\n<img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019319.png\" width=\"300px\">\n</blockquote>\n<blockquote>\n<ul>\n<li>红圈1、找到页面上的元素分别对应哪句<code>html</code>标签</li>\n<li>红圈2、主要看<kbd>元素</kbd>和<kbd>网络</kbd>两个</li>\n<li>红圈3、左边如果是红色表示正在抓包记录，右边是清除已经抓到的包记录</li>\n<li>红圈4、一般我喜欢直接点选<kbd>全部</kbd>这个按钮，其他的是过滤数据的类型</li>\n</ul>\n</blockquote>\n<h3 id=\"如何寻找数据呢？\"><a href=\"#如何寻找数据呢？\" class=\"headerlink\" title=\"如何寻找数据呢？\"></a>如何寻找数据呢？</h3><blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019519.png\" alt=\"image-20211219162409621\"></p>\n<p>我们首先需要伪造成浏览器，发送请求标头，然后分析一下响应的数据，这个就是一个抓包过程啦</p>\n<p>听起来是不是很简单呢？</p>\n<p><kbd>简单</kbd> 打在公屏上</p>\n</blockquote>\n<hr>\n<h2 id=\"分析数据\"><a href=\"#分析数据\" class=\"headerlink\" title=\"分析数据\"></a>分析数据</h2><h3 id=\"浏览器人性化查看数据\"><a href=\"#浏览器人性化查看数据\" class=\"headerlink\" title=\"浏览器人性化查看数据\"></a>浏览器人性化查看数据</h3><blockquote>\n<center><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052033311.png\" width=\"450px\"><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052033151.png\" width=\"450px\"></center>\n\n<p>第一张图和第二张图有所区别，多了一个<kbd>载荷</kbd>选项，因为第二张图是在百度翻译上面抓的</p>\n<p>第二张图发送请求时候带了参数，所以比第一张图多了<kbd>载荷</kbd>选项</p>\n</blockquote>\n<h3 id=\"分析请求标头\"><a href=\"#分析请求标头\" class=\"headerlink\" title=\"分析请求标头\"></a>分析请求标头</h3><blockquote>\n<p><strong>这么多的数据，我应该怎么办呢？</strong></p>\n<ul>\n<li><code>User-Agent</code>：这个相当于浏览器标识，看你是什么浏览器发送的，我们直接用这个就行<code>Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36</code>，这个代表是<code>chrome</code>浏览器的标识</li>\n<li><code>Referer</code>：它其实是<code>refer</code>，就是代表这个网也从哪个网页来的</li>\n<li><code>cookie</code>：就是<code>cookie</code>，前面基础知识提到过</li>\n<li><code>请求网址</code>：就是你向哪个网址发送请求，请求的对象是哪个</li>\n</ul>\n<p><strong>查看载荷</strong></p>\n<p>如上面第二张图中的请求网址是：<img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019090.png\" alt=\"image-20211219170540421\"></p>\n<p>分为前后两部分组成，后面那部分就是载荷了，它是多个<kbd>字符串参数</kbd>，然后它是这么个形式：<kbd>键值=值</kbd> 组成的</p>\n<p>多个<kbd>字符串参数</kbd>用<code>&amp;</code>链接起来，把他人性化一点查看就是这样：<kbd>字符串参数</kbd></p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019096.png\" alt=\"image-20211219170645219\"></p>\n<p><strong>POST请求不仅仅只有请求头还有请求数据</strong></p>\n<p>下面是百度翻译的<code>post</code>请求的载荷</p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019112.png\" alt=\"image-20211219170803923\"></p>\n<p>上面和<code>get</code>请求一样，是<kbd>字符串参数</kbd>，下面就是<kbd>表单数据</kbd>，这个是很重要的一个部分</p>\n</blockquote>\n<p>这些都是基础概念，之后会用到，现在先学学</p>\n<h3 id=\"分析响应数据\"><a href=\"#分析响应数据\" class=\"headerlink\" title=\"分析响应数据\"></a>分析响应数据</h3><blockquote>\n<p>响应数据多种多样，常见的有：<code>html</code>文本，图片文件，表单数据，视频文件等等</p>\n<p>其中，图片文件和视频文件等都是二进制格式</p>\n<p><code>html</code>文本和表单数据是文本格式</p>\n</blockquote>\n<blockquote>\n<ul>\n<li><code>html</code>文本</li>\n</ul>\n<p>一般都需要请求这个，它会告诉浏览器需要<kbd>渲染</kbd>什么，如下载哪张图片，下载哪个音频，下载哪个文件等等</p>\n<p>我们一般都需要分析一下这个文件</p>\n<ul>\n<li>图片文件</li>\n</ul>\n<p>直接以二进制的形式写入本地就相当于下载下来</p>\n<ul>\n<li>表单数据</li>\n</ul>\n<p>返回的数据中一般带有我们需要的数据，如翻译的请求，就会把翻译的结果再以表单的形式返回了</p>\n</blockquote>\n<h2 id=\"代码编写\"><a href=\"#代码编写\" class=\"headerlink\" title=\"代码编写\"></a>代码编写</h2><p>有了上述的知识，可以进行代码编写，其实完全可以先进行代码编写，然后再去上述补充基本知识，这个顺序可以根据大家喜好来看。</p>\n<p><a href=\"https://docs.python-requests.org/zh_CN/latest/user/quickstart.html\"><em><strong><code>requests</code>教程</strong></em></a></p>\n<h4 id=\"导入requests包\"><a href=\"#导入requests包\" class=\"headerlink\" title=\"导入requests包\"></a>导入<code>requests</code>包</h4><blockquote>\n<p>下载：<code>pip install requests</code></p>\n<p>导入：<code>import requests</code></p>\n<p><code>emmmmm </code>怎么说呢，这个好像不如跟着视频里面做一遍，虽然我还没有录视频，但是聪明的你们肯定会上百度吧</p>\n</blockquote>\n<h4 id=\"requests包的使用\"><a href=\"#requests包的使用\" class=\"headerlink\" title=\"requests包的使用\"></a><code>requests</code>包的使用</h4><blockquote>\n<p>这个教程顺序可能和网上很多都不一样</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> requests <span class=\"keyword\">as</span> rq</span><br><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"></span><br><span class=\"line\">tool = rq.session()   <span class=\"comment\"># 这个会返回一个爬虫工具箱，并且它会自动维持cookie</span></span><br><span class=\"line\"></span><br><span class=\"line\">verify=<span class=\"literal\">False</span>   <span class=\"comment\"># 设置是否进行SSL验证，一般设置为否</span></span><br><span class=\"line\">url=<span class=\"string\">&quot;https://baidu.com&quot;</span>  <span class=\"comment\"># 这里请求百度的数据</span></span><br><span class=\"line\">headers=&#123;   <span class=\"comment\"># 设置请求头</span></span><br><span class=\"line\"> <span class=\"string\">&quot;User-Agent&quot;</span>: <span class=\"string\">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/&quot;</span></span><br><span class=\"line\">  <span class=\"string\">&quot;537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36&quot;</span>,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">proxies=&#123;    <span class=\"comment\"># 设置代理</span></span><br><span class=\"line\"> <span class=\"string\">&quot;http&quot;</span>: <span class=\"literal\">None</span>,</span><br><span class=\"line\"> <span class=\"string\">&quot;https&quot;</span>: <span class=\"literal\">None</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">params=&#123;   <span class=\"comment\"># 设置字符串参数</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">data=&#123;  <span class=\"comment\"># 设置请求表单</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 发送get请求，得到get响应</span></span><br><span class=\"line\">responseGet = tool.get(url=url, params=params, headers=headers, verify=verify, proxies=proxies)</span><br><span class=\"line\"><span class=\"comment\"># 发送post请求，得到post响应</span></span><br><span class=\"line\">responsePost = tool.post(url=url, data=data, headers=headers, verify=verify, proxies=proxies)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 解析响应</span></span><br><span class=\"line\"><span class=\"comment\"># 1、假如响应是文本数据，如html文本</span></span><br><span class=\"line\">response = responseGet</span><br><span class=\"line\">response.content <span class=\"comment\"># 这个是内容，是二进制编码</span></span><br><span class=\"line\">response.content.decode(<span class=\"string\">&quot;gbk&quot;</span>)  <span class=\"comment\"># 使用gbk解码，不加参数就是utf-8解码</span></span><br><span class=\"line\"><span class=\"comment\"># 2、假如响应是图片数据</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&quot;1.png&quot;</span>, <span class=\"string\">&quot;wb&quot;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\"> f.write(response.content)   <span class=\"comment\"># 直接以二进制写入文件</span></span><br><span class=\"line\"><span class=\"comment\"># 3、假如响应是表单数据</span></span><br><span class=\"line\">dat = json.loads(response.content.decode())   <span class=\"comment\"># 返回的就是一个字典数据了</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</blockquote>\n<h4 id=\"正则表达式简单用法\"><a href=\"#正则表达式简单用法\" class=\"headerlink\" title=\"正则表达式简单用法\"></a>正则表达式简单用法</h4><blockquote>\n<p>爬虫中的正则表达式一般会比较简单</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> re   <span class=\"comment\"># 导入正则表达式包</span></span><br><span class=\"line\"><span class=\"comment\"># 假如有下列字符串需要被匹配</span></span><br><span class=\"line\"><span class=\"comment\"># str1 = &quot;&lt;link href=&quot;https://stacdn.proginn.com/plugin/swiper/swiper.min.css?version=4.30.2&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># rel=&quot;stylesheet&quot; type=&quot;text/css&quot;&gt;&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 其中href中的是我们需要的那么</span></span><br><span class=\"line\">html = response.content.decode()</span><br><span class=\"line\">restr = <span class=\"string\">&quot;&lt;link\\\\shref=\\&quot;(.*?)\\&quot;\\\\srel=\\&quot;stylesheet\\&quot;\\\\stype=\\&quot;text/css\\&quot;&gt;&quot;</span></span><br><span class=\"line\">dst_list = re.findall(restr, html)   <span class=\"comment\"># 返回一个列表</span></span><br><span class=\"line\"><span class=\"comment\"># 上面这条语句，会将html里面所有形如str1中的href都返回到列表中</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 假如我们是要爬取妹妹图，那么就把当前页面所有的妹妹图的网址都保存到列表了</span></span><br><span class=\"line\"><span class=\"comment\"># 只需要进行如下操作遍历列表就行</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> pngurl <span class=\"keyword\">in</span> dst_list:</span><br><span class=\"line\"> <span class=\"built_in\">print</span>(pngurl)</span><br></pre></td></tr></table></figure>\n</blockquote>\n<hr>\n<h1 id=\"结束语\"><a href=\"#结束语\" class=\"headerlink\" title=\"结束语\"></a>结束语</h1><p>​        爬虫会涉及到有关法律问题，这里不作讨论，但是希望大家不要拿来干坏事。<em><strong>概不负责</strong></em>。</p>\n<p>​        爬虫与反爬、反反爬一直都在相互进行着，是相互迭代的过程，爬虫重点在于数据分析而不是代码编写。</p>\n<p>​        本课程涉及的只是非常非常简单的爬虫，还有很多很多爬虫知识需要后续的学习，爬虫涉及的知识太广了，不是一堂课能够讲的清楚的。涵盖网络知识、密码知识、前后端工作方式、编码格式等等。之后应该学校课程有一门叫做<kbd>《计算机网络技术》</kbd>，我个人感觉这门课程非常重要，但是其实学校老师讲的可能<code>emmmmmm...</code>。大家可以课外多花时间学习，不管之后是嵌入式，物联网，互联网，软件开发，网络安全、科学上网等等方向都需要用到计算机网络的知识。</p>\n<p>​        任重而道远，我学这个是凭借着兴趣而学习，所以更多的知识还是得看自己慢慢学。之后我如果有时间，应该会录制两三个爬虫例子。如爬取二次元桌面图片、一键登录校园网、获取天气预报、打造一个翻译官等等。</p>\n","site":{"data":{}},"more":"<h1 id=\"Python爬虫入门教程\"><a href=\"#Python爬虫入门教程\" class=\"headerlink\" title=\"Python爬虫入门教程\"></a><code>Python</code>爬虫入门教程</h1><hr>\n<h2 id=\"基础知识\"><a href=\"#基础知识\" class=\"headerlink\" title=\"基础知识\"></a>基础知识</h2><h3 id=\"什么是HTML、CSS、JavaScript\"><a href=\"#什么是HTML、CSS、JavaScript\" class=\"headerlink\" title=\"什么是HTML、CSS、JavaScript\"></a>什么是<code>HTML、CSS、JavaScript</code></h3><blockquote>\n<p>网页往往采用<code>html+css+js</code>开发，<code>html</code>是一门标记语言</p>\n<p>如下：</p>\n<figure class=\"highlight html\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;!- 将下面这句话放入html文件中，--&gt;</span><br><span class=\"line\">&lt;!- 然后浏览器就会将这句话解释为下面那张图片，--&gt;</span><br><span class=\"line\">&lt;!- 这个就是浏览器渲染的功能--&gt;</span><br><span class=\"line\">&lt;!- 这里我们知道了一个词——浏览器的渲染   --&gt;</span><br><span class=\"line\">&lt;!- 并且我们发现，浏览器会在下面这个网址 自动 --&gt;</span><br><span class=\"line\">&lt;!- 把这张图片下载下来，然后渲染给我们看，这在我们之后抓包会有用 --&gt;</span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">img</span> <span class=\"attr\">src</span>=<span class=\"string\">&quot;https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019260.png&quot;</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"attr\">width</span>=<span class=\"string\">&quot;300px&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>\n\n<img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019260.png\" width=\"300px\">\n</blockquote>\n<h3 id=\"什么是请求，什么是响应\"><a href=\"#什么是请求，什么是响应\" class=\"headerlink\" title=\"什么是请求，什么是响应\"></a>什么是请求，什么是响应</h3><blockquote>\n<p>请求：就是前端向后端发送一个请求，如请求我的账户浏览记录</p>\n<p>响应：就是后端向前端发送一个响应，你请求你的账户浏览器记录，那么我把记录发给你，叫做响应</p>\n<p><code>JavaScript</code>中有请求，浏览器渲染到其中的请求，就会向后端发送请求</p>\n</blockquote>\n<h3 id=\"什么是GET，什么是POST\"><a href=\"#什么是GET，什么是POST\" class=\"headerlink\" title=\"什么是GET，什么是POST\"></a>什么是<code>GET</code>，什么是<code>POST</code></h3><blockquote>\n<p>这个是两种请求方式而已，<code>get</code>直接把请求数据放在链接里面，<code>post</code>一般以则不是</p>\n</blockquote>\n<h3 id=\"什么是Cookie\"><a href=\"#什么是Cookie\" class=\"headerlink\" title=\"什么是Cookie\"></a>什么是<code>Cookie</code></h3><blockquote>\n<p>曲奇饼干？不是</p>\n<p>打个比方，大家申请出校，需要在手机上申请，然后今天一天都可以通过刷脸进出校园</p>\n<p>那么，在手机上申请相当于告诉学校后端，你请求了进出校权限。也相当于，你在网页上登录账户密码</p>\n<p>然后，你一天可以通过刷脸，这个刷脸就是<code>cookie</code>，今天进出校园不需要再申请了</p>\n<p>这个就是<code>cookie</code>的作用，最常见的就是，不需要每次点开一个页面都进行账户密码登录</p>\n</blockquote>\n<h3 id=\"Python基本语法\"><a href=\"#Python基本语法\" class=\"headerlink\" title=\"Python基本语法\"></a><code>Python</code>基本语法</h3><blockquote>\n<p>这个本该大家自己去学习的，但是这里说好基础入门，就简单提一点点</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">a = <span class=\"number\">1</span></span><br><span class=\"line\">b = <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"comment\"># if结构</span></span><br><span class=\"line\"><span class=\"keyword\">if</span> a &gt; b:</span><br><span class=\"line\"> <span class=\"built_in\">print</span>(<span class=\"string\">&quot;a大于b&quot;</span>)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\"> <span class=\"built_in\">print</span>(<span class=\"string\">&quot;a不大于b&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># while循环</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\"> <span class=\"built_in\">print</span>(<span class=\"string\">&quot;这里面是while循环&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 列表和字典</span></span><br><span class=\"line\">m = [<span class=\"string\">&quot;hello&quot;</span>, <span class=\"number\">2</span>, <span class=\"number\">4.5</span>]  <span class=\"comment\"># 列表支持不同数据类型，并且可以随意扩充和删减</span></span><br><span class=\"line\">n = &#123;\t\t\t<span class=\"comment\"># 字典里面每个元素都是   键值:值   组成</span></span><br><span class=\"line\"> <span class=\"string\">&quot;key1&quot;</span>: <span class=\"number\">3</span>,</span><br><span class=\"line\"> <span class=\"string\">&quot;key3&quot;</span>: <span class=\"string\">&quot;hello&quot;</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">m[<span class=\"number\">0</span>]    <span class=\"comment\">## 索引到第0个元素，即 &quot;hello&quot;</span></span><br><span class=\"line\">n[<span class=\"string\">&quot;key1&quot;</span>]   <span class=\"comment\">## 索引到键值为&quot;key1&quot;的值，即 3</span></span><br></pre></td></tr></table></figure>\n</blockquote>\n<h3 id=\"什么是抓包\"><a href=\"#什么是抓包\" class=\"headerlink\" title=\"什么是抓包\"></a>什么是抓包</h3><blockquote>\n<p>打个比方：你要向某人发一条数据，我在你们之间截获了或者记录了你们的数据，这个叫做抓包</p>\n</blockquote>\n<pre class=\"mermaid\">graph LR\nA(数据发送者) -->B[抓包者]\nB -->C(数据接收者)</pre>\n<blockquote>\n<p><strong>那么我们需要抓什么包呢？抓包的用处在哪呢？</strong></p>\n<p>答：我们需要抓取浏览器和后端服务器通信的包；用处是分析他们的数据然后用代码进行伪造数据发送，以便获得和浏览器同样的响应</p>\n</blockquote>\n<h3 id=\"什么是代理\"><a href=\"#什么是代理\" class=\"headerlink\" title=\"什么是代理\"></a>什么是代理</h3><blockquote>\n<p>不进行代理应该是下列图：</p>\n</blockquote>\n<pre class=\"mermaid\">graph LR\nA(前台客户端)-->|发送请求|C[后台服务器]\nC -->|返回响应|A</pre>\n<blockquote>\n<p>代理就是如下：</p>\n</blockquote>\n<pre class=\"mermaid\">graph LR\nA(前台客户端)-->|发送请求|B[代理服务器]\nB -->|转发请求|C(后台服务器)\nC -->|返回响应|B\nB -->|转发响应|A</pre>\n\n<h3 id=\"如何伪造呢？\"><a href=\"#如何伪造呢？\" class=\"headerlink\" title=\"如何伪造呢？\"></a>如何伪造呢？</h3><blockquote>\n<p>1、一般网站开发者希望我们使用浏览器浏览他们的网站，不希望我们使用代码进行浏览</p>\n<p>2、欸，但我就想用代码进行浏览，怎么办呢？</p>\n<p>3、那么就需要将我们的代码尽量伪装成浏览器，让后端以为我们是浏览器</p>\n<p>4、具体就是抓包，分析数据，用代码发送请求</p>\n</blockquote>\n<hr>\n<h2 id=\"浏览器抓包\"><a href=\"#浏览器抓包\" class=\"headerlink\" title=\"浏览器抓包\"></a>浏览器抓包</h2><h3 id=\"进入调试模式\"><a href=\"#进入调试模式\" class=\"headerlink\" title=\"进入调试模式\"></a>进入调试模式</h3><blockquote>\n<p>打开某个浏览器，按下键盘上的<kbd>F12</kbd>键，进入调试模式</p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019536.png\" alt=\"image-20211219160806912\"></p>\n<p>一般用得到上面四个红圈里面的内容，建议跟我一样，将这个调试界面放到右侧，不然之后找不到对应的按钮（仅代表个人习惯）。<br>如果是英文的，也不要担心，相信这点英文应该看得懂，看不懂应该也能找到相应位置，还可以自行百度怎么换成中文哦。</p>\n<img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019319.png\" width=\"300px\">\n</blockquote>\n<blockquote>\n<ul>\n<li>红圈1、找到页面上的元素分别对应哪句<code>html</code>标签</li>\n<li>红圈2、主要看<kbd>元素</kbd>和<kbd>网络</kbd>两个</li>\n<li>红圈3、左边如果是红色表示正在抓包记录，右边是清除已经抓到的包记录</li>\n<li>红圈4、一般我喜欢直接点选<kbd>全部</kbd>这个按钮，其他的是过滤数据的类型</li>\n</ul>\n</blockquote>\n<h3 id=\"如何寻找数据呢？\"><a href=\"#如何寻找数据呢？\" class=\"headerlink\" title=\"如何寻找数据呢？\"></a>如何寻找数据呢？</h3><blockquote>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019519.png\" alt=\"image-20211219162409621\"></p>\n<p>我们首先需要伪造成浏览器，发送请求标头，然后分析一下响应的数据，这个就是一个抓包过程啦</p>\n<p>听起来是不是很简单呢？</p>\n<p><kbd>简单</kbd> 打在公屏上</p>\n</blockquote>\n<hr>\n<h2 id=\"分析数据\"><a href=\"#分析数据\" class=\"headerlink\" title=\"分析数据\"></a>分析数据</h2><h3 id=\"浏览器人性化查看数据\"><a href=\"#浏览器人性化查看数据\" class=\"headerlink\" title=\"浏览器人性化查看数据\"></a>浏览器人性化查看数据</h3><blockquote>\n<center><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052033311.png\" width=\"450px\"><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052033151.png\" width=\"450px\"></center>\n\n<p>第一张图和第二张图有所区别，多了一个<kbd>载荷</kbd>选项，因为第二张图是在百度翻译上面抓的</p>\n<p>第二张图发送请求时候带了参数，所以比第一张图多了<kbd>载荷</kbd>选项</p>\n</blockquote>\n<h3 id=\"分析请求标头\"><a href=\"#分析请求标头\" class=\"headerlink\" title=\"分析请求标头\"></a>分析请求标头</h3><blockquote>\n<p><strong>这么多的数据，我应该怎么办呢？</strong></p>\n<ul>\n<li><code>User-Agent</code>：这个相当于浏览器标识，看你是什么浏览器发送的，我们直接用这个就行<code>Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36</code>，这个代表是<code>chrome</code>浏览器的标识</li>\n<li><code>Referer</code>：它其实是<code>refer</code>，就是代表这个网也从哪个网页来的</li>\n<li><code>cookie</code>：就是<code>cookie</code>，前面基础知识提到过</li>\n<li><code>请求网址</code>：就是你向哪个网址发送请求，请求的对象是哪个</li>\n</ul>\n<p><strong>查看载荷</strong></p>\n<p>如上面第二张图中的请求网址是：<img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019090.png\" alt=\"image-20211219170540421\"></p>\n<p>分为前后两部分组成，后面那部分就是载荷了，它是多个<kbd>字符串参数</kbd>，然后它是这么个形式：<kbd>键值=值</kbd> 组成的</p>\n<p>多个<kbd>字符串参数</kbd>用<code>&amp;</code>链接起来，把他人性化一点查看就是这样：<kbd>字符串参数</kbd></p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019096.png\" alt=\"image-20211219170645219\"></p>\n<p><strong>POST请求不仅仅只有请求头还有请求数据</strong></p>\n<p>下面是百度翻译的<code>post</code>请求的载荷</p>\n<p><img src=\"https://raw.githubusercontent.com/MinzhiYoyo/ImageHost/main/202204052019112.png\" alt=\"image-20211219170803923\"></p>\n<p>上面和<code>get</code>请求一样，是<kbd>字符串参数</kbd>，下面就是<kbd>表单数据</kbd>，这个是很重要的一个部分</p>\n</blockquote>\n<p>这些都是基础概念，之后会用到，现在先学学</p>\n<h3 id=\"分析响应数据\"><a href=\"#分析响应数据\" class=\"headerlink\" title=\"分析响应数据\"></a>分析响应数据</h3><blockquote>\n<p>响应数据多种多样，常见的有：<code>html</code>文本，图片文件，表单数据，视频文件等等</p>\n<p>其中，图片文件和视频文件等都是二进制格式</p>\n<p><code>html</code>文本和表单数据是文本格式</p>\n</blockquote>\n<blockquote>\n<ul>\n<li><code>html</code>文本</li>\n</ul>\n<p>一般都需要请求这个，它会告诉浏览器需要<kbd>渲染</kbd>什么，如下载哪张图片，下载哪个音频，下载哪个文件等等</p>\n<p>我们一般都需要分析一下这个文件</p>\n<ul>\n<li>图片文件</li>\n</ul>\n<p>直接以二进制的形式写入本地就相当于下载下来</p>\n<ul>\n<li>表单数据</li>\n</ul>\n<p>返回的数据中一般带有我们需要的数据，如翻译的请求，就会把翻译的结果再以表单的形式返回了</p>\n</blockquote>\n<h2 id=\"代码编写\"><a href=\"#代码编写\" class=\"headerlink\" title=\"代码编写\"></a>代码编写</h2><p>有了上述的知识，可以进行代码编写，其实完全可以先进行代码编写，然后再去上述补充基本知识，这个顺序可以根据大家喜好来看。</p>\n<p><a href=\"https://docs.python-requests.org/zh_CN/latest/user/quickstart.html\"><em><strong><code>requests</code>教程</strong></em></a></p>\n<h4 id=\"导入requests包\"><a href=\"#导入requests包\" class=\"headerlink\" title=\"导入requests包\"></a>导入<code>requests</code>包</h4><blockquote>\n<p>下载：<code>pip install requests</code></p>\n<p>导入：<code>import requests</code></p>\n<p><code>emmmmm </code>怎么说呢，这个好像不如跟着视频里面做一遍，虽然我还没有录视频，但是聪明的你们肯定会上百度吧</p>\n</blockquote>\n<h4 id=\"requests包的使用\"><a href=\"#requests包的使用\" class=\"headerlink\" title=\"requests包的使用\"></a><code>requests</code>包的使用</h4><blockquote>\n<p>这个教程顺序可能和网上很多都不一样</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> requests <span class=\"keyword\">as</span> rq</span><br><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"></span><br><span class=\"line\">tool = rq.session()   <span class=\"comment\"># 这个会返回一个爬虫工具箱，并且它会自动维持cookie</span></span><br><span class=\"line\"></span><br><span class=\"line\">verify=<span class=\"literal\">False</span>   <span class=\"comment\"># 设置是否进行SSL验证，一般设置为否</span></span><br><span class=\"line\">url=<span class=\"string\">&quot;https://baidu.com&quot;</span>  <span class=\"comment\"># 这里请求百度的数据</span></span><br><span class=\"line\">headers=&#123;   <span class=\"comment\"># 设置请求头</span></span><br><span class=\"line\"> <span class=\"string\">&quot;User-Agent&quot;</span>: <span class=\"string\">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/&quot;</span></span><br><span class=\"line\">  <span class=\"string\">&quot;537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36&quot;</span>,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">proxies=&#123;    <span class=\"comment\"># 设置代理</span></span><br><span class=\"line\"> <span class=\"string\">&quot;http&quot;</span>: <span class=\"literal\">None</span>,</span><br><span class=\"line\"> <span class=\"string\">&quot;https&quot;</span>: <span class=\"literal\">None</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">params=&#123;   <span class=\"comment\"># 设置字符串参数</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\">data=&#123;  <span class=\"comment\"># 设置请求表单</span></span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 发送get请求，得到get响应</span></span><br><span class=\"line\">responseGet = tool.get(url=url, params=params, headers=headers, verify=verify, proxies=proxies)</span><br><span class=\"line\"><span class=\"comment\"># 发送post请求，得到post响应</span></span><br><span class=\"line\">responsePost = tool.post(url=url, data=data, headers=headers, verify=verify, proxies=proxies)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 解析响应</span></span><br><span class=\"line\"><span class=\"comment\"># 1、假如响应是文本数据，如html文本</span></span><br><span class=\"line\">response = responseGet</span><br><span class=\"line\">response.content <span class=\"comment\"># 这个是内容，是二进制编码</span></span><br><span class=\"line\">response.content.decode(<span class=\"string\">&quot;gbk&quot;</span>)  <span class=\"comment\"># 使用gbk解码，不加参数就是utf-8解码</span></span><br><span class=\"line\"><span class=\"comment\"># 2、假如响应是图片数据</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&quot;1.png&quot;</span>, <span class=\"string\">&quot;wb&quot;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\"> f.write(response.content)   <span class=\"comment\"># 直接以二进制写入文件</span></span><br><span class=\"line\"><span class=\"comment\"># 3、假如响应是表单数据</span></span><br><span class=\"line\">dat = json.loads(response.content.decode())   <span class=\"comment\"># 返回的就是一个字典数据了</span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n</blockquote>\n<h4 id=\"正则表达式简单用法\"><a href=\"#正则表达式简单用法\" class=\"headerlink\" title=\"正则表达式简单用法\"></a>正则表达式简单用法</h4><blockquote>\n<p>爬虫中的正则表达式一般会比较简单</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> re   <span class=\"comment\"># 导入正则表达式包</span></span><br><span class=\"line\"><span class=\"comment\"># 假如有下列字符串需要被匹配</span></span><br><span class=\"line\"><span class=\"comment\"># str1 = &quot;&lt;link href=&quot;https://stacdn.proginn.com/plugin/swiper/swiper.min.css?version=4.30.2&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># rel=&quot;stylesheet&quot; type=&quot;text/css&quot;&gt;&quot;</span></span><br><span class=\"line\"><span class=\"comment\"># 其中href中的是我们需要的那么</span></span><br><span class=\"line\">html = response.content.decode()</span><br><span class=\"line\">restr = <span class=\"string\">&quot;&lt;link\\\\shref=\\&quot;(.*?)\\&quot;\\\\srel=\\&quot;stylesheet\\&quot;\\\\stype=\\&quot;text/css\\&quot;&gt;&quot;</span></span><br><span class=\"line\">dst_list = re.findall(restr, html)   <span class=\"comment\"># 返回一个列表</span></span><br><span class=\"line\"><span class=\"comment\"># 上面这条语句，会将html里面所有形如str1中的href都返回到列表中</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 假如我们是要爬取妹妹图，那么就把当前页面所有的妹妹图的网址都保存到列表了</span></span><br><span class=\"line\"><span class=\"comment\"># 只需要进行如下操作遍历列表就行</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> pngurl <span class=\"keyword\">in</span> dst_list:</span><br><span class=\"line\"> <span class=\"built_in\">print</span>(pngurl)</span><br></pre></td></tr></table></figure>\n</blockquote>\n<hr>\n<h1 id=\"结束语\"><a href=\"#结束语\" class=\"headerlink\" title=\"结束语\"></a>结束语</h1><p>​        爬虫会涉及到有关法律问题，这里不作讨论，但是希望大家不要拿来干坏事。<em><strong>概不负责</strong></em>。</p>\n<p>​        爬虫与反爬、反反爬一直都在相互进行着，是相互迭代的过程，爬虫重点在于数据分析而不是代码编写。</p>\n<p>​        本课程涉及的只是非常非常简单的爬虫，还有很多很多爬虫知识需要后续的学习，爬虫涉及的知识太广了，不是一堂课能够讲的清楚的。涵盖网络知识、密码知识、前后端工作方式、编码格式等等。之后应该学校课程有一门叫做<kbd>《计算机网络技术》</kbd>，我个人感觉这门课程非常重要，但是其实学校老师讲的可能<code>emmmmmm...</code>。大家可以课外多花时间学习，不管之后是嵌入式，物联网，互联网，软件开发，网络安全、科学上网等等方向都需要用到计算机网络的知识。</p>\n<p>​        任重而道远，我学这个是凭借着兴趣而学习，所以更多的知识还是得看自己慢慢学。之后我如果有时间，应该会录制两三个爬虫例子。如爬取二次元桌面图片、一键登录校园网、获取天气预报、打造一个翻译官等等。</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cl1m3bz2800017gu52i2z1vdl","category_id":"cl1m3bz2e00047gu5a8lqgc07","_id":"cl1m3bz2p000c7gu53si381j3"},{"post_id":"cl1m3bz2b00037gu5c4j22ql3","category_id":"cl1m3bz2e00047gu5a8lqgc07","_id":"cl1m3bz2q000e7gu5fsw43245"},{"post_id":"cl1m3fohp0000k4u50nm422aa","category_id":"cl1m3fohu0001k4u5eib1fo2k","_id":"cl1m3fohx0004k4u5hrlu6d4w"},{"post_id":"cl1m3qre700000su5ap2e331l","category_id":"cl1m3qred00010su5cl370w8n","_id":"cl1m3qrei00070su5an2l2qm4"},{"post_id":"cl1m3qre700000su5ap2e331l","category_id":"cl1m3qreh00040su56ch6hsan","_id":"cl1m3qrei00080su5hz1j6pcc"},{"post_id":"cl1m40hwb0000rsu5e9vk13cu","category_id":"cl1m3qred00010su5cl370w8n","_id":"cl1m40hwe0003rsu58l7l130s"},{"post_id":"cl1m40hwb0000rsu5e9vk13cu","category_id":"cl1m3qreh00040su56ch6hsan","_id":"cl1m40hwe0004rsu586vq0d39"}],"PostTag":[{"post_id":"cl1m3bz2800017gu52i2z1vdl","tag_id":"cl1m3bz2f00057gu550p2falt","_id":"cl1m3bz2q000g7gu5axavglin"},{"post_id":"cl1m3bz2800017gu52i2z1vdl","tag_id":"cl1m3bz2n000b7gu51cjyh2jw","_id":"cl1m3bz2r000h7gu5b5rle90x"},{"post_id":"cl1m3bz2800017gu52i2z1vdl","tag_id":"cl1m3bz2p000d7gu57adrg1un","_id":"cl1m3bz2r000j7gu5hcbcerml"},{"post_id":"cl1m3bz2b00037gu5c4j22ql3","tag_id":"cl1m3bz2f00057gu550p2falt","_id":"cl1m3bz2s000l7gu5hw4s8d7l"},{"post_id":"cl1m3bz2b00037gu5c4j22ql3","tag_id":"cl1m3bz2r000i7gu56hv32u9d","_id":"cl1m3bz2s000m7gu54t99cv7h"},{"post_id":"cl1m3bz2b00037gu5c4j22ql3","tag_id":"cl1m3bz2p000d7gu57adrg1un","_id":"cl1m3bz2s000n7gu58nlc8ejw"},{"post_id":"cl1m3fohp0000k4u50nm422aa","tag_id":"cl1m3fohw0002k4u57taob8rg","_id":"cl1m3fohx0006k4u55s9a3p2r"},{"post_id":"cl1m3fohp0000k4u50nm422aa","tag_id":"cl1m3fohw0003k4u56vat5nul","_id":"cl1m3fohy0007k4u5apl7efj2"},{"post_id":"cl1m3fohp0000k4u50nm422aa","tag_id":"cl1m3fohx0005k4u5d0wcf8my","_id":"cl1m3fohy0008k4u5bfq02cmz"},{"post_id":"cl1m3qre700000su5ap2e331l","tag_id":"cl1m3qref00020su51awi2ws2","_id":"cl1m3qrei00050su5az7u95n4"},{"post_id":"cl1m3qre700000su5ap2e331l","tag_id":"cl1m3qreg00030su554pubret","_id":"cl1m3qrei00060su51czk7th2"},{"post_id":"cl1m40hwb0000rsu5e9vk13cu","tag_id":"cl1m3qref00020su51awi2ws2","_id":"cl1m40hwd0001rsu5d5ig6teb"},{"post_id":"cl1m40hwb0000rsu5e9vk13cu","tag_id":"cl1m3qreg00030su554pubret","_id":"cl1m40hwe0002rsu5gkkjdhtw"}],"Tag":[{"name":"计算机妙招","_id":"cl1m3bz2f00057gu550p2falt"},{"name":"注册表","_id":"cl1m3bz2n000b7gu51cjyh2jw"},{"name":"Windows","_id":"cl1m3bz2p000d7gu57adrg1un"},{"name":"局域网共享","_id":"cl1m3bz2r000i7gu56hv32u9d"},{"name":"Linux","_id":"cl1m3fohw0002k4u57taob8rg"},{"name":"Uboot","_id":"cl1m3fohw0003k4u56vat5nul"},{"name":"编译","_id":"cl1m3fohx0005k4u5d0wcf8my"},{"name":"Python","_id":"cl1m3qref00020su51awi2ws2"},{"name":"爬虫","_id":"cl1m3qreg00030su554pubret"}]}}